# Segmenter Models

This folder contains the code to create tensorflow models to perform the argumentative unit segmentation.

## Docker

Tensorflow is constantly changing for that a docker image was created with a specific version (2.9.1) in order to the work can be easly executed in the future. The docker image already comes with jupyter notebook that allows an easy development.

- build_docker_image.sh: Run this script to build the docker image
- run.sh: Run this script to start a container of the created image

## Notebooks

- segmenter.ipynb: This notebook contains all the code to process data, train, test and perform simple evaluation to the models.

## Corpus exporter

The `segmenter_exporter.py` file contains the necessary algorithms to export _conll_ files, in this case it could be those generated by the parser built into the training format of the neural network responsible for the segmentation of the argumentative components. This format consists of 9 files:

- [train, testa, testb].words.txt: In each line it contains an entry with the tokens separated by spaces. This input can be segmented into sentences or paragraphs depending on what is needed.
- [train, testa, testb].tags.txt: Each line contains an entry with the token labels separated by spaces. This input can be segmented into sentences or paragraphs depending on what is needed.
- vocab.[chars, tags, words].txt: Each line contains the characters, tags and words as a set respectively.
