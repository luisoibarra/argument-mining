{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "try:\n",
    "    BASE_PATH = str(Path(__file__, \"..\", \"..\", \"..\").resolve())\n",
    "    import sys\n",
    "except NameError:\n",
    "    import sys\n",
    "    BASE_PATH = str(Path(\"..\", \"..\").resolve())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if BASE_PATH not in sys.path:\n",
    "        sys.path.insert(0, BASE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import corpus_parser.conll_parser\n",
    "# import importlib\n",
    "# importlib.reload(corpus_parser.conll_parser)\n",
    "import os\n",
    "\n",
    "from corpus_parser.unified_parser import UnifiedParser\n",
    "from corpus_parser.conll_parser import ConllParser\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import keras.backend as K\n",
    "\n",
    "import json\n",
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rand\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, classification_report\n",
    "\n",
    "from link_prediction.models.link_utils import create_lr_annealing_function\n",
    "from link_prediction.models.attention import apply_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model initial params\n",
    "\n",
    "INFO_TAG = \"persuasive_essays_paragraph\"\n",
    "\n",
    "DATA_PATH = Path(BASE_PATH, \"data/\")\n",
    "\n",
    "# LANGUAGE = \"english\"\n",
    "LANGUAGE = \"spanish\"\n",
    "if LANGUAGE == \"english\":\n",
    "    GLOVE_PATH = Path(DATA_PATH, 'glove.840B.300d.txt')\n",
    "elif LANGUAGE == \"spanish\":\n",
    "    GLOVE_PATH = Path(DATA_PATH, 'glove-sbwc.i25.vec')\n",
    "else:\n",
    "    raise Exception(\"Not supported language\")\n",
    "\n",
    "EXPORT_PATH = Path(DATA_PATH, 'link_prediction', INFO_TAG)\n",
    "TO_PROCESS_DATADIR = Path(DATA_PATH, 'segmenter_processed', INFO_TAG)\n",
    "PROCESSED_DATADIR = Path(DATA_PATH, 'link_prediction_processed', INFO_TAG)\n",
    "DIM = 300\n",
    "\n",
    "params = {\n",
    "    'in_production': True,\n",
    "    \n",
    "    # Model Training Hyperparameters\n",
    "    'epochs': 70,\n",
    "    'batch_size': 20,\n",
    "    'metrics': ['acc'],\n",
    "    \n",
    "    # Ensemble Hyperparameters\n",
    "    'ensemble_amount': 3,\n",
    "    \n",
    "    # Model Hyperparameters\n",
    "    'dim': DIM,\n",
    "    'dropout': 0.1,\n",
    "    'lstm_size': 200,\n",
    "    'max_distance_encoded': 5,\n",
    "    'linear_embedders_dims': [50, 50, 50, DIM],\n",
    "    'regularizer_weight': 0.001,\n",
    "    'encoder_dense_units': 50,\n",
    "    'encoder_pool_size': 1, # If 1 no tranformation is made to the input.\n",
    "    'lstm_units': 25,\n",
    "    'final_size': 20,\n",
    "    'residual_size': 50,\n",
    "    'with_attention': True, # If the attention block is used\n",
    "    'loss_weights': {\n",
    "        'relation': 10,\n",
    "        'source': 1,\n",
    "        'target': 1,\n",
    "    },\n",
    "    \n",
    "    # Adam Optimizer Hyperparameters\n",
    "    'lr_alpha': 0.003,\n",
    "    'lr_kappa': 0.001,\n",
    "    'beta_1': 0.9,\n",
    "    'beta_2': 0.999,\n",
    "    \n",
    "    # Early Stopping Hyperparameters\n",
    "    'min_delta': 0,\n",
    "    'patience': 5,\n",
    "    \n",
    "    # Corpus Info\n",
    "    'corpus_path': str(Path(DATA_PATH, 'projection', INFO_TAG)),\n",
    "    'glove_path': str(Path(EXPORT_PATH, 'glove.npz')),\n",
    "    'export_path': str(EXPORT_PATH),\n",
    "    'model_path': str(EXPORT_PATH / \"model\"),\n",
    "    'glove_raw_path': str(Path(GLOVE_PATH)),\n",
    "    'language': LANGUAGE,\n",
    "    \n",
    "    # Vectorizer Hyperparameters\n",
    "    'sequence_standardize': None,\n",
    "    'sequence_split': 'whitespace',\n",
    "    \n",
    "    # Corpus Hyperparameters\n",
    "    'max_proposition_distance': 10, # Max distance allowed between argumentation\n",
    "    'non_related_max_proportion': 0.5, # Max proportion allowed between non related links and the total of links\n",
    "    \n",
    "    # Data info\n",
    "    'to_process_data_path': str(Path(TO_PROCESS_DATADIR)), # Directory with text to be processed\n",
    "    'processed_data_path': str(Path(PROCESSED_DATADIR)), # Directory to save the processed data\n",
    "}\n",
    "\n",
    "params['model_name'] = \"model\" + (\"_attention\" if params['with_attention'] else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev relations 652\n",
      "dev source argumentative units 326\n",
      "dev target argumentative units 144\n",
      "test relations 1618\n",
      "test source argumentative units 809\n",
      "test target argumentative units 365\n",
      "train relations 5392\n",
      "train source argumentative units 2696\n",
      "train target argumentative units 1198\n",
      "Vocab size 8958\n",
      "Relation tags ['attacks_Inverse', 'attacks', 'supports_Inverse', 'supports']\n",
      "Proposition tags ['Claim', 'MajorClaim', 'Premise']\n",
      "max_size_prop 70\n",
      "max_amount_doc 20\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset \n",
    "\n",
    "def find_duplicates(dataframe, first, second, group):\n",
    "\n",
    "    for g, dataframe in dataframe.groupby(by=group):\n",
    "        rows = [row for _, row in dataframe.iterrows()]\n",
    "        for i, row in enumerate(rows):\n",
    "            for row2 in rows[i+1:]:\n",
    "                if row[first] == row2[second] and row[second] == row2[first]:\n",
    "                    print(\"DUPLICATED ROW\")\n",
    "                    print(g)\n",
    "                    print(row)\n",
    "                    print(row2)\n",
    "\n",
    "                \n",
    "def extract_propositions(params: dict):\n",
    "    corpus_path = Path(params['corpus_path'])\n",
    "    \n",
    "    parser = UnifiedParser()\n",
    "    \n",
    "    names = [\n",
    "        \"dev\", \n",
    "        \"test\",\n",
    "        \"train\",\n",
    "    ]\n",
    "    \n",
    "    relation_tags = set()\n",
    "    proposition_tags = set()\n",
    "    \n",
    "    source_vocabulary = set()\n",
    "    target_vocabulary = set()\n",
    "    \n",
    "    # Max amount of propositions in a document\n",
    "    max_amount_source_in_doc = 0\n",
    "    max_amount_target_in_doc = 0\n",
    "    \n",
    "    # Max amount of tokens in a proposition\n",
    "    max_size_in_source_prop = 0\n",
    "    max_size_in_target_prop = 0\n",
    "    \n",
    "    for name in names:\n",
    "        \n",
    "        proposition_dict = parser.parse_dir(corpus_path / name)\n",
    "        \n",
    "        current_source_arg_units = {\n",
    "            'prop_id': [], \n",
    "            'prop_type': [], \n",
    "            'prop_text': [], \n",
    "            'file_key': []\n",
    "        }\n",
    "        current_target_arg_units = {\n",
    "            'prop_id': [], \n",
    "            'prop_type': [], \n",
    "            'prop_text': [], \n",
    "            'file_key': []\n",
    "        }\n",
    "        current_relations = {\n",
    "            'prop_id_source': [], \n",
    "            'prop_id_target': [], \n",
    "            'relation_type': [], \n",
    "            'distance': [], \n",
    "            'file_key': []\n",
    "        }\n",
    "\n",
    "        for key, (args_unit, relations, _) in proposition_dict.items():\n",
    "            args_unit['file_key'] = [key for _ in range(len(args_unit))]\n",
    "            args_unit = args_unit[['prop_id', 'prop_type', 'prop_text', 'file_key']]\n",
    "            \n",
    "            \n",
    "            relations = relations[['prop_id_source', 'prop_id_target', 'relation_type']]\n",
    "            relations['distance'] = relations.aggregate(lambda x: x['prop_id_target']-x['prop_id_source'], axis=1)\n",
    "            relations['file_key'] = relations.aggregate(lambda x: key, axis=1)\n",
    "            \n",
    "            source_prop = args_unit[args_unit['prop_id'].isin(relations['prop_id_source'])]\n",
    "            target_prop = args_unit[args_unit['prop_id'].isin(relations['prop_id_target'])]\n",
    "            \n",
    "            source_vocabulary.update([t for s in source_prop['prop_text'] for t in s.split()])\n",
    "            target_vocabulary.update([t for s in target_prop['prop_text'] for t in s.split()])\n",
    "            \n",
    "            max_size_in_source_prop = max(max_size_in_source_prop, source_prop.aggregate(lambda x: len(x['prop_text'].split()), axis=1).max())\n",
    "            max_size_in_target_prop = max(max_size_in_target_prop, target_prop.aggregate(lambda x: len(x['prop_text'].split()), axis=1).max())\n",
    "            \n",
    "            \n",
    "            max_amount_source_in_doc = max(max_amount_source_in_doc, len(relations['prop_id_source'].drop_duplicates()))\n",
    "            max_amount_target_in_doc = max(max_amount_target_in_doc, len(relations['prop_id_target'].drop_duplicates()))\n",
    "            \n",
    "            current_source_arg_units['prop_id'].extend(source_prop['prop_id'])\n",
    "            current_source_arg_units['prop_type'].extend(source_prop['prop_type'])\n",
    "            current_source_arg_units['prop_text'].extend(source_prop['prop_text'])\n",
    "            current_source_arg_units['file_key'].extend(source_prop['file_key'])\n",
    "            \n",
    "            current_target_arg_units['prop_id'].extend(target_prop['prop_id'])\n",
    "            current_target_arg_units['prop_type'].extend(target_prop['prop_type'])\n",
    "            current_target_arg_units['prop_text'].extend(target_prop['prop_text'])\n",
    "            current_target_arg_units['file_key'].extend(target_prop['file_key'])\n",
    "            \n",
    "            current_relations['prop_id_source'].extend(relations['prop_id_source'])\n",
    "            current_relations['prop_id_target'].extend(relations['prop_id_target'])\n",
    "            current_relations['relation_type'].extend(relations['relation_type'])\n",
    "            current_relations['distance'].extend(relations['distance'])\n",
    "            current_relations['file_key'].extend(relations['file_key'])\n",
    "\n",
    "            \n",
    "        # Add Inverse Relations\n",
    "        inverse_relations = {\n",
    "            'prop_id_source': current_relations['prop_id_target'].copy(),\n",
    "            'prop_id_target': current_relations['prop_id_source'].copy(),\n",
    "            'relation_type': [relation_type + \"_Inverse\" for relation_type in current_relations['relation_type']],\n",
    "            'distance': [-distance for distance in current_relations['distance']],\n",
    "            'file_key': current_relations['file_key'].copy(),\n",
    "        }\n",
    "        current_relations['prop_id_source'].extend(inverse_relations['prop_id_source'])\n",
    "        current_relations['prop_id_target'].extend(inverse_relations['prop_id_target'])\n",
    "        current_relations['relation_type'].extend(inverse_relations['relation_type'])\n",
    "        current_relations['distance'].extend(inverse_relations['distance'])\n",
    "        current_relations['file_key'].extend(inverse_relations['file_key'])\n",
    "        \n",
    "        \n",
    "        current_relations = pandas.DataFrame(current_relations)\n",
    "        current_source_arg_units = pandas.DataFrame(current_source_arg_units)\n",
    "        current_target_arg_units = pandas.DataFrame(current_target_arg_units)\n",
    "        \n",
    "        # Sanity checks\n",
    "#         print(\"NEGATIVE PROP IDs\")\n",
    "#         print(\"TARGET < 0\", current_target_arg_units[current_target_arg_units['prop_id'] < 0])\n",
    "#         print(\"SOURCE < 0\", current_source_arg_units[current_source_arg_units['prop_id'] < 0])\n",
    "#         print(\"RELATION TARGET < 0:\", list(current_relations[current_relations['prop_id_target'] < 0]['file_key']))\n",
    "#         print(\"RELATION SOURCE < 0:\", list(current_relations[current_relations['prop_id_source'] < 0]['file_key']))\n",
    "#         def check_max(s_t_data, data, max_column, compare_to, title):\n",
    "#             for file, df in data.groupby(by='file_key'):\n",
    "#                 maxim = s_t_data[s_t_data['file_key'] == file][max_column].max()\n",
    "#                 print(title, maxim, file)\n",
    "#                 print(df[df[compare_to] > maxim])\n",
    "#         check_max(current_target_arg_units, current_relations, 'prop_id', 'prop_id_target', \"RELATION TARGET > max\")\n",
    "#         check_max(current_source_arg_units, current_relations, 'prop_id', 'prop_id_source', \"RELATION SOURCE > max\")\n",
    "#         print(\"BEFORE\")\n",
    "#         find_duplicates(current_relations, 'prop_id_source', 'prop_id_target', 'file_key')\n",
    "\n",
    "        params[f'{name}_source_propositions'] = current_source_arg_units\n",
    "        params[f'{name}_target_propositions'] = current_target_arg_units\n",
    "        params[f'{name}_relations'] = current_relations\n",
    "\n",
    "        print(name, \"relations\", len(current_relations))\n",
    "        print(name, \"source argumentative units\", len(current_source_arg_units))\n",
    "        print(name, \"target argumentative units\", len(current_target_arg_units))\n",
    "\n",
    "        relation_tags.update(current_relations['relation_type'])\n",
    "        proposition_tags.update(current_source_arg_units['prop_type'])\n",
    "        proposition_tags.update(current_target_arg_units['prop_type'])\n",
    "    \n",
    "\n",
    "    vocabulary = source_vocabulary.union(target_vocabulary)\n",
    "    params['vocabulary'] = vocabulary\n",
    "    print(\"Vocab size\", len(vocabulary))\n",
    "    \n",
    "    relation_tags = list(relation_tags)\n",
    "    proposition_tags = list(proposition_tags)\n",
    "    print(\"Relation tags\", relation_tags)\n",
    "    print(\"Proposition tags\", proposition_tags)\n",
    "    params['relation_tags'] = relation_tags\n",
    "    params['proposition_tags'] = proposition_tags\n",
    "    \n",
    "    max_size_prop = max(max_size_in_source_prop, max_size_in_target_prop)\n",
    "    max_amount_doc = max(max_amount_source_in_doc, max_amount_target_in_doc)\n",
    "    params['max_size_prop'] = max_size_prop\n",
    "    params['max_amount_doc'] = max_amount_doc\n",
    "    \n",
    "    print('max_size_prop', max_size_prop)\n",
    "    print('max_amount_doc', max_amount_doc)\n",
    "\n",
    "    # Vectorizers\n",
    "    sequence_vectorizer = layers.TextVectorization(\n",
    "        output_mode = \"int\",\n",
    "        max_tokens = len(vocabulary) + 2, # Plus PAD and UNK\n",
    "        output_sequence_length = int(max_size_prop),\n",
    "        standardize = params['sequence_standardize'],\n",
    "        split = params['sequence_split']\n",
    "    )\n",
    "    sequence_vectorizer.adapt(pandas.concat([\n",
    "        params['train_source_propositions'],\n",
    "        params['train_target_propositions'],\n",
    "    ], ignore_index=True)['prop_text'])\n",
    "    params['sequence_vectorizer'] = sequence_vectorizer\n",
    "    \n",
    "    relation_tag_vectorizer = layers.TextVectorization(\n",
    "        output_mode = \"int\",\n",
    "        max_tokens = len(relation_tags) + 2, # Plus PAD and UNK\n",
    "        output_sequence_length = 1,\n",
    "        standardize = None,\n",
    "        split = None\n",
    "    )\n",
    "    relation_tag_vectorizer.adapt(relation_tags)\n",
    "    params['relation_tag_vectorizer'] = relation_tag_vectorizer\n",
    "    \n",
    "    proposition_tag_vectorizer = layers.TextVectorization(\n",
    "        output_mode = \"int\",\n",
    "        max_tokens = len(proposition_tags) + 2, # Plus PAD and UNK\n",
    "        output_sequence_length = 1,\n",
    "        standardize = None,\n",
    "        split = None\n",
    "    )\n",
    "    proposition_tag_vectorizer.adapt(proposition_tags)\n",
    "    params['proposition_tag_vectorizer'] = proposition_tag_vectorizer\n",
    "    \n",
    "    # One-Hot Encoders\n",
    "    relation_encoder = layers.CategoryEncoding(\n",
    "        num_tokens=len(relation_tag_vectorizer.get_vocabulary()), # Plus PAD and UNK\n",
    "        output_mode=\"one_hot\",\n",
    "    )\n",
    "    params['relation_encoder'] = relation_encoder\n",
    "    \n",
    "    proposition_encoder = layers.CategoryEncoding(\n",
    "        num_tokens=len(proposition_tag_vectorizer.get_vocabulary()), # Plus PAD and UNK\n",
    "        output_mode=\"one_hot\",\n",
    "    )\n",
    "    params['proposition_encoder'] = proposition_encoder\n",
    "    \n",
    "    \n",
    "extract_propositions(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dataset_statistics(params: dict):\n",
    "    \n",
    "    def plot_relation_info(relation_df: pandas.DataFrame):\n",
    "        relation_df = relation_df[~relation_df['relation_type'].str.endswith(\"_Inverse\")]\n",
    "        bins = set(relation_df['distance'])\n",
    "        relation_df['distance'].hist(bins=len(bins))\n",
    "        plt.title(\"Relation distances\")\n",
    "        plt.show()\n",
    "    \n",
    "    for name in ['train']:\n",
    "        current_relations = params[f'{name}_relations']\n",
    "\n",
    "        plot_relation_info(current_relations)\n",
    "    \n",
    "dataset_statistics(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove Embedding Matrix Found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def creating_glove_embeddings(params: dict):\n",
    "    \n",
    "    if Path(params[\"glove_path\"]).exists():\n",
    "        print(\"Glove Embedding Matrix Found\")\n",
    "        embedding_matrix = np.load(params[\"glove_path\"])[\"embeddings\"]\n",
    "        params['embedding_matrix'] = embedding_matrix\n",
    "        return\n",
    "    \n",
    "    # Loading Glove\n",
    "    hits = 0\n",
    "    embedding_dim = params['dim']\n",
    "    word_to_index = dict(map(lambda x: (x[1], x[0]), enumerate(params['sequence_vectorizer'].get_vocabulary())))\n",
    "    num_tokens = len(word_to_index) # Plus padding and unknown \n",
    "\n",
    "    embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "    with Path(params[\"glove_raw_path\"]).open() as f:\n",
    "        for line_idx, line in enumerate(f):\n",
    "            if line_idx % 100000 == 0:\n",
    "                print('- At line {}'.format(line_idx))\n",
    "            line = line.strip().split()\n",
    "            if len(line) != 300 + 1:\n",
    "                continue\n",
    "            word = line[0]\n",
    "            embedding = line[1:]\n",
    "            if word in word_to_index:\n",
    "                hits += 1\n",
    "                word_idx = word_to_index[word]\n",
    "                embedding_matrix[word_idx] = embedding\n",
    "                \n",
    "    print('- Done. Found {} vectors for {} words'.format(hits, num_tokens - 2))\n",
    "    \n",
    "    params['embedding_matrix'] = embedding_matrix\n",
    "    Path(params[\"glove_path\"], \"..\").resolve().mkdir(exist_ok=True, parents=True)\n",
    "    np.savez_compressed(params[\"glove_path\"], embeddings=embedding_matrix)\n",
    "\n",
    "creating_glove_embeddings(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Dataframe Found\n",
      "55534\n",
      "dev Counter({'': 652, 'supports': 304, 'supports_Inverse': 304, 'attacks': 22, 'attacks_Inverse': 22})\n",
      "test Counter({'': 1618, 'supports': 767, 'supports_Inverse': 767, 'attacks_Inverse': 42, 'attacks': 42})\n",
      "train Counter({'': 5390, 'supports': 2540, 'supports_Inverse': 2540, 'attacks_Inverse': 155, 'attacks': 155})\n"
     ]
    }
   ],
   "source": [
    "# Encode Dataset\n",
    "\n",
    "def encode_distance(distance, encode_size):\n",
    "    \"\"\"\n",
    "    return: Tensor with the encoded distance\n",
    "    \"\"\"\n",
    "    middle = encode_size // 2\n",
    "\n",
    "    abs_distance = tf.cast(tf.abs(distance), dtype=\"int32\") \n",
    "    zeros = tf.zeros((tf.maximum(1, abs_distance), middle))\n",
    "\n",
    "    to_sum = tf.concat([zeros, tf.eye(abs_distance, num_columns=middle)], axis=0)\n",
    "    distance_vec = tf.foldl(lambda x, y: tf.add(x, y), to_sum)\n",
    "\n",
    "    if distance < 0:\n",
    "        first_vec = tf.reverse(distance_vec, axis=[0])\n",
    "        second_vec = zeros[0]\n",
    "    else:\n",
    "        first_vec = zeros[0]\n",
    "        second_vec = distance_vec\n",
    "\n",
    "    return tf.concat([first_vec, second_vec], axis=0)\n",
    "\n",
    "\n",
    "def encode_datasets(params: dict):\n",
    "    sequence_vectorizer = params['sequence_vectorizer']\n",
    "    proposition_tag_vectorizer = params['proposition_tag_vectorizer']\n",
    "    relation_tag_vectorizer = params['relation_tag_vectorizer']\n",
    "    proposition_encoder = params['proposition_encoder']\n",
    "    relation_encoder = params['relation_encoder']\n",
    "    distance_encoding_bits = params['max_distance_encoded'] * 2\n",
    "    max_proposition_distance = params['max_proposition_distance']\n",
    "    non_related_max_proportion = params['non_related_max_proportion']\n",
    "\n",
    "    df_path = Path(params['export_path'], f'data_df_{max_proposition_distance}.pkl')\n",
    "    if df_path.exists():\n",
    "        data_dataframe = pandas.read_pickle(df_path)\n",
    "        print(\"Data Dataframe Found\")\n",
    "    else:\n",
    "        data_dataframe = pandas.DataFrame(\n",
    "            columns = [\n",
    "                'file_key', \n",
    "                'source_prop_id', \n",
    "                'target_prop_id', \n",
    "                'source_prop_text',\n",
    "                'target_prop_text',\n",
    "                'source_prop_type',\n",
    "                'target_prop_type',\n",
    "                'relation_type', \n",
    "                'distance',\n",
    "                'split',\n",
    "            ])\n",
    "\n",
    "        for split in ['dev', 'test', 'train']:\n",
    "\n",
    "            source_arg_units = params[f'{split}_source_propositions']\n",
    "            target_arg_units = params[f'{split}_target_propositions']\n",
    "            relations = params[f'{split}_relations']\n",
    "\n",
    "            all_arg_units = pandas.concat([source_arg_units, target_arg_units], ignore_index=True)\n",
    "            all_arg_units = all_arg_units.drop_duplicates()\n",
    "            all_arg_units = [(file, df) for file, df in all_arg_units.groupby(by='file_key')]\n",
    "            \n",
    "            for file_key, file_source_df in all_arg_units:\n",
    "                file_target_df = file_source_df.copy()\n",
    "                file_relations = relations[relations['file_key'] == file_key]\n",
    "\n",
    "                current_file_info = {\n",
    "                    'file_key': [], \n",
    "                    'source_prop_id': [],\n",
    "                    'target_prop_id': [],\n",
    "                    'source_prop_text': [],\n",
    "                    'target_prop_text': [],\n",
    "                    'source_prop_type': [],\n",
    "                    'target_prop_type': [],\n",
    "                    'relation_type': [],\n",
    "                    'distance': [],\n",
    "                    'split': [],\n",
    "                }\n",
    "                \n",
    "                for _, source_row in file_source_df.iterrows():\n",
    "                    source_id = source_row['prop_id']\n",
    "                    for _, target_row in file_target_df.iterrows():\n",
    "                        target_id = target_row['prop_id']\n",
    "\n",
    "                        # Same relations not allowed\n",
    "                        if source_id == target_id:\n",
    "                            continue\n",
    "\n",
    "                        distance = target_id - source_id\n",
    "                        # Distance is greater than the max alowed distance between propositions\n",
    "                        if abs(distance) > max_proposition_distance:\n",
    "                            continue\n",
    "\n",
    "\n",
    "                        source_target_relation = file_relations[(file_relations['prop_id_target'] == target_id) & (file_relations['prop_id_source'] == source_id)]\n",
    "                        \n",
    "                        if len(source_target_relation) == 0:\n",
    "                            # No related propositions\n",
    "                            relation_type = '' # No Relation\n",
    "                            distance = 0 # Mock Distance\n",
    "                            source_target_relation = pandas.concat([source_target_relation, pandas.DataFrame({\n",
    "                                'prop_id_source': [source_id],\n",
    "                                'prop_id_target': [target_id],\n",
    "                                'relation_type': [relation_type],\n",
    "                                'distance': [distance],\n",
    "                                'file_key': [file_key]\n",
    "                            })])\n",
    "                            \n",
    "                        if len(source_target_relation) > 1:\n",
    "                            print(\"WARNING: Multiple relation with single source-target pair\")\n",
    "                            print(source_target_relation)\n",
    "\n",
    "                        for _, relation_row in source_target_relation.iterrows():\n",
    "\n",
    "                            assert relation_row['distance'] == distance, f\"{relation_row['distance']} != {distance}\"\n",
    "\n",
    "                            # Adding data\n",
    "                            current_file_info['file_key'].append(file_key)\n",
    "                            current_file_info['source_prop_id'].append(source_id)\n",
    "                            current_file_info['target_prop_id'].append(target_id)\n",
    "                            current_file_info['source_prop_text'].append(source_row['prop_text'])\n",
    "                            current_file_info['target_prop_text'].append(target_row['prop_text'])\n",
    "                            current_file_info['source_prop_type'].append(source_row['prop_type'])\n",
    "                            current_file_info['target_prop_type'].append(target_row['prop_type'])\n",
    "                            current_file_info['relation_type'].append(relation_row['relation_type'])\n",
    "                            current_file_info['distance'].append(distance)\n",
    "                            current_file_info['split'].append(split)\n",
    "                    \n",
    "                current_file_info = pandas.DataFrame(current_file_info)\n",
    "                \n",
    "\n",
    "                data_dataframe = pandas.concat([data_dataframe, current_file_info], ignore_index=True)\n",
    "        data_dataframe.to_pickle(df_path)\n",
    "\n",
    "    params['raw_data_dataframe'] = data_dataframe\n",
    "    print(len(data_dataframe))\n",
    "    \n",
    "    # Encoding\n",
    "    for split, data_dataframe in data_dataframe.groupby(by=\"split\"):\n",
    "        \n",
    "        relation_counter = Counter(data_dataframe['relation_type'])\n",
    "        \n",
    "        non_related_proportion = relation_counter[''] / len(data_dataframe)\n",
    "        if non_related_proportion > non_related_max_proportion:\n",
    "            amount_to_drop = int((relation_counter[''] - non_related_max_proportion * len(data_dataframe)) / (1 - non_related_max_proportion))\n",
    "            index = list(data_dataframe[data_dataframe['relation_type'] == ''].index)\n",
    "            rand.shuffle(index)\n",
    "            \n",
    "            data_dataframe = data_dataframe.drop(index[:amount_to_drop])\n",
    "        \n",
    "        params[f'raw_{split}_data_dataframe'] = data_dataframe\n",
    "            \n",
    "        relation_counter = Counter(data_dataframe['relation_type'])\n",
    "        print(split, relation_counter)\n",
    "        \n",
    "        source_ds = tf.data.Dataset.from_tensor_slices(tf.constant(data_dataframe['source_prop_text'])).map(lambda x: sequence_vectorizer(x))\n",
    "        target_ds = tf.data.Dataset.from_tensor_slices(tf.constant(data_dataframe['target_prop_text'])).map(lambda x: sequence_vectorizer(x))\n",
    "        source_type_ds = tf.data.Dataset.from_tensor_slices(tf.constant(data_dataframe['source_prop_type'])).map(lambda x: proposition_encoder(proposition_tag_vectorizer([x])))\n",
    "        target_type_ds = tf.data.Dataset.from_tensor_slices(tf.constant(data_dataframe['target_prop_type'])).map(lambda x: proposition_encoder(proposition_tag_vectorizer([x])))\n",
    "        relation_type_ds = tf.data.Dataset.from_tensor_slices(tf.constant(data_dataframe['relation_type'])).map(lambda x: relation_encoder(relation_tag_vectorizer([x])))\n",
    "        distance_ds = tf.data.Dataset.from_tensor_slices(list(data_dataframe['distance'].to_numpy(dtype=int))).map(lambda x: encode_distance(x, distance_encoding_bits))\n",
    "        \n",
    "        # Order matters\n",
    "        input_ds = tf.data.Dataset.zip((source_ds, target_ds, distance_ds))\n",
    "        output_ds = tf.data.Dataset.zip((relation_type_ds, source_type_ds, target_type_ds))\n",
    "        \n",
    "        ds = tf.data.Dataset.zip((input_ds, output_ds))\n",
    "        \n",
    "        params[f\"{split}_ds\"] = ds\n",
    "\n",
    "        \n",
    "encode_datasets(params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "Two versions of the model can be buit. The difference is the presence or not of an attention layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_attention_0\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 70)]         0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 70)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 70, 300)      2242500     ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 70, 300)      2242500     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, 70, 300)     37250       ['embedding_1[0][0]']            \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 70, 300)     37250       ['embedding[0][0]']              \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 70, 300)      0           ['embedding_1[0][0]',            \n",
      "                                                                  'time_distributed_1[0][0]']     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 70, 300)      0           ['embedding[0][0]',              \n",
      "                                                                  'time_distributed[0][0]']       \n",
      "                                                                                                  \n",
      " model_2 (Functional)           (None, 70, 50)       15250       ['add[0][0]',                    \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " model_3 (Functional)           (None, 70, 25)       15200       ['model_2[0][0]',                \n",
      "                                                                  'model_2[1][0]']                \n",
      "                                                                                                  \n",
      " avg_query_target_0 (GlobalAver  (None, 25)          0           ['model_3[1][0]']                \n",
      " agePooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " avg_query_source_0 (GlobalAver  (None, 25)          0           ['model_3[0][0]']                \n",
      " agePooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " att_linearity_query_source_0 (  (None, 20)          520         ['avg_query_target_0[0][0]']     \n",
      " Dense)                                                                                           \n",
      "                                                                                                  \n",
      " att_linearity_query_target_0 (  (None, 20)          520         ['avg_query_source_0[0][0]']     \n",
      " Dense)                                                                                           \n",
      "                                                                                                  \n",
      " repeat_query_source_0 (RepeatV  (None, 70, 20)      0           ['att_linearity_query_source_0[0]\n",
      " ector)                                                          [0]']                            \n",
      "                                                                                                  \n",
      " att_K_source_0 (TimeDistribute  (None, 70, 20)      520         ['model_3[0][0]']                \n",
      " d)                                                                                               \n",
      "                                                                                                  \n",
      " repeat_query_target_0 (RepeatV  (None, 70, 20)      0           ['att_linearity_query_target_0[0]\n",
      " ector)                                                          [0]']                            \n",
      "                                                                                                  \n",
      " att_K_target_0 (TimeDistribute  (None, 70, 20)      520         ['model_3[1][0]']                \n",
      " d)                                                                                               \n",
      "                                                                                                  \n",
      " att_addition_source_0 (Add)    (None, 70, 20)       0           ['repeat_query_source_0[0][0]',  \n",
      "                                                                  'att_K_source_0[0][0]']         \n",
      "                                                                                                  \n",
      " att_addition_target_0 (Add)    (None, 70, 20)       0           ['repeat_query_target_0[0][0]',  \n",
      "                                                                  'att_K_target_0[0][0]']         \n",
      "                                                                                                  \n",
      " att_activation_source_0 (Activ  (None, 70, 20)      0           ['att_addition_source_0[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " att_activation_target_0 (Activ  (None, 70, 20)      0           ['att_addition_target_0[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " masking (Lambda)               (None, 70)           0           ['input_2[0][0]',                \n",
      "                                                                  'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " att_scores_source_0 (TimeDistr  (None, 70, 1)       21          ['att_activation_source_0[0][0]']\n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " att_scores_target_0 (TimeDistr  (None, 70, 1)       21          ['att_activation_target_0[0][0]']\n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " negative_mul (Lambda)          (None, 70)           0           ['masking[0][0]',                \n",
      "                                                                  'masking[1][0]']                \n",
      "                                                                                                  \n",
      " att_scores_flat_source_0 (Flat  (None, 70)          0           ['att_scores_source_0[0][0]']    \n",
      " ten)                                                                                             \n",
      "                                                                                                  \n",
      " att_scores_flat_target_0 (Flat  (None, 70)          0           ['att_scores_target_0[0][0]']    \n",
      " ten)                                                                                             \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " att_masked_addition_source_0 (  (None, 70)          0           ['negative_mul[0][0]',           \n",
      " Add)                                                             'att_scores_flat_source_0[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " att_masked_addition_target_0 (  (None, 70)          0           ['negative_mul[1][0]',           \n",
      " Add)                                                             'att_scores_flat_target_0[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " att_weights_source_0 (Activati  (None, 70)          0           ['att_masked_addition_source_0[0]\n",
      " on)                                                             [0]']                            \n",
      "                                                                                                  \n",
      " att_weights_target_0 (Activati  (None, 70)          0           ['att_masked_addition_target_0[0]\n",
      " on)                                                             [0]']                            \n",
      "                                                                                                  \n",
      " att_weights_reshape_source_0 (  (None, 70, 1)       0           ['att_weights_source_0[0][0]']   \n",
      " Reshape)                                                                                         \n",
      "                                                                                                  \n",
      " att_weights_reshape_target_0 (  (None, 70, 1)       0           ['att_weights_target_0[0][0]']   \n",
      " Reshape)                                                                                         \n",
      "                                                                                                  \n",
      " att_multiply_source_0 (Multipl  (None, 70, 50)      0           ['att_weights_reshape_source_0[0]\n",
      " y)                                                              [0]',                            \n",
      "                                                                  'model_2[0][0]']                \n",
      "                                                                                                  \n",
      " att_multiply_target_0 (Multipl  (None, 70, 50)      0           ['att_weights_reshape_target_0[0]\n",
      " y)                                                              [0]',                            \n",
      "                                                                  'model_2[1][0]']                \n",
      "                                                                                                  \n",
      " att_cv_source_0 (Lambda)       (None, 50)           0           ['att_multiply_source_0[0][0]']  \n",
      "                                                                                                  \n",
      " att_cv_target_0 (Lambda)       (None, 50)           0           ['att_multiply_target_0[0][0]']  \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 110)          0           ['att_cv_source_0[0][0]',        \n",
      "                                                                  'att_cv_target_0[0][0]',        \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 110)         440         ['concatenate[0][0]']            \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 110)          0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 20)           2220        ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 20)          80          ['dense_9[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 20)           0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 20)           0           ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 50)           1050        ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 50)          200         ['dense_10[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 50)           0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 50)           0           ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 20)           1020        ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 20)           0           ['dense_9[0][0]',                \n",
      "                                                                  'dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 20)          80          ['add_2[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 20)           0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 20)           0           ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 50)           1050        ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 50)          200         ['dense_12[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 50)           0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 50)           0           ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 20)           1020        ['activation_11[0][0]']          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 20)           0           ['add_2[0][0]',                  \n",
      "                                                                  'dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 20)          80          ['add_3[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 20)           0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " relation_0 (Dense)             (None, 6)            126         ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " source_0 (Dense)               (None, 5)            105         ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " target_0 (Dense)               (None, 5)            105         ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,599,848\n",
      "Trainable params: 112,408\n",
      "Non-trainable params: 4,487,440\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_attention_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 70)]         0           []                               \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)          [(None, 70)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 70, 300)      2242500     ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 70, 300)      2242500     ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " time_distributed_4 (TimeDistri  (None, 70, 300)     37250       ['embedding_3[0][0]']            \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_distributed_3 (TimeDistri  (None, 70, 300)     37250       ['embedding_2[0][0]']            \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 70, 300)      0           ['embedding_3[0][0]',            \n",
      "                                                                  'time_distributed_4[0][0]']     \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 70, 300)      0           ['embedding_2[0][0]',            \n",
      "                                                                  'time_distributed_3[0][0]']     \n",
      "                                                                                                  \n",
      " model_6 (Functional)           (None, 70, 50)       15250       ['add_4[0][0]',                  \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " model_7 (Functional)           (None, 70, 25)       15200       ['model_6[0][0]',                \n",
      "                                                                  'model_6[1][0]']                \n",
      "                                                                                                  \n",
      " avg_query_target_1 (GlobalAver  (None, 25)          0           ['model_7[1][0]']                \n",
      " agePooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " avg_query_source_1 (GlobalAver  (None, 25)          0           ['model_7[0][0]']                \n",
      " agePooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " att_linearity_query_source_1 (  (None, 20)          520         ['avg_query_target_1[0][0]']     \n",
      " Dense)                                                                                           \n",
      "                                                                                                  \n",
      " att_linearity_query_target_1 (  (None, 20)          520         ['avg_query_source_1[0][0]']     \n",
      " Dense)                                                                                           \n",
      "                                                                                                  \n",
      " repeat_query_source_1 (RepeatV  (None, 70, 20)      0           ['att_linearity_query_source_1[0]\n",
      " ector)                                                          [0]']                            \n",
      "                                                                                                  \n",
      " att_K_source_1 (TimeDistribute  (None, 70, 20)      520         ['model_7[0][0]']                \n",
      " d)                                                                                               \n",
      "                                                                                                  \n",
      " repeat_query_target_1 (RepeatV  (None, 70, 20)      0           ['att_linearity_query_target_1[0]\n",
      " ector)                                                          [0]']                            \n",
      "                                                                                                  \n",
      " att_K_target_1 (TimeDistribute  (None, 70, 20)      520         ['model_7[1][0]']                \n",
      " d)                                                                                               \n",
      "                                                                                                  \n",
      " att_addition_source_1 (Add)    (None, 70, 20)       0           ['repeat_query_source_1[0][0]',  \n",
      "                                                                  'att_K_source_1[0][0]']         \n",
      "                                                                                                  \n",
      " att_addition_target_1 (Add)    (None, 70, 20)       0           ['repeat_query_target_1[0][0]',  \n",
      "                                                                  'att_K_target_1[0][0]']         \n",
      "                                                                                                  \n",
      " att_activation_source_1 (Activ  (None, 70, 20)      0           ['att_addition_source_1[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " att_activation_target_1 (Activ  (None, 70, 20)      0           ['att_addition_target_1[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " masking (Lambda)               (None, 70)           0           ['input_9[0][0]',                \n",
      "                                                                  'input_11[0][0]']               \n",
      "                                                                                                  \n",
      " att_scores_source_1 (TimeDistr  (None, 70, 1)       21          ['att_activation_source_1[0][0]']\n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " att_scores_target_1 (TimeDistr  (None, 70, 1)       21          ['att_activation_target_1[0][0]']\n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " negative_mul (Lambda)          (None, 70)           0           ['masking[0][0]',                \n",
      "                                                                  'masking[1][0]']                \n",
      "                                                                                                  \n",
      " att_scores_flat_source_1 (Flat  (None, 70)          0           ['att_scores_source_1[0][0]']    \n",
      " ten)                                                                                             \n",
      "                                                                                                  \n",
      " att_scores_flat_target_1 (Flat  (None, 70)          0           ['att_scores_target_1[0][0]']    \n",
      " ten)                                                                                             \n",
      "                                                                                                  \n",
      " att_masked_addition_source_1 (  (None, 70)          0           ['negative_mul[0][0]',           \n",
      " Add)                                                             'att_scores_flat_source_1[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " att_masked_addition_target_1 (  (None, 70)          0           ['negative_mul[1][0]',           \n",
      " Add)                                                             'att_scores_flat_target_1[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " att_weights_source_1 (Activati  (None, 70)          0           ['att_masked_addition_source_1[0]\n",
      " on)                                                             [0]']                            \n",
      "                                                                                                  \n",
      " att_weights_target_1 (Activati  (None, 70)          0           ['att_masked_addition_target_1[0]\n",
      " on)                                                             [0]']                            \n",
      "                                                                                                  \n",
      " att_weights_reshape_source_1 (  (None, 70, 1)       0           ['att_weights_source_1[0][0]']   \n",
      " Reshape)                                                                                         \n",
      "                                                                                                  \n",
      " att_weights_reshape_target_1 (  (None, 70, 1)       0           ['att_weights_target_1[0][0]']   \n",
      " Reshape)                                                                                         \n",
      "                                                                                                  \n",
      " att_multiply_source_1 (Multipl  (None, 70, 50)      0           ['att_weights_reshape_source_1[0]\n",
      " y)                                                              [0]',                            \n",
      "                                                                  'model_6[0][0]']                \n",
      "                                                                                                  \n",
      " att_multiply_target_1 (Multipl  (None, 70, 50)      0           ['att_weights_reshape_target_1[0]\n",
      " y)                                                              [0]',                            \n",
      "                                                                  'model_6[1][0]']                \n",
      "                                                                                                  \n",
      " att_cv_source_1 (Lambda)       (None, 50)           0           ['att_multiply_source_1[0][0]']  \n",
      "                                                                                                  \n",
      " att_cv_target_1 (Lambda)       (None, 50)           0           ['att_multiply_target_1[0][0]']  \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 110)          0           ['att_cv_source_1[0][0]',        \n",
      "                                                                  'att_cv_target_1[0][0]',        \n",
      "                                                                  'input_8[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 110)         440         ['concatenate_1[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 110)          0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 20)           2220        ['dropout_22[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 20)          80          ['dense_23[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 20)           0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 20)           0           ['dropout_23[0][0]']             \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 50)           1050        ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 50)          200         ['dense_24[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 50)           0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 50)           0           ['dropout_24[0][0]']             \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 20)           1020        ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 20)           0           ['dense_23[0][0]',               \n",
      "                                                                  'dense_25[0][0]']               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 20)          80          ['add_6[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 20)           0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 20)           0           ['dropout_25[0][0]']             \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 50)           1050        ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 50)          200         ['dense_26[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 50)           0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 50)           0           ['dropout_26[0][0]']             \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 20)           1020        ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 20)           0           ['add_6[0][0]',                  \n",
      "                                                                  'dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 20)          80          ['add_7[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)           (None, 20)           0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " relation_1 (Dense)             (None, 6)            126         ['dropout_27[0][0]']             \n",
      "                                                                                                  \n",
      " source_1 (Dense)               (None, 5)            105         ['dropout_27[0][0]']             \n",
      "                                                                                                  \n",
      " target_1 (Dense)               (None, 5)            105         ['dropout_27[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,599,848\n",
      "Trainable params: 112,408\n",
      "Non-trainable params: 4,487,440\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_attention_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_16 (InputLayer)          [(None, 70)]         0           []                               \n",
      "                                                                                                  \n",
      " input_18 (InputLayer)          [(None, 70)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, 70, 300)      2242500     ['input_18[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 70, 300)      2242500     ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " time_distributed_7 (TimeDistri  (None, 70, 300)     37250       ['embedding_5[0][0]']            \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_distributed_6 (TimeDistri  (None, 70, 300)     37250       ['embedding_4[0][0]']            \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 70, 300)      0           ['embedding_5[0][0]',            \n",
      "                                                                  'time_distributed_7[0][0]']     \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 70, 300)      0           ['embedding_4[0][0]',            \n",
      "                                                                  'time_distributed_6[0][0]']     \n",
      "                                                                                                  \n",
      " model_10 (Functional)          (None, 70, 50)       15250       ['add_8[0][0]',                  \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " model_11 (Functional)          (None, 70, 25)       15200       ['model_10[0][0]',               \n",
      "                                                                  'model_10[1][0]']               \n",
      "                                                                                                  \n",
      " avg_query_target_2 (GlobalAver  (None, 25)          0           ['model_11[1][0]']               \n",
      " agePooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " avg_query_source_2 (GlobalAver  (None, 25)          0           ['model_11[0][0]']               \n",
      " agePooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " att_linearity_query_source_2 (  (None, 20)          520         ['avg_query_target_2[0][0]']     \n",
      " Dense)                                                                                           \n",
      "                                                                                                  \n",
      " att_linearity_query_target_2 (  (None, 20)          520         ['avg_query_source_2[0][0]']     \n",
      " Dense)                                                                                           \n",
      "                                                                                                  \n",
      " repeat_query_source_2 (RepeatV  (None, 70, 20)      0           ['att_linearity_query_source_2[0]\n",
      " ector)                                                          [0]']                            \n",
      "                                                                                                  \n",
      " att_K_source_2 (TimeDistribute  (None, 70, 20)      520         ['model_11[0][0]']               \n",
      " d)                                                                                               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " repeat_query_target_2 (RepeatV  (None, 70, 20)      0           ['att_linearity_query_target_2[0]\n",
      " ector)                                                          [0]']                            \n",
      "                                                                                                  \n",
      " att_K_target_2 (TimeDistribute  (None, 70, 20)      520         ['model_11[1][0]']               \n",
      " d)                                                                                               \n",
      "                                                                                                  \n",
      " att_addition_source_2 (Add)    (None, 70, 20)       0           ['repeat_query_source_2[0][0]',  \n",
      "                                                                  'att_K_source_2[0][0]']         \n",
      "                                                                                                  \n",
      " att_addition_target_2 (Add)    (None, 70, 20)       0           ['repeat_query_target_2[0][0]',  \n",
      "                                                                  'att_K_target_2[0][0]']         \n",
      "                                                                                                  \n",
      " att_activation_source_2 (Activ  (None, 70, 20)      0           ['att_addition_source_2[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " att_activation_target_2 (Activ  (None, 70, 20)      0           ['att_addition_target_2[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " masking (Lambda)               (None, 70)           0           ['input_16[0][0]',               \n",
      "                                                                  'input_18[0][0]']               \n",
      "                                                                                                  \n",
      " att_scores_source_2 (TimeDistr  (None, 70, 1)       21          ['att_activation_source_2[0][0]']\n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " att_scores_target_2 (TimeDistr  (None, 70, 1)       21          ['att_activation_target_2[0][0]']\n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " negative_mul (Lambda)          (None, 70)           0           ['masking[0][0]',                \n",
      "                                                                  'masking[1][0]']                \n",
      "                                                                                                  \n",
      " att_scores_flat_source_2 (Flat  (None, 70)          0           ['att_scores_source_2[0][0]']    \n",
      " ten)                                                                                             \n",
      "                                                                                                  \n",
      " att_scores_flat_target_2 (Flat  (None, 70)          0           ['att_scores_target_2[0][0]']    \n",
      " ten)                                                                                             \n",
      "                                                                                                  \n",
      " att_masked_addition_source_2 (  (None, 70)          0           ['negative_mul[0][0]',           \n",
      " Add)                                                             'att_scores_flat_source_2[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " att_masked_addition_target_2 (  (None, 70)          0           ['negative_mul[1][0]',           \n",
      " Add)                                                             'att_scores_flat_target_2[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " att_weights_source_2 (Activati  (None, 70)          0           ['att_masked_addition_source_2[0]\n",
      " on)                                                             [0]']                            \n",
      "                                                                                                  \n",
      " att_weights_target_2 (Activati  (None, 70)          0           ['att_masked_addition_target_2[0]\n",
      " on)                                                             [0]']                            \n",
      "                                                                                                  \n",
      " att_weights_reshape_source_2 (  (None, 70, 1)       0           ['att_weights_source_2[0][0]']   \n",
      " Reshape)                                                                                         \n",
      "                                                                                                  \n",
      " att_weights_reshape_target_2 (  (None, 70, 1)       0           ['att_weights_target_2[0][0]']   \n",
      " Reshape)                                                                                         \n",
      "                                                                                                  \n",
      " att_multiply_source_2 (Multipl  (None, 70, 50)      0           ['att_weights_reshape_source_2[0]\n",
      " y)                                                              [0]',                            \n",
      "                                                                  'model_10[0][0]']               \n",
      "                                                                                                  \n",
      " att_multiply_target_2 (Multipl  (None, 70, 50)      0           ['att_weights_reshape_target_2[0]\n",
      " y)                                                              [0]',                            \n",
      "                                                                  'model_10[1][0]']               \n",
      "                                                                                                  \n",
      " att_cv_source_2 (Lambda)       (None, 50)           0           ['att_multiply_source_2[0][0]']  \n",
      "                                                                                                  \n",
      " att_cv_target_2 (Lambda)       (None, 50)           0           ['att_multiply_target_2[0][0]']  \n",
      "                                                                                                  \n",
      " input_15 (InputLayer)          [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 110)          0           ['att_cv_source_2[0][0]',        \n",
      "                                                                  'att_cv_target_2[0][0]',        \n",
      "                                                                  'input_15[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 110)         440         ['concatenate_2[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_36 (Dropout)           (None, 110)          0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " dense_37 (Dense)               (None, 20)           2220        ['dropout_36[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 20)          80          ['dense_37[0][0]']               \n",
      " ormalization)                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 20)           0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 20)           0           ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      " dense_38 (Dense)               (None, 50)           1050        ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 50)          200         ['dense_38[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 50)           0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 50)           0           ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 20)           1020        ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 20)           0           ['dense_37[0][0]',               \n",
      "                                                                  'dense_39[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 20)          80          ['add_10[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)           (None, 20)           0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 20)           0           ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " dense_40 (Dense)               (None, 50)           1050        ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 50)          200         ['dense_40[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_40 (Dropout)           (None, 50)           0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 50)           0           ['dropout_40[0][0]']             \n",
      "                                                                                                  \n",
      " dense_41 (Dense)               (None, 20)           1020        ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 20)           0           ['add_10[0][0]',                 \n",
      "                                                                  'dense_41[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 20)          80          ['add_11[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_41 (Dropout)           (None, 20)           0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " relation_2 (Dense)             (None, 6)            126         ['dropout_41[0][0]']             \n",
      "                                                                                                  \n",
      " source_2 (Dense)               (None, 5)            105         ['dropout_41[0][0]']             \n",
      "                                                                                                  \n",
      " target_2 (Dense)               (None, 5)            105         ['dropout_41[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,599,848\n",
      "Trainable params: 112,408\n",
      "Non-trainable params: 4,487,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build Model\n",
    "\n",
    "def build_model(params: dict):\n",
    "    linear_embedders_dims = params['linear_embedders_dims'] # [50, 50, 50, 300]\n",
    "    max_sequence_size = params['max_size_prop']\n",
    "    words_amount = len(params['sequence_vectorizer'].get_vocabulary()) # Plus UNK and Pad\n",
    "    embedding_dim = params['dim']\n",
    "    embedding_matrix = params['embedding_matrix']\n",
    "    regularizer_weight = params['regularizer_weight']\n",
    "    dropout = params['dropout']\n",
    "    final_embedding_dimension = params['encoder_dense_units']\n",
    "    final_layer_size = params['final_size']\n",
    "    pool_size = params['encoder_pool_size']\n",
    "    distance_encoding_bits = params['max_distance_encoded'] * 2\n",
    "    lstm_units = params['lstm_units']\n",
    "    res_size = params['residual_size']\n",
    "    relation_amount = len(params['relation_tag_vectorizer'].get_vocabulary()) # Plus UNK and Pad\n",
    "    proposition_tag_amount = len(params['proposition_tag_vectorizer'].get_vocabulary()) # Plus UNK and Pad\n",
    "    with_attention = params['with_attention']\n",
    "    ensemble_amount = params['ensemble_amount']\n",
    "    \n",
    "    def build_embedder(max_sequence_size, words_amount, embedding_dim, embedding_matrix, linear_layers_dims, regularizer_weight, dropout):\n",
    "        \"\"\"\n",
    "        Builds a proposition embedder\n",
    "        \"\"\"\n",
    "        \n",
    "        # Input layer\n",
    "        int_sequence_input = keras.Input(\n",
    "            shape=(max_sequence_size,), \n",
    "            dtype=\"int64\"\n",
    "        )\n",
    "\n",
    "        # Embedding layer, convert an index vector into a embedding vector, by accessing embedding_matrix\n",
    "        embedding_layer = layers.Embedding(\n",
    "            words_amount,\n",
    "            embedding_dim,\n",
    "            embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "            trainable=False,\n",
    "            input_length=max_sequence_size,\n",
    "        )\n",
    "\n",
    "        initial_layer = model_layers = embedding_layer(int_sequence_input)\n",
    "\n",
    "        def get_linear_layer(dense_dim, linear_layer=None):\n",
    "            \"\"\"\n",
    "            Creates a single dense layer for the embedder\n",
    "            \"\"\"\n",
    "            \n",
    "            if linear_layer is None:\n",
    "                input_vec = keras.Input(shape=(embedding_dim,))\n",
    "            else:\n",
    "                input_vec = linear_layer\n",
    "            \n",
    "            linear_layer = layers.Dense(\n",
    "                units=dense_dim,\n",
    "                activation=None,\n",
    "                kernel_initializer='he_normal',\n",
    "                kernel_regularizer=keras.regularizers.l2(regularizer_weight),\n",
    "                bias_regularizer=keras.regularizers.l2(regularizer_weight)\n",
    "            )(input_vec)\n",
    "            \n",
    "            linear_layer = layers.BatchNormalization()(linear_layer)\n",
    "            linear_layer = layers.Dropout(dropout)(linear_layer)\n",
    "            linear_layer = layers.Activation('relu')(linear_layer)\n",
    "            return input_vec, linear_layer\n",
    "        \n",
    "        # Linear transformation\n",
    "        linear_input, linear_layer = get_linear_layer(linear_layers_dims[0])\n",
    "        for dim in linear_layers_dims[1:]:\n",
    "            _, linear_layer = get_linear_layer(dim, linear_layer)\n",
    "        linear_layer = keras.Model(inputs=linear_input, outputs=linear_layer)\n",
    "        \n",
    "        # Apply linear_layer to each word embedding\n",
    "        model_layers = layers.TimeDistributed(linear_layer)(model_layers)\n",
    "        \n",
    "        # Residual connection\n",
    "        model_layers = layers.Add()([initial_layer, model_layers])\n",
    "        \n",
    "        return int_sequence_input, model_layers\n",
    "    \n",
    "    def build_dense_encoder(max_sequence_size, embedding_dim, final_dimension, pool_size, regularizer_weight):\n",
    "        \n",
    "        # Input layer\n",
    "        embedding_inputs = keras.Input(\n",
    "            shape=(max_sequence_size, embedding_dim)\n",
    "        )\n",
    "        \n",
    "        encoder_layer = embedding_inputs\n",
    "        \n",
    "        linear_layer = layers.Dense(\n",
    "            units=final_dimension,\n",
    "            activation='relu',\n",
    "            kernel_regularizer=keras.regularizers.l2(regularizer_weight),\n",
    "            bias_regularizer=keras.regularizers.l2(regularizer_weight)\n",
    "        )\n",
    "        \n",
    "        # Apply linear_layer to each word embedding\n",
    "        encoder_layer = layers.TimeDistributed(linear_layer)(encoder_layer)\n",
    "        \n",
    "        # Average the words embeddings\n",
    "        encoder_layer = layers.AveragePooling1D(\n",
    "            pool_size=pool_size,\n",
    "        )(encoder_layer)\n",
    "    \n",
    "        encoder_layer = layers.BatchNormalization()(encoder_layer)\n",
    "    \n",
    "        return keras.Model(inputs=embedding_inputs, outputs=encoder_layer)\n",
    "    \n",
    "    def build_bilstm_encoder(sequence_size, encoded_dim, lstm_units, dropout, regularizer_weight, return_sequences):\n",
    "\n",
    "        # Input layer\n",
    "        embedding_inputs = keras.Input(\n",
    "            shape=(sequence_size, encoded_dim)\n",
    "        )\n",
    "        \n",
    "        bilstm_layer = layers.Bidirectional(\n",
    "            layers.LSTM(\n",
    "                units=lstm_units,\n",
    "                dropout=dropout,\n",
    "                recurrent_dropout=dropout,\n",
    "                kernel_regularizer=keras.regularizers.l2(regularizer_weight),\n",
    "                recurrent_regularizer=keras.regularizers.l2(regularizer_weight),\n",
    "                bias_regularizer=keras.regularizers.l2(regularizer_weight),\n",
    "                return_sequences=return_sequences,\n",
    "            ),\n",
    "            merge_mode='mul'\n",
    "        )(embedding_inputs)\n",
    "        \n",
    "        return keras.Model(inputs=embedding_inputs, outputs=bilstm_layer)\n",
    "    \n",
    "    def apply_resnet(input_layer, regularizer_weight, res_size, dropout):\n",
    "        prev_layer = input_layer\n",
    "        prev_block = prev_layer\n",
    "        \n",
    "        layers_dims = (2, 2)\n",
    "        blocks = layers_dims[0]\n",
    "        res_layers = layers_dims[1]\n",
    "\n",
    "        shape = int(np.shape(input_layer)[1])\n",
    "\n",
    "        for i in range(1, blocks + 1):\n",
    "            for j in range(1, res_layers):\n",
    "                prev_layer = layers.BatchNormalization()(prev_layer)\n",
    "\n",
    "                prev_layer = layers.Dropout(dropout)(prev_layer)\n",
    "\n",
    "                prev_layer = layers.Activation('relu')(prev_layer)\n",
    "\n",
    "                prev_layer = layers.Dense(\n",
    "                    units=res_size,\n",
    "                    activation=None,\n",
    "                    kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=keras.regularizers.l2(regularizer_weight),\n",
    "                    bias_regularizer=keras.regularizers.l2(regularizer_weight),\n",
    "                )(prev_layer)\n",
    "            \n",
    "            prev_layer = layers.BatchNormalization()(prev_layer)\n",
    "\n",
    "            prev_layer = layers.Dropout(dropout)(prev_layer)\n",
    "\n",
    "            prev_layer = layers.Activation('relu')(prev_layer)\n",
    "\n",
    "            prev_layer = layers.Dense(units=shape,\n",
    "                               activation=None,\n",
    "                               kernel_initializer='he_normal',\n",
    "                               kernel_regularizer=keras.regularizers.l2(regularizer_weight),\n",
    "                               bias_regularizer=keras.regularizers.l2(regularizer_weight),\n",
    "                               )(prev_layer)\n",
    "\n",
    "            prev_layer = layers.Add()([prev_block, prev_layer])\n",
    "            prev_block = prev_layer\n",
    "\n",
    "        return prev_block\n",
    "    \n",
    "    def create_single_model(index):\n",
    "        \"\"\"\n",
    "        Create a single model for the ensemble learning\n",
    "        \"\"\"\n",
    "        \n",
    "        input_distance = keras.Input(\n",
    "            shape=(distance_encoding_bits, )\n",
    "        )\n",
    "\n",
    "        input_source_embedder, source_embedder = build_embedder(\n",
    "            max_sequence_size, \n",
    "            words_amount, \n",
    "            embedding_dim, \n",
    "            embedding_matrix, \n",
    "            linear_embedders_dims, \n",
    "            regularizer_weight, \n",
    "            dropout\n",
    "        )\n",
    "\n",
    "        input_target_embedder, target_embedder = build_embedder(\n",
    "            max_sequence_size, \n",
    "            words_amount, \n",
    "            embedding_dim, \n",
    "            embedding_matrix, \n",
    "            linear_embedders_dims, \n",
    "            regularizer_weight, \n",
    "            dropout\n",
    "        )\n",
    "\n",
    "        dense_encoder = build_dense_encoder(\n",
    "            max_sequence_size, \n",
    "            embedding_dim, \n",
    "            final_embedding_dimension, \n",
    "            pool_size, \n",
    "            regularizer_weight\n",
    "        )\n",
    "\n",
    "        bilstm_encoder = build_bilstm_encoder(\n",
    "            max_sequence_size, \n",
    "            final_embedding_dimension, \n",
    "            lstm_units, \n",
    "            dropout, \n",
    "            regularizer_weight,\n",
    "            with_attention\n",
    "        )\n",
    "\n",
    "        # Apply dense encoder to source and target sequence features\n",
    "        prev_source_layers = source_layers = dense_encoder(source_embedder)\n",
    "        prev_target_layers = target_layers = dense_encoder(target_embedder)\n",
    "\n",
    "        # Apply bilstm encoder to source and target sequence features\n",
    "        source_layers = bilstm_encoder(source_layers)\n",
    "        target_layers = bilstm_encoder(target_layers)\n",
    "\n",
    "        if with_attention:\n",
    "            source_layers, target_layers = apply_attention(\n",
    "                input_source_embedder, \n",
    "                input_target_embedder,\n",
    "                prev_source_layers,\n",
    "                prev_target_layers,\n",
    "                source_layers,\n",
    "                target_layers,\n",
    "                final_layer_size,\n",
    "                index,\n",
    "            )\n",
    "\n",
    "        # Concatenate source and target sequence features with other features \n",
    "        model_layers = layers.Concatenate()([source_layers, target_layers, input_distance])\n",
    "        model_layers = layers.BatchNormalization()(model_layers)\n",
    "        model_layers = layers.Dropout(dropout)(model_layers)\n",
    "\n",
    "        # Middle dense layer\n",
    "        model_layers = layers.Dense(\n",
    "            units=final_layer_size,\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "            kernel_regularizer=keras.regularizers.l2(regularizer_weight),\n",
    "            bias_regularizer=keras.regularizers.l2(regularizer_weight),\n",
    "        )(model_layers)\n",
    "\n",
    "        # Apply a residual network\n",
    "        model_layers = apply_resnet(\n",
    "            model_layers,\n",
    "            regularizer_weight,\n",
    "            res_size,\n",
    "            dropout\n",
    "        )\n",
    "\n",
    "\n",
    "        model_layers = layers.BatchNormalization()(model_layers)\n",
    "        model_layers = layers.Dropout(dropout)(model_layers)\n",
    "\n",
    "        # Classifiers\n",
    "        relation_classifier = layers.Dense(\n",
    "            units=relation_amount,\n",
    "            activation='softmax',\n",
    "            name=f\"relation_{index}\",\n",
    "        )(model_layers)\n",
    "\n",
    "        source_classifier = layers.Dense(\n",
    "            units=proposition_tag_amount,\n",
    "            activation='softmax',\n",
    "            name=f\"source_{index}\",\n",
    "        )(model_layers)\n",
    "\n",
    "        target_classifier = layers.Dense(\n",
    "            units=proposition_tag_amount,\n",
    "            activation='softmax',\n",
    "            name=f\"target_{index}\",\n",
    "        )(model_layers)\n",
    "\n",
    "        # Creating final model\n",
    "        model = keras.Model(\n",
    "            inputs=(input_source_embedder, input_target_embedder, input_distance),\n",
    "            outputs=(relation_classifier, source_classifier, target_classifier),\n",
    "            name=f\"{params['model_name']}_{index}\"\n",
    "        )\n",
    "    \n",
    "        model.summary()\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    for i in range(ensemble_amount):\n",
    "        model = create_single_model(i)\n",
    "        models.append(model)\n",
    "    \n",
    "    params[params['model_name']] = models\n",
    "\n",
    "build_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNEW LR: 0.003\n",
      "\tNEW LR: 0.003\n",
      "Epoch 1/70\n",
      "1948/1948 [==============================] - 461s 222ms/step - loss: 5.5677 - relation_0_loss: 0.2297 - source_0_loss: 0.6124 - target_0_loss: 0.5811 - relation_0_acc: 0.9269 - relation_0_relation_0F1Macro: 0.3743 - source_0_acc: 0.7564 - source_0_source_0F1Macro: 0.1785 - target_0_acc: 0.7722 - target_0_target_0F1Macro: 0.2238 - val_loss: 4.3130 - val_relation_0_loss: 0.1667 - val_source_0_loss: 0.5226 - val_target_0_loss: 0.5508 - val_relation_0_acc: 0.9335 - val_relation_0_relation_0F1Macro: 0.3427 - val_source_0_acc: 0.7846 - val_source_0_source_0F1Macro: 0.1759 - val_target_0_acc: 0.7433 - val_target_0_target_0F1Macro: 0.2386 - lr: 0.0030\n",
      "\tNEW LR: 0.0029970029970029974\n",
      "Epoch 2/70\n",
      "1948/1948 [==============================] - 421s 216ms/step - loss: 3.6088 - relation_0_loss: 0.1387 - source_0_loss: 0.5340 - target_0_loss: 0.4790 - relation_0_acc: 0.9561 - relation_0_relation_0F1Macro: 0.4080 - source_0_acc: 0.7791 - source_0_source_0F1Macro: 0.1752 - target_0_acc: 0.7953 - target_0_target_0F1Macro: 0.2312 - val_loss: 3.3317 - val_relation_0_loss: 0.1430 - val_source_0_loss: 0.5242 - val_target_0_loss: 0.5065 - val_relation_0_acc: 0.9375 - val_relation_0_relation_0F1Macro: 0.3602 - val_source_0_acc: 0.7846 - val_source_0_source_0F1Macro: 0.1759 - val_target_0_acc: 0.7852 - val_target_0_target_0F1Macro: 0.2015 - lr: 0.0030\n",
      "\tNEW LR: 0.0029940119760479044\n",
      "Epoch 3/70\n",
      "1948/1948 [==============================] - 422s 217ms/step - loss: 3.0023 - relation_0_loss: 0.1315 - source_0_loss: 0.5331 - target_0_loss: 0.4595 - relation_0_acc: 0.9578 - relation_0_relation_0F1Macro: 0.4122 - source_0_acc: 0.7791 - source_0_source_0F1Macro: 0.1752 - target_0_acc: 0.7989 - target_0_target_0F1Macro: 0.2408 - val_loss: 3.0509 - val_relation_0_loss: 0.1411 - val_source_0_loss: 0.5159 - val_target_0_loss: 0.4958 - val_relation_0_acc: 0.9368 - val_relation_0_relation_0F1Macro: 0.3591 - val_source_0_acc: 0.7846 - val_source_0_source_0F1Macro: 0.1759 - val_target_0_acc: 0.7819 - val_target_0_target_0F1Macro: 0.2232 - lr: 0.0030\n",
      "\tNEW LR: 0.0029910269192422734\n",
      "Epoch 4/70\n",
      "1948/1948 [==============================] - 420s 216ms/step - loss: 2.8253 - relation_0_loss: 0.1316 - source_0_loss: 0.5330 - target_0_loss: 0.4546 - relation_0_acc: 0.9584 - relation_0_relation_0F1Macro: 0.4134 - source_0_acc: 0.7792 - source_0_source_0F1Macro: 0.1752 - target_0_acc: 0.7983 - target_0_target_0F1Macro: 0.2399 - val_loss: 2.8153 - val_relation_0_loss: 0.1363 - val_source_0_loss: 0.5095 - val_target_0_loss: 0.4720 - val_relation_0_acc: 0.9421 - val_relation_0_relation_0F1Macro: 0.3719 - val_source_0_acc: 0.7846 - val_source_0_source_0F1Macro: 0.1759 - val_target_0_acc: 0.7828 - val_target_0_target_0F1Macro: 0.2134 - lr: 0.0030\n",
      "\tNEW LR: 0.00298804780876494\n",
      "Epoch 5/70\n",
      "1948/1948 [==============================] - 422s 217ms/step - loss: 2.6394 - relation_0_loss: 0.1224 - source_0_loss: 0.5320 - target_0_loss: 0.4472 - relation_0_acc: 0.9598 - relation_0_relation_0F1Macro: 0.4162 - source_0_acc: 0.7792 - source_0_source_0F1Macro: 0.1752 - target_0_acc: 0.8001 - target_0_target_0F1Macro: 0.2452 - val_loss: 3.0952 - val_relation_0_loss: 0.1527 - val_source_0_loss: 0.5043 - val_target_0_loss: 0.4975 - val_relation_0_acc: 0.9384 - val_relation_0_relation_0F1Macro: 0.3579 - val_source_0_acc: 0.7846 - val_source_0_source_0F1Macro: 0.1759 - val_target_0_acc: 0.7650 - val_target_0_target_0F1Macro: 0.2343 - lr: 0.0030\n",
      "\tNEW LR: 0.002985074626865672\n",
      "Epoch 6/70\n",
      "1948/1948 [==============================] - 422s 217ms/step - loss: 2.7072 - relation_0_loss: 0.1228 - source_0_loss: 0.5308 - target_0_loss: 0.4456 - relation_0_acc: 0.9602 - relation_0_relation_0F1Macro: 0.4167 - source_0_acc: 0.7792 - source_0_source_0F1Macro: 0.1752 - target_0_acc: 0.7987 - target_0_target_0F1Macro: 0.2437 - val_loss: 2.7756 - val_relation_0_loss: 0.1285 - val_source_0_loss: 0.5020 - val_target_0_loss: 0.4814 - val_relation_0_acc: 0.9381 - val_relation_0_relation_0F1Macro: 0.3624 - val_source_0_acc: 0.7846 - val_source_0_source_0F1Macro: 0.1759 - val_target_0_acc: 0.7957 - val_target_0_target_0F1Macro: 0.2298 - lr: 0.0030\n",
      "\tNEW LR: 0.002982107355864811\n",
      "Epoch 7/70\n",
      "1948/1948 [==============================] - 423s 217ms/step - loss: 2.6488 - relation_0_loss: 0.1209 - source_0_loss: 0.5309 - target_0_loss: 0.4468 - relation_0_acc: 0.9601 - relation_0_relation_0F1Macro: 0.4169 - source_0_acc: 0.7792 - source_0_source_0F1Macro: 0.1752 - target_0_acc: 0.8043 - target_0_target_0F1Macro: 0.2497 - val_loss: 3.0298 - val_relation_0_loss: 0.1509 - val_source_0_loss: 0.5062 - val_target_0_loss: 0.5301 - val_relation_0_acc: 0.9373 - val_relation_0_relation_0F1Macro: 0.3547 - val_source_0_acc: 0.7846 - val_source_0_source_0F1Macro: 0.1759 - val_target_0_acc: 0.7380 - val_target_0_target_0F1Macro: 0.2319 - lr: 0.0030\n",
      "\tNEW LR: 0.00297914597815293\n",
      "Epoch 8/70\n",
      "1948/1948 [==============================] - 421s 216ms/step - loss: 2.6713 - relation_0_loss: 0.1231 - source_0_loss: 0.5303 - target_0_loss: 0.4600 - relation_0_acc: 0.9601 - relation_0_relation_0F1Macro: 0.4173 - source_0_acc: 0.7792 - source_0_source_0F1Macro: 0.1752 - target_0_acc: 0.7993 - target_0_target_0F1Macro: 0.2393 - val_loss: 2.8739 - val_relation_0_loss: 0.1422 - val_source_0_loss: 0.5176 - val_target_0_loss: 0.4925 - val_relation_0_acc: 0.9353 - val_relation_0_relation_0F1Macro: 0.3555 - val_source_0_acc: 0.7846 - val_source_0_source_0F1Macro: 0.1759 - val_target_0_acc: 0.7900 - val_target_0_target_0F1Macro: 0.2157 - lr: 0.0030\n",
      "\tNEW LR: 0.002976190476190476\n",
      "Epoch 9/70\n",
      "1948/1948 [==============================] - 428s 220ms/step - loss: 2.5801 - relation_0_loss: 0.1185 - source_0_loss: 0.5303 - target_0_loss: 0.4489 - relation_0_acc: 0.9616 - relation_0_relation_0F1Macro: 0.4201 - source_0_acc: 0.7792 - source_0_source_0F1Macro: 0.1752 - target_0_acc: 0.8031 - target_0_target_0F1Macro: 0.2474 - val_loss: 2.8669 - val_relation_0_loss: 0.1394 - val_source_0_loss: 0.5088 - val_target_0_loss: 0.5051 - val_relation_0_acc: 0.9370 - val_relation_0_relation_0F1Macro: 0.3580 - val_source_0_acc: 0.7846 - val_source_0_source_0F1Macro: 0.1759 - val_target_0_acc: 0.7841 - val_target_0_target_0F1Macro: 0.2076 - lr: 0.0030\n",
      "\tNEW LR: 0.0029732408325074335\n",
      "Epoch 10/70\n",
      "1948/1948 [==============================] - 421s 216ms/step - loss: 2.6287 - relation_0_loss: 0.1194 - source_0_loss: 0.5300 - target_0_loss: 0.4562 - relation_0_acc: 0.9600 - relation_0_relation_0F1Macro: 0.4167 - source_0_acc: 0.7792 - source_0_source_0F1Macro: 0.1752 - target_0_acc: 0.7997 - target_0_target_0F1Macro: 0.2384 - val_loss: 2.7776 - val_relation_0_loss: 0.1341 - val_source_0_loss: 0.5104 - val_target_0_loss: 0.4916 - val_relation_0_acc: 0.9384 - val_relation_0_relation_0F1Macro: 0.3629 - val_source_0_acc: 0.7846 - val_source_0_source_0F1Macro: 0.1759 - val_target_0_acc: 0.7604 - val_target_0_target_0F1Macro: 0.2276 - lr: 0.0030\n",
      "\tNEW LR: 0.0029702970297029703\n",
      "Epoch 11/70\n",
      "1948/1948 [==============================] - 428s 220ms/step - loss: 2.6324 - relation_0_loss: 0.1193 - source_0_loss: 0.5297 - target_0_loss: 0.4515 - relation_0_acc: 0.9600 - relation_0_relation_0F1Macro: 0.4169 - source_0_acc: 0.7792 - source_0_source_0F1Macro: 0.1752 - target_0_acc: 0.7991 - target_0_target_0F1Macro: 0.2443 - val_loss: 3.0278 - val_relation_0_loss: 0.1489 - val_source_0_loss: 0.5052 - val_target_0_loss: 0.5069 - val_relation_0_acc: 0.9375 - val_relation_0_relation_0F1Macro: 0.3493 - val_source_0_acc: 0.7846 - val_source_0_source_0F1Macro: 0.1759 - val_target_0_acc: 0.7646 - val_target_0_target_0F1Macro: 0.2435 - lr: 0.0030\n",
      "Epoch 11: early stopping\n",
      "INFO:tensorflow:Assets written to: /tf/notebooks/data/link_prediction/persuasive_essays_paragraph/model/model_attention_0/assets\n",
      "\tNEW LR: 0.003\n",
      "\tNEW LR: 0.003\n",
      "Epoch 1/70\n",
      "1948/1948 [==============================] - 444s 217ms/step - loss: 5.6783 - relation_1_loss: 0.2501 - source_1_loss: 0.6122 - target_1_loss: 0.5798 - relation_1_acc: 0.9197 - relation_1_relation_1F1Macro: 0.3660 - source_1_acc: 0.7563 - source_1_source_1F1Macro: 0.1809 - target_1_acc: 0.7666 - target_1_target_1F1Macro: 0.2193 - val_loss: 4.0226 - val_relation_1_loss: 0.1513 - val_source_1_loss: 0.5181 - val_target_1_loss: 0.5614 - val_relation_1_acc: 0.9370 - val_relation_1_relation_1F1Macro: 0.3582 - val_source_1_acc: 0.7867 - val_source_1_source_1F1Macro: 0.1801 - val_target_1_acc: 0.7889 - val_target_1_target_1F1Macro: 0.2156 - lr: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNEW LR: 0.0029970029970029974\n",
      "Epoch 2/70\n",
      "1948/1948 [==============================] - 426s 219ms/step - loss: 3.4683 - relation_1_loss: 0.1397 - source_1_loss: 0.5344 - target_1_loss: 0.4741 - relation_1_acc: 0.9551 - relation_1_relation_1F1Macro: 0.4063 - source_1_acc: 0.7785 - source_1_source_1F1Macro: 0.1754 - target_1_acc: 0.7978 - target_1_target_1F1Macro: 0.2351 - val_loss: 4.1283 - val_relation_1_loss: 0.2261 - val_source_1_loss: 0.5086 - val_target_1_loss: 0.6116 - val_relation_1_acc: 0.9320 - val_relation_1_relation_1F1Macro: 0.3162 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.6505 - val_target_1_target_1F1Macro: 0.2315 - lr: 0.0030\n",
      "\tNEW LR: 0.0029940119760479044\n",
      "Epoch 3/70\n",
      "1948/1948 [==============================] - 421s 216ms/step - loss: 2.8734 - relation_1_loss: 0.1294 - source_1_loss: 0.5326 - target_1_loss: 0.4597 - relation_1_acc: 0.9585 - relation_1_relation_1F1Macro: 0.4128 - source_1_acc: 0.7790 - source_1_source_1F1Macro: 0.1753 - target_1_acc: 0.7979 - target_1_target_1F1Macro: 0.2385 - val_loss: 3.0779 - val_relation_1_loss: 0.1452 - val_source_1_loss: 0.5079 - val_target_1_loss: 0.5579 - val_relation_1_acc: 0.9331 - val_relation_1_relation_1F1Macro: 0.3493 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7793 - val_target_1_target_1F1Macro: 0.1968 - lr: 0.0030\n",
      "\tNEW LR: 0.0029910269192422734\n",
      "Epoch 4/70\n",
      "1948/1948 [==============================] - 422s 217ms/step - loss: 2.7580 - relation_1_loss: 0.1259 - source_1_loss: 0.5320 - target_1_loss: 0.4567 - relation_1_acc: 0.9586 - relation_1_relation_1F1Macro: 0.4133 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.7977 - target_1_target_1F1Macro: 0.2429 - val_loss: 3.0351 - val_relation_1_loss: 0.1505 - val_source_1_loss: 0.5178 - val_target_1_loss: 0.4928 - val_relation_1_acc: 0.9351 - val_relation_1_relation_1F1Macro: 0.3550 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7887 - val_target_1_target_1F1Macro: 0.2085 - lr: 0.0030\n",
      "\tNEW LR: 0.00298804780876494\n",
      "Epoch 5/70\n",
      "1948/1948 [==============================] - 423s 217ms/step - loss: 2.6957 - relation_1_loss: 0.1254 - source_1_loss: 0.5320 - target_1_loss: 0.4612 - relation_1_acc: 0.9582 - relation_1_relation_1F1Macro: 0.4144 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.7979 - target_1_target_1F1Macro: 0.2390 - val_loss: 2.9443 - val_relation_1_loss: 0.1532 - val_source_1_loss: 0.5132 - val_target_1_loss: 0.4939 - val_relation_1_acc: 0.9353 - val_relation_1_relation_1F1Macro: 0.3514 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7898 - val_target_1_target_1F1Macro: 0.2256 - lr: 0.0030\n",
      "\tNEW LR: 0.002985074626865672\n",
      "Epoch 6/70\n",
      "1948/1948 [==============================] - 424s 218ms/step - loss: 2.6319 - relation_1_loss: 0.1228 - source_1_loss: 0.5317 - target_1_loss: 0.4607 - relation_1_acc: 0.9589 - relation_1_relation_1F1Macro: 0.4140 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.7974 - target_1_target_1F1Macro: 0.2384 - val_loss: 3.0773 - val_relation_1_loss: 0.1451 - val_source_1_loss: 0.5224 - val_target_1_loss: 0.6945 - val_relation_1_acc: 0.9370 - val_relation_1_relation_1F1Macro: 0.3513 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.5603 - val_target_1_target_1F1Macro: 0.2160 - lr: 0.0030\n",
      "\tNEW LR: 0.002982107355864811\n",
      "Epoch 7/70\n",
      "1948/1948 [==============================] - 422s 217ms/step - loss: 2.6502 - relation_1_loss: 0.1236 - source_1_loss: 0.5313 - target_1_loss: 0.4575 - relation_1_acc: 0.9584 - relation_1_relation_1F1Macro: 0.4133 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.7970 - target_1_target_1F1Macro: 0.2388 - val_loss: 3.2022 - val_relation_1_loss: 0.1583 - val_source_1_loss: 0.5132 - val_target_1_loss: 0.6244 - val_relation_1_acc: 0.9353 - val_relation_1_relation_1F1Macro: 0.3406 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.5748 - val_target_1_target_1F1Macro: 0.2191 - lr: 0.0030\n",
      "\tNEW LR: 0.00297914597815293\n",
      "Epoch 8/70\n",
      "1948/1948 [==============================] - 423s 217ms/step - loss: 2.6227 - relation_1_loss: 0.1205 - source_1_loss: 0.5313 - target_1_loss: 0.4498 - relation_1_acc: 0.9608 - relation_1_relation_1F1Macro: 0.4181 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8022 - target_1_target_1F1Macro: 0.2488 - val_loss: 2.9711 - val_relation_1_loss: 0.1551 - val_source_1_loss: 0.5173 - val_target_1_loss: 0.5174 - val_relation_1_acc: 0.9353 - val_relation_1_relation_1F1Macro: 0.3530 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7380 - val_target_1_target_1F1Macro: 0.2323 - lr: 0.0030\n",
      "\tNEW LR: 0.002976190476190476\n",
      "Epoch 9/70\n",
      "1948/1948 [==============================] - 421s 216ms/step - loss: 2.6002 - relation_1_loss: 0.1236 - source_1_loss: 0.5313 - target_1_loss: 0.4562 - relation_1_acc: 0.9592 - relation_1_relation_1F1Macro: 0.4155 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.7997 - target_1_target_1F1Macro: 0.2432 - val_loss: 2.9140 - val_relation_1_loss: 0.1475 - val_source_1_loss: 0.5191 - val_target_1_loss: 0.5648 - val_relation_1_acc: 0.9377 - val_relation_1_relation_1F1Macro: 0.3607 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7920 - val_target_1_target_1F1Macro: 0.2067 - lr: 0.0030\n",
      "\tNEW LR: 0.0029732408325074335\n",
      "Epoch 10/70\n",
      "1948/1948 [==============================] - 424s 218ms/step - loss: 2.6564 - relation_1_loss: 0.1209 - source_1_loss: 0.5304 - target_1_loss: 0.4631 - relation_1_acc: 0.9595 - relation_1_relation_1F1Macro: 0.4159 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.7990 - target_1_target_1F1Macro: 0.2407 - val_loss: 3.0878 - val_relation_1_loss: 0.1556 - val_source_1_loss: 0.5214 - val_target_1_loss: 0.5391 - val_relation_1_acc: 0.9318 - val_relation_1_relation_1F1Macro: 0.3274 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7367 - val_target_1_target_1F1Macro: 0.2454 - lr: 0.0030\n",
      "\tNEW LR: 0.0029702970297029703\n",
      "Epoch 11/70\n",
      "1948/1948 [==============================] - 424s 218ms/step - loss: 2.5637 - relation_1_loss: 0.1213 - source_1_loss: 0.5301 - target_1_loss: 0.4501 - relation_1_acc: 0.9589 - relation_1_relation_1F1Macro: 0.4148 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8032 - target_1_target_1F1Macro: 0.2487 - val_loss: 3.1079 - val_relation_1_loss: 0.1711 - val_source_1_loss: 0.5126 - val_target_1_loss: 0.5073 - val_relation_1_acc: 0.9357 - val_relation_1_relation_1F1Macro: 0.3525 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7832 - val_target_1_target_1F1Macro: 0.2321 - lr: 0.0030\n",
      "\tNEW LR: 0.0029673590504451044\n",
      "Epoch 12/70\n",
      "1948/1948 [==============================] - 425s 218ms/step - loss: 2.5502 - relation_1_loss: 0.1175 - source_1_loss: 0.5299 - target_1_loss: 0.4515 - relation_1_acc: 0.9603 - relation_1_relation_1F1Macro: 0.4171 - source_1_acc: 0.7793 - source_1_source_1F1Macro: 0.1753 - target_1_acc: 0.8048 - target_1_target_1F1Macro: 0.2526 - val_loss: 2.9119 - val_relation_1_loss: 0.1499 - val_source_1_loss: 0.5227 - val_target_1_loss: 0.4816 - val_relation_1_acc: 0.9388 - val_relation_1_relation_1F1Macro: 0.3602 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7905 - val_target_1_target_1F1Macro: 0.2270 - lr: 0.0030\n",
      "\tNEW LR: 0.002964426877470356\n",
      "Epoch 13/70\n",
      "1948/1948 [==============================] - 388s 199ms/step - loss: 2.5412 - relation_1_loss: 0.1170 - source_1_loss: 0.5296 - target_1_loss: 0.4494 - relation_1_acc: 0.9609 - relation_1_relation_1F1Macro: 0.4189 - source_1_acc: 0.7793 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8010 - target_1_target_1F1Macro: 0.2466 - val_loss: 3.0502 - val_relation_1_loss: 0.1476 - val_source_1_loss: 0.5165 - val_target_1_loss: 0.5228 - val_relation_1_acc: 0.9373 - val_relation_1_relation_1F1Macro: 0.3529 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7867 - val_target_1_target_1F1Macro: 0.2352 - lr: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNEW LR: 0.002961500493583416\n",
      "Epoch 14/70\n",
      "1948/1948 [==============================] - 388s 199ms/step - loss: 2.5376 - relation_1_loss: 0.1154 - source_1_loss: 0.5298 - target_1_loss: 0.4509 - relation_1_acc: 0.9606 - relation_1_relation_1F1Macro: 0.4184 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8015 - target_1_target_1F1Macro: 0.2461 - val_loss: 2.9639 - val_relation_1_loss: 0.1486 - val_source_1_loss: 0.5209 - val_target_1_loss: 0.5032 - val_relation_1_acc: 0.9377 - val_relation_1_relation_1F1Macro: 0.3566 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7541 - val_target_1_target_1F1Macro: 0.2427 - lr: 0.0030\n",
      "\tNEW LR: 0.0029585798816568047\n",
      "Epoch 15/70\n",
      "1948/1948 [==============================] - 388s 199ms/step - loss: 2.5569 - relation_1_loss: 0.1151 - source_1_loss: 0.5293 - target_1_loss: 0.4473 - relation_1_acc: 0.9605 - relation_1_relation_1F1Macro: 0.4179 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8023 - target_1_target_1F1Macro: 0.2491 - val_loss: 2.9143 - val_relation_1_loss: 0.1448 - val_source_1_loss: 0.5144 - val_target_1_loss: 0.4952 - val_relation_1_acc: 0.9351 - val_relation_1_relation_1F1Macro: 0.3548 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7652 - val_target_1_target_1F1Macro: 0.2245 - lr: 0.0030\n",
      "\tNEW LR: 0.002955665024630542\n",
      "Epoch 16/70\n",
      "1948/1948 [==============================] - 409s 210ms/step - loss: 2.5451 - relation_1_loss: 0.1124 - source_1_loss: 0.5292 - target_1_loss: 0.4519 - relation_1_acc: 0.9617 - relation_1_relation_1F1Macro: 0.4206 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8017 - target_1_target_1F1Macro: 0.2463 - val_loss: 3.0420 - val_relation_1_loss: 0.1539 - val_source_1_loss: 0.5455 - val_target_1_loss: 0.5674 - val_relation_1_acc: 0.9370 - val_relation_1_relation_1F1Macro: 0.3537 - val_source_1_acc: 0.7859 - val_source_1_source_1F1Macro: 0.1784 - val_target_1_acc: 0.7804 - val_target_1_target_1F1Macro: 0.2135 - lr: 0.0030\n",
      "\tNEW LR: 0.002952755905511811\n",
      "Epoch 17/70\n",
      "1948/1948 [==============================] - 426s 219ms/step - loss: 2.5117 - relation_1_loss: 0.1157 - source_1_loss: 0.5282 - target_1_loss: 0.4501 - relation_1_acc: 0.9605 - relation_1_relation_1F1Macro: 0.4189 - source_1_acc: 0.7793 - source_1_source_1F1Macro: 0.1753 - target_1_acc: 0.7993 - target_1_target_1F1Macro: 0.2459 - val_loss: 2.8146 - val_relation_1_loss: 0.1397 - val_source_1_loss: 0.5130 - val_target_1_loss: 0.5072 - val_relation_1_acc: 0.9359 - val_relation_1_relation_1F1Macro: 0.3570 - val_source_1_acc: 0.7892 - val_source_1_source_1F1Macro: 0.1887 - val_target_1_acc: 0.7874 - val_target_1_target_1F1Macro: 0.2064 - lr: 0.0030\n",
      "\tNEW LR: 0.0029498525073746317\n",
      "Epoch 18/70\n",
      "1948/1948 [==============================] - 398s 204ms/step - loss: 2.4679 - relation_1_loss: 0.1121 - source_1_loss: 0.5288 - target_1_loss: 0.4494 - relation_1_acc: 0.9608 - relation_1_relation_1F1Macro: 0.4183 - source_1_acc: 0.7793 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8001 - target_1_target_1F1Macro: 0.2456 - val_loss: 2.8177 - val_relation_1_loss: 0.1444 - val_source_1_loss: 0.5089 - val_target_1_loss: 0.5150 - val_relation_1_acc: 0.9346 - val_relation_1_relation_1F1Macro: 0.3539 - val_source_1_acc: 0.7863 - val_source_1_source_1F1Macro: 0.1827 - val_target_1_acc: 0.7547 - val_target_1_target_1F1Macro: 0.2253 - lr: 0.0029\n",
      "\tNEW LR: 0.0029469548133595285\n",
      "Epoch 19/70\n",
      "1948/1948 [==============================] - 393s 202ms/step - loss: 2.4645 - relation_1_loss: 0.1116 - source_1_loss: 0.5288 - target_1_loss: 0.4435 - relation_1_acc: 0.9608 - relation_1_relation_1F1Macro: 0.4186 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8022 - target_1_target_1F1Macro: 0.2503 - val_loss: 2.8642 - val_relation_1_loss: 0.1469 - val_source_1_loss: 0.5062 - val_target_1_loss: 0.4945 - val_relation_1_acc: 0.9359 - val_relation_1_relation_1F1Macro: 0.3556 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7878 - val_target_1_target_1F1Macro: 0.2145 - lr: 0.0029\n",
      "\tNEW LR: 0.0029440628066732095\n",
      "Epoch 20/70\n",
      "1948/1948 [==============================] - 393s 202ms/step - loss: 2.4822 - relation_1_loss: 0.1139 - source_1_loss: 0.5284 - target_1_loss: 0.4460 - relation_1_acc: 0.9608 - relation_1_relation_1F1Macro: 0.4193 - source_1_acc: 0.7793 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.7998 - target_1_target_1F1Macro: 0.2451 - val_loss: 2.7845 - val_relation_1_loss: 0.1374 - val_source_1_loss: 0.5115 - val_target_1_loss: 0.5095 - val_relation_1_acc: 0.9421 - val_relation_1_relation_1F1Macro: 0.3706 - val_source_1_acc: 0.7857 - val_source_1_source_1F1Macro: 0.1780 - val_target_1_acc: 0.7589 - val_target_1_target_1F1Macro: 0.2316 - lr: 0.0029\n",
      "\tNEW LR: 0.0029411764705882353\n",
      "Epoch 21/70\n",
      "1948/1948 [==============================] - 394s 202ms/step - loss: 2.4885 - relation_1_loss: 0.1126 - source_1_loss: 0.5287 - target_1_loss: 0.4509 - relation_1_acc: 0.9610 - relation_1_relation_1F1Macro: 0.4191 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8003 - target_1_target_1F1Macro: 0.2441 - val_loss: 2.8749 - val_relation_1_loss: 0.1459 - val_source_1_loss: 0.5151 - val_target_1_loss: 0.5124 - val_relation_1_acc: 0.9333 - val_relation_1_relation_1F1Macro: 0.3482 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7900 - val_target_1_target_1F1Macro: 0.2297 - lr: 0.0029\n",
      "\tNEW LR: 0.0029382957884427035\n",
      "Epoch 22/70\n",
      "1948/1948 [==============================] - 447s 229ms/step - loss: 2.4614 - relation_1_loss: 0.1125 - source_1_loss: 0.5286 - target_1_loss: 0.4425 - relation_1_acc: 0.9608 - relation_1_relation_1F1Macro: 0.4190 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8034 - target_1_target_1F1Macro: 0.2512 - val_loss: 2.8850 - val_relation_1_loss: 0.1438 - val_source_1_loss: 0.5149 - val_target_1_loss: 0.5055 - val_relation_1_acc: 0.9419 - val_relation_1_relation_1F1Macro: 0.3706 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7413 - val_target_1_target_1F1Macro: 0.2486 - lr: 0.0029\n",
      "\tNEW LR: 0.0029354207436399216\n",
      "Epoch 23/70\n",
      "1948/1948 [==============================] - 421s 216ms/step - loss: 2.4965 - relation_1_loss: 0.1130 - source_1_loss: 0.5285 - target_1_loss: 0.4435 - relation_1_acc: 0.9609 - relation_1_relation_1F1Macro: 0.4196 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8011 - target_1_target_1F1Macro: 0.2480 - val_loss: 2.8977 - val_relation_1_loss: 0.1461 - val_source_1_loss: 0.5123 - val_target_1_loss: 0.5227 - val_relation_1_acc: 0.9346 - val_relation_1_relation_1F1Macro: 0.3538 - val_source_1_acc: 0.7843 - val_source_1_source_1F1Macro: 0.1758 - val_target_1_acc: 0.7604 - val_target_1_target_1F1Macro: 0.2443 - lr: 0.0029\n",
      "\tNEW LR: 0.0029325513196480943\n",
      "Epoch 24/70\n",
      "1948/1948 [==============================] - 387s 199ms/step - loss: 2.4518 - relation_1_loss: 0.1123 - source_1_loss: 0.5280 - target_1_loss: 0.4404 - relation_1_acc: 0.9609 - relation_1_relation_1F1Macro: 0.4190 - source_1_acc: 0.7793 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8031 - target_1_target_1F1Macro: 0.2489 - val_loss: 3.0920 - val_relation_1_loss: 0.1599 - val_source_1_loss: 0.5217 - val_target_1_loss: 0.5984 - val_relation_1_acc: 0.9335 - val_relation_1_relation_1F1Macro: 0.3462 - val_source_1_acc: 0.7900 - val_source_1_source_1F1Macro: 0.1975 - val_target_1_acc: 0.7602 - val_target_1_target_1F1Macro: 0.2022 - lr: 0.0029\n",
      "\tNEW LR: 0.0029296875\n",
      "Epoch 25/70\n",
      "1948/1948 [==============================] - 386s 198ms/step - loss: 2.3910 - relation_1_loss: 0.1125 - source_1_loss: 0.5285 - target_1_loss: 0.4410 - relation_1_acc: 0.9609 - relation_1_relation_1F1Macro: 0.4195 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8012 - target_1_target_1F1Macro: 0.2482 - val_loss: 2.9765 - val_relation_1_loss: 0.1543 - val_source_1_loss: 0.5183 - val_target_1_loss: 0.6110 - val_relation_1_acc: 0.9351 - val_relation_1_relation_1F1Macro: 0.3522 - val_source_1_acc: 0.7885 - val_source_1_source_1F1Macro: 0.1925 - val_target_1_acc: 0.7878 - val_target_1_target_1F1Macro: 0.2077 - lr: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: early stopping\n",
      "INFO:tensorflow:Assets written to: /tf/notebooks/data/link_prediction/persuasive_essays_paragraph/model/model_attention_1/assets\n",
      "\tNEW LR: 0.003\n",
      "\tNEW LR: 0.003\n",
      "Epoch 1/70\n",
      "1948/1948 [==============================] - 406s 199ms/step - loss: 5.5853 - relation_2_loss: 0.2386 - source_2_loss: 0.6189 - target_2_loss: 0.5698 - relation_2_acc: 0.9242 - relation_2_relation_2F1Macro: 0.3729 - source_2_acc: 0.7572 - source_2_source_2F1Macro: 0.1773 - target_2_acc: 0.7683 - target_2_target_2F1Macro: 0.2208 - val_loss: 3.9185 - val_relation_2_loss: 0.1458 - val_source_2_loss: 0.5124 - val_target_2_loss: 0.5117 - val_relation_2_acc: 0.9331 - val_relation_2_relation_2F1Macro: 0.3477 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7885 - val_target_2_target_2F1Macro: 0.1981 - lr: 0.0030\n",
      "\tNEW LR: 0.0029970029970029974\n",
      "Epoch 2/70\n",
      "1948/1948 [==============================] - 385s 198ms/step - loss: 3.3863 - relation_2_loss: 0.1345 - source_2_loss: 0.5357 - target_2_loss: 0.4732 - relation_2_acc: 0.9564 - relation_2_relation_2F1Macro: 0.4082 - source_2_acc: 0.7791 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.7962 - target_2_target_2F1Macro: 0.2346 - val_loss: 3.3888 - val_relation_2_loss: 0.1563 - val_source_2_loss: 0.5201 - val_target_2_loss: 0.5223 - val_relation_2_acc: 0.9397 - val_relation_2_relation_2F1Macro: 0.3598 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7286 - val_target_2_target_2F1Macro: 0.2363 - lr: 0.0030\n",
      "\tNEW LR: 0.0029940119760479044\n",
      "Epoch 3/70\n",
      "1948/1948 [==============================] - 386s 198ms/step - loss: 2.8996 - relation_2_loss: 0.1297 - source_2_loss: 0.5341 - target_2_loss: 0.4648 - relation_2_acc: 0.9587 - relation_2_relation_2F1Macro: 0.4134 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.7975 - target_2_target_2F1Macro: 0.2387 - val_loss: 3.0074 - val_relation_2_loss: 0.1432 - val_source_2_loss: 0.5267 - val_target_2_loss: 0.5031 - val_relation_2_acc: 0.9300 - val_relation_2_relation_2F1Macro: 0.3388 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7843 - val_target_2_target_2F1Macro: 0.1906 - lr: 0.0030\n",
      "\tNEW LR: 0.0029910269192422734\n",
      "Epoch 4/70\n",
      "1948/1948 [==============================] - 386s 198ms/step - loss: 2.7856 - relation_2_loss: 0.1276 - source_2_loss: 0.5328 - target_2_loss: 0.4637 - relation_2_acc: 0.9584 - relation_2_relation_2F1Macro: 0.4128 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.7975 - target_2_target_2F1Macro: 0.2377 - val_loss: 3.0253 - val_relation_2_loss: 0.1470 - val_source_2_loss: 0.5104 - val_target_2_loss: 0.4945 - val_relation_2_acc: 0.9348 - val_relation_2_relation_2F1Macro: 0.3498 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7815 - val_target_2_target_2F1Macro: 0.2293 - lr: 0.0030\n",
      "\tNEW LR: 0.00298804780876494\n",
      "Epoch 5/70\n",
      "1948/1948 [==============================] - 385s 198ms/step - loss: 2.7915 - relation_2_loss: 0.1259 - source_2_loss: 0.5328 - target_2_loss: 0.4586 - relation_2_acc: 0.9585 - relation_2_relation_2F1Macro: 0.4132 - source_2_acc: 0.7791 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8004 - target_2_target_2F1Macro: 0.2450 - val_loss: 3.1248 - val_relation_2_loss: 0.1507 - val_source_2_loss: 0.5127 - val_target_2_loss: 0.5228 - val_relation_2_acc: 0.9397 - val_relation_2_relation_2F1Macro: 0.3596 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7495 - val_target_2_target_2F1Macro: 0.2471 - lr: 0.0030\n",
      "\tNEW LR: 0.002985074626865672\n",
      "Epoch 6/70\n",
      "1948/1948 [==============================] - 385s 198ms/step - loss: 2.6965 - relation_2_loss: 0.1224 - source_2_loss: 0.5310 - target_2_loss: 0.4584 - relation_2_acc: 0.9594 - relation_2_relation_2F1Macro: 0.4150 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8010 - target_2_target_2F1Macro: 0.2447 - val_loss: 3.0846 - val_relation_2_loss: 0.1573 - val_source_2_loss: 0.5148 - val_target_2_loss: 0.5343 - val_relation_2_acc: 0.9381 - val_relation_2_relation_2F1Macro: 0.3597 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7222 - val_target_2_target_2F1Macro: 0.2421 - lr: 0.0030\n",
      "\tNEW LR: 0.002982107355864811\n",
      "Epoch 7/70\n",
      "1948/1948 [==============================] - 385s 197ms/step - loss: 2.6067 - relation_2_loss: 0.1170 - source_2_loss: 0.5304 - target_2_loss: 0.4520 - relation_2_acc: 0.9605 - relation_2_relation_2F1Macro: 0.4173 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8009 - target_2_target_2F1Macro: 0.2465 - val_loss: 2.9277 - val_relation_2_loss: 0.1432 - val_source_2_loss: 0.5191 - val_target_2_loss: 0.4880 - val_relation_2_acc: 0.9386 - val_relation_2_relation_2F1Macro: 0.3635 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7905 - val_target_2_target_2F1Macro: 0.2256 - lr: 0.0030\n",
      "\tNEW LR: 0.00297914597815293\n",
      "Epoch 8/70\n",
      "1948/1948 [==============================] - 385s 198ms/step - loss: 2.6076 - relation_2_loss: 0.1189 - source_2_loss: 0.5303 - target_2_loss: 0.4548 - relation_2_acc: 0.9606 - relation_2_relation_2F1Macro: 0.4187 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8005 - target_2_target_2F1Macro: 0.2469 - val_loss: 3.1100 - val_relation_2_loss: 0.1568 - val_source_2_loss: 0.5214 - val_target_2_loss: 0.5467 - val_relation_2_acc: 0.9392 - val_relation_2_relation_2F1Macro: 0.3619 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7337 - val_target_2_target_2F1Macro: 0.2377 - lr: 0.0030\n",
      "\tNEW LR: 0.002976190476190476\n",
      "Epoch 9/70\n",
      "1948/1948 [==============================] - 386s 198ms/step - loss: 2.6104 - relation_2_loss: 0.1162 - source_2_loss: 0.5304 - target_2_loss: 0.4481 - relation_2_acc: 0.9602 - relation_2_relation_2F1Macro: 0.4171 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8029 - target_2_target_2F1Macro: 0.2498 - val_loss: 3.0040 - val_relation_2_loss: 0.1528 - val_source_2_loss: 0.5134 - val_target_2_loss: 0.4956 - val_relation_2_acc: 0.9364 - val_relation_2_relation_2F1Macro: 0.3559 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7729 - val_target_2_target_2F1Macro: 0.2260 - lr: 0.0030\n",
      "\tNEW LR: 0.0029732408325074335\n",
      "Epoch 10/70\n",
      "1948/1948 [==============================] - 385s 197ms/step - loss: 2.5631 - relation_2_loss: 0.1154 - source_2_loss: 0.5304 - target_2_loss: 0.4525 - relation_2_acc: 0.9608 - relation_2_relation_2F1Macro: 0.4185 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8002 - target_2_target_2F1Macro: 0.2460 - val_loss: 2.8939 - val_relation_2_loss: 0.1450 - val_source_2_loss: 0.5209 - val_target_2_loss: 0.4884 - val_relation_2_acc: 0.9375 - val_relation_2_relation_2F1Macro: 0.3545 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7876 - val_target_2_target_2F1Macro: 0.2347 - lr: 0.0030\n",
      "\tNEW LR: 0.0029702970297029703\n",
      "Epoch 11/70\n",
      "1948/1948 [==============================] - 385s 198ms/step - loss: 2.5671 - relation_2_loss: 0.1175 - source_2_loss: 0.5307 - target_2_loss: 0.4488 - relation_2_acc: 0.9597 - relation_2_relation_2F1Macro: 0.4167 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8041 - target_2_target_2F1Macro: 0.2506 - val_loss: 3.2007 - val_relation_2_loss: 0.1652 - val_source_2_loss: 0.5170 - val_target_2_loss: 0.6097 - val_relation_2_acc: 0.9309 - val_relation_2_relation_2F1Macro: 0.3136 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.6766 - val_target_2_target_2F1Macro: 0.2406 - lr: 0.0030\n",
      "\tNEW LR: 0.0029673590504451044\n",
      "Epoch 12/70\n",
      "1948/1948 [==============================] - 385s 197ms/step - loss: 2.5012 - relation_2_loss: 0.1148 - source_2_loss: 0.5302 - target_2_loss: 0.4475 - relation_2_acc: 0.9608 - relation_2_relation_2F1Macro: 0.4189 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8029 - target_2_target_2F1Macro: 0.2484 - val_loss: 2.8586 - val_relation_2_loss: 0.1481 - val_source_2_loss: 0.5137 - val_target_2_loss: 0.4622 - val_relation_2_acc: 0.9397 - val_relation_2_relation_2F1Macro: 0.3632 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7909 - val_target_2_target_2F1Macro: 0.2352 - lr: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNEW LR: 0.002964426877470356\n",
      "Epoch 13/70\n",
      "1948/1948 [==============================] - 385s 198ms/step - loss: 2.5678 - relation_2_loss: 0.1140 - source_2_loss: 0.5298 - target_2_loss: 0.4469 - relation_2_acc: 0.9607 - relation_2_relation_2F1Macro: 0.4188 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8020 - target_2_target_2F1Macro: 0.2477 - val_loss: 2.9508 - val_relation_2_loss: 0.1449 - val_source_2_loss: 0.5147 - val_target_2_loss: 0.5196 - val_relation_2_acc: 0.9368 - val_relation_2_relation_2F1Macro: 0.3571 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7387 - val_target_2_target_2F1Macro: 0.2435 - lr: 0.0030\n",
      "\tNEW LR: 0.002961500493583416\n",
      "Epoch 14/70\n",
      "1948/1948 [==============================] - 386s 198ms/step - loss: 2.5629 - relation_2_loss: 0.1141 - source_2_loss: 0.5296 - target_2_loss: 0.4531 - relation_2_acc: 0.9604 - relation_2_relation_2F1Macro: 0.4184 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8016 - target_2_target_2F1Macro: 0.2429 - val_loss: 2.7844 - val_relation_2_loss: 0.1404 - val_source_2_loss: 0.5166 - val_target_2_loss: 0.4700 - val_relation_2_acc: 0.9410 - val_relation_2_relation_2F1Macro: 0.3687 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7946 - val_target_2_target_2F1Macro: 0.2307 - lr: 0.0030\n",
      "\tNEW LR: 0.0029585798816568047\n",
      "Epoch 15/70\n",
      "1948/1948 [==============================] - 385s 198ms/step - loss: 2.4579 - relation_2_loss: 0.1120 - source_2_loss: 0.5293 - target_2_loss: 0.4435 - relation_2_acc: 0.9599 - relation_2_relation_2F1Macro: 0.4168 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8056 - target_2_target_2F1Macro: 0.2504 - val_loss: 2.7502 - val_relation_2_loss: 0.1404 - val_source_2_loss: 0.5111 - val_target_2_loss: 0.5002 - val_relation_2_acc: 0.9368 - val_relation_2_relation_2F1Macro: 0.3592 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7955 - val_target_2_target_2F1Macro: 0.2191 - lr: 0.0030\n",
      "\tNEW LR: 0.002955665024630542\n",
      "Epoch 16/70\n",
      "1948/1948 [==============================] - 391s 201ms/step - loss: 2.4654 - relation_2_loss: 0.1129 - source_2_loss: 0.5293 - target_2_loss: 0.4446 - relation_2_acc: 0.9616 - relation_2_relation_2F1Macro: 0.4211 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8034 - target_2_target_2F1Macro: 0.2490 - val_loss: 2.9476 - val_relation_2_loss: 0.1481 - val_source_2_loss: 0.5160 - val_target_2_loss: 0.4868 - val_relation_2_acc: 0.9370 - val_relation_2_relation_2F1Macro: 0.3571 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7894 - val_target_2_target_2F1Macro: 0.2198 - lr: 0.0030\n",
      "\tNEW LR: 0.002952755905511811\n",
      "Epoch 17/70\n",
      "1948/1948 [==============================] - 424s 217ms/step - loss: 2.5310 - relation_2_loss: 0.1143 - source_2_loss: 0.5291 - target_2_loss: 0.4437 - relation_2_acc: 0.9599 - relation_2_relation_2F1Macro: 0.4170 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8035 - target_2_target_2F1Macro: 0.2481 - val_loss: 2.8401 - val_relation_2_loss: 0.1435 - val_source_2_loss: 0.5222 - val_target_2_loss: 0.4816 - val_relation_2_acc: 0.9357 - val_relation_2_relation_2F1Macro: 0.3528 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7953 - val_target_2_target_2F1Macro: 0.2273 - lr: 0.0030\n",
      "\tNEW LR: 0.0029498525073746317\n",
      "Epoch 18/70\n",
      "1948/1948 [==============================] - 418s 215ms/step - loss: 2.5007 - relation_2_loss: 0.1106 - source_2_loss: 0.5293 - target_2_loss: 0.4439 - relation_2_acc: 0.9609 - relation_2_relation_2F1Macro: 0.4192 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8021 - target_2_target_2F1Macro: 0.2486 - val_loss: 2.7877 - val_relation_2_loss: 0.1397 - val_source_2_loss: 0.5111 - val_target_2_loss: 0.4774 - val_relation_2_acc: 0.9414 - val_relation_2_relation_2F1Macro: 0.3673 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7911 - val_target_2_target_2F1Macro: 0.2315 - lr: 0.0029\n",
      "\tNEW LR: 0.0029469548133595285\n",
      "Epoch 19/70\n",
      "1948/1948 [==============================] - 421s 216ms/step - loss: 2.4592 - relation_2_loss: 0.1120 - source_2_loss: 0.5295 - target_2_loss: 0.4411 - relation_2_acc: 0.9608 - relation_2_relation_2F1Macro: 0.4191 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8027 - target_2_target_2F1Macro: 0.2509 - val_loss: 3.0003 - val_relation_2_loss: 0.1548 - val_source_2_loss: 0.5123 - val_target_2_loss: 0.5581 - val_relation_2_acc: 0.9399 - val_relation_2_relation_2F1Macro: 0.3570 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.6994 - val_target_2_target_2F1Macro: 0.2456 - lr: 0.0029\n",
      "\tNEW LR: 0.0029440628066732095\n",
      "Epoch 20/70\n",
      "1948/1948 [==============================] - 419s 215ms/step - loss: 2.4422 - relation_2_loss: 0.1116 - source_2_loss: 0.5287 - target_2_loss: 0.4444 - relation_2_acc: 0.9611 - relation_2_relation_2F1Macro: 0.4197 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8040 - target_2_target_2F1Macro: 0.2524 - val_loss: 2.8160 - val_relation_2_loss: 0.1458 - val_source_2_loss: 0.5191 - val_target_2_loss: 0.5057 - val_relation_2_acc: 0.9346 - val_relation_2_relation_2F1Macro: 0.3539 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7885 - val_target_2_target_2F1Macro: 0.2052 - lr: 0.0029\n",
      "Epoch 20: early stopping\n",
      "INFO:tensorflow:Assets written to: /tf/notebooks/data/link_prediction/persuasive_essays_paragraph/model/model_attention_2/assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_and_save_model(params: dict):\n",
    "    model_name = params['model_name']\n",
    "    batch_size = params['batch_size']\n",
    "    if params['in_production']:\n",
    "        epochs = params['epochs']\n",
    "        train_ds = params['train_ds'].batch(batch_size)\n",
    "        val_ds = params['dev_ds'].batch(batch_size)\n",
    "        models = params[model_name]\n",
    "    else:\n",
    "        epochs = 2 \n",
    "        train_ds = params['train_ds'].batch(batch_size).take(30)\n",
    "        val_ds = params['dev_ds'].batch(batch_size).take(10)\n",
    "        models = params[model_name][:2]\n",
    "    loss_weights = params['loss_weights']\n",
    "    lr_alpha = params['lr_alpha']\n",
    "    lr_kappa = params['lr_kappa']\n",
    "    relation_amount = len(params['relation_tag_vectorizer'].get_vocabulary())\n",
    "    proposition_amount = len(params['proposition_tag_vectorizer'].get_vocabulary())\n",
    "    global_metrics = params['metrics']\n",
    "    beta_1 = params['beta_1']\n",
    "    beta_2 = params['beta_2']\n",
    "    min_delta = params['min_delta']\n",
    "    patience = params['patience']\n",
    "  \n",
    "    def single_train(index, model):\n",
    "        # Optimizer\n",
    "        lr_function = create_lr_annealing_function(initial_lr=lr_alpha, k=lr_kappa)\n",
    "        lr_scheduler = keras.callbacks.LearningRateScheduler(lr_function)\n",
    "        optimizer = tf.optimizers.Adam(\n",
    "            learning_rate=lr_function(0),\n",
    "            beta_1=beta_1,\n",
    "            beta_2=beta_2,\n",
    "        )\n",
    "\n",
    "        # EarlyStopping\n",
    "        early_stopping = keras.callbacks.EarlyStopping(\n",
    "            min_delta=min_delta,\n",
    "            patience=patience,\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        # Metrics\n",
    "        metrics = {\n",
    "            f'relation_{index}': global_metrics.copy(),\n",
    "            f'source_{index}': global_metrics.copy(),\n",
    "            f'target_{index}': global_metrics.copy(),\n",
    "        }\n",
    "        for name, num_classes in [\n",
    "                (f'relation_{index}', relation_amount), \n",
    "                (f'source_{index}', proposition_amount), \n",
    "                (f'target_{index}', proposition_amount)\n",
    "            ]:\n",
    "\n",
    "            f1_macro = tfa.metrics.F1Score(\n",
    "                num_classes=num_classes,\n",
    "                average='macro',\n",
    "                name=f'{name}F1Macro',\n",
    "            )\n",
    "            metrics[name].extend([\n",
    "                f1_macro,\n",
    "            ])\n",
    "        \n",
    "        current_loss_weights = {f'{name}_{index}': value for name, value in loss_weights.items()}\n",
    "        \n",
    "        model.compile(\n",
    "            loss='categorical_crossentropy', # Apply this loss function to all outputs\n",
    "            loss_weights=current_loss_weights, # Weights for the sum of the loss functions\n",
    "            optimizer=optimizer,\n",
    "            metrics=metrics\n",
    "        )\n",
    "\n",
    "        # Train\n",
    "        history = model.fit(train_ds,\n",
    "                      batch_size=batch_size, \n",
    "                      epochs=epochs, \n",
    "                      validation_data=val_ds,\n",
    "                      callbacks=[\n",
    "                          lr_scheduler,\n",
    "                          early_stopping,\n",
    "                      ])\n",
    "\n",
    "        model.save(str(Path(params[\"model_path\"], f\"{model_name}_{index}\")), save_format='tf')\n",
    "\n",
    "        history = history.history\n",
    "        for key in history:\n",
    "            values = np.array(history[key]).tolist()\n",
    "            history[key] = values\n",
    "        params[f'history_{index}'] = history\n",
    "        with Path(params['export_path'], f\"{model_name}_{index}_history.json\").open('w') as f:\n",
    "            json.dump(history, f)\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        single_train(i, model)\n",
    "\n",
    "train_and_save_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "def load_saved_model(params: dict):\n",
    "    ensemble_amount = params['ensemble_amount']\n",
    "    \n",
    "    model_name = params[\"model_name\"]\n",
    "    models = []\n",
    "    for i in range(ensemble_amount):        \n",
    "        model_path = Path(params[\"model_path\"], f\"{model_name}_{i}\")\n",
    "        if model_path.exists():\n",
    "            history_path = Path(params['export_path'], f\"{model_name}_{i}_history.json\")\n",
    "            history = json.load(history_path.open())\n",
    "            params[f'history_{i}'] = history\n",
    "            model = keras.models.load_model(str(model_path))\n",
    "            models.append(model)\n",
    "        else:\n",
    "            print(f\"Model in {model_path} doesn't exist\")\n",
    "    params[model_name] = models\n",
    "\n",
    "    \n",
    "load_saved_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "162/162 [==============================] - 18s 51ms/step - loss: 6.1294 - relation_0_loss: 0.4489 - source_0_loss: 0.5649 - target_0_loss: 0.5489 - relation_0_acc: 0.7982 - relation_0_relation_0F1Macro: 0.3611 - source_0_acc: 0.7086 - source_0_source_0F1Macro: 0.1659 - target_0_acc: 0.7349 - target_0_target_0F1Macro: 0.2768\n",
      "Model 1\n",
      "162/162 [==============================] - 13s 50ms/step - loss: 5.8009 - relation_1_loss: 0.4302 - source_1_loss: 0.5529 - target_1_loss: 0.6417 - relation_1_acc: 0.8180 - relation_1_relation_1F1Macro: 0.3827 - source_1_acc: 0.7451 - source_1_source_1F1Macro: 0.2263 - target_1_acc: 0.7417 - target_1_target_1F1Macro: 0.2326\n",
      "Model 2\n",
      "162/162 [==============================] - 14s 67ms/step - loss: 5.6603 - relation_2_loss: 0.4210 - source_2_loss: 0.5703 - target_2_loss: 0.5467 - relation_2_acc: 0.8226 - relation_2_relation_2F1Macro: 0.3874 - source_2_acc: 0.7086 - source_2_source_2F1Macro: 0.1659 - target_2_acc: 0.7509 - target_2_target_2F1Macro: 0.2504\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "def evaluate_model(params: dict):\n",
    "    models = params[params['model_name']]\n",
    "    batch_size = params['batch_size']\n",
    "    test_ds = params['test_ds'].batch(batch_size)\n",
    "    for i, model in enumerate(models):\n",
    "        print(\"Model\", i)\n",
    "        results = model.evaluate(test_ds, batch_size=batch_size)\n",
    "\n",
    "\n",
    "evaluate_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_history(params: dict):\n",
    "    history = params['history_0']\n",
    "    relation_labels = [x if x else \"None\" for x in params['relation_tag_vectorizer'].get_vocabulary()]\n",
    "    proposition_labels = [x if x else \"None\" for x in params['proposition_tag_vectorizer'].get_vocabulary()]\n",
    "        \n",
    "    def plot_list(values, label):\n",
    "        X = [i for i in range(len(values))]\n",
    "        plt.plot(X, values, label=label)\n",
    "    \n",
    "    def show_plot(title, x_label=\"Epoch\", y_label=\"\"):\n",
    "        plt.title(title)\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel(y_label)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_categorical_list(values, labels, bar_plot=False):\n",
    "        values = np.array(values).T\n",
    "        plt.xticks(rotation = 45)\n",
    "        if bar_plot:\n",
    "            plt.bar(labels, [x[-1] for x in values])\n",
    "        else:\n",
    "            for label, label_values in zip(labels, values):\n",
    "                X = [i for i in range(len(label_values))]\n",
    "                plt.plot(X, label_values, label=label)\n",
    "    \n",
    "    for key, value in history.items():\n",
    "        value = np.array(value)\n",
    "        if len(value.shape) == 1: # List values\n",
    "            plot_list(value, key)\n",
    "            show_plot(key, y_label=\"values\")\n",
    "        else: # Categorical values\n",
    "            labels = relation_labels if 'relation' in key else proposition_labels\n",
    "            plot_categorical_list(value, labels, bar_plot=True)\n",
    "            show_plot(key + \" bar\", x_label='categories', y_label=\"values\")\n",
    "            plot_categorical_list(value, labels, bar_plot=False)\n",
    "            show_plot(key, y_label=\"values\")\n",
    "        \n",
    "plot_history(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('supports', 'Premise', 'Claim'), ('', 'Premise', 'Premise'), ('supports', 'Premise', 'Premise')]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "class LinkPredictionModel(keras.Model):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 models,\n",
    "                 sequence_vectorizer, \n",
    "                 proposition_tag_vectorizer, \n",
    "                 relation_tag_vectorizer, \n",
    "                 distance_encoding_bits,\n",
    "                 batch_size=32\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.models = models\n",
    "        self.sequence_vectorizer = sequence_vectorizer\n",
    "        self.proposition_tag_vectorizer = proposition_tag_vectorizer\n",
    "        self.relation_tag_vectorizer = relation_tag_vectorizer\n",
    "        self.distance_encoding_bits = distance_encoding_bits\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __decode_outputs(self, outputs):\n",
    "        propositions = self.proposition_tag_vectorizer.get_vocabulary()\n",
    "        relations = self.relation_tag_vectorizer.get_vocabulary()\n",
    "        \n",
    "#         # Flatting results\n",
    "#         results = []\n",
    "#         for models_output in outputs:\n",
    "#             relation = []\n",
    "#             source = []\n",
    "#             target = []\n",
    "#             for i,input_models_output in enumerate(zip(*models_output)):\n",
    "#                 print(input_models_output)\n",
    "#                 if i == 0:\n",
    "#                     current = relation\n",
    "#                 elif i == 1:\n",
    "#                     current = source\n",
    "#                 elif i == 2:\n",
    "#                     current = target\n",
    "#                 current.append(list(input_models_output))\n",
    "                \n",
    "# #                 for relation_output, source_output, target_output in zip(relation_outputs, source_outputs, target_outputs):\n",
    "# #                     result.append((relation_output, source_output, target_output))\n",
    "#             results.append(list(zip(relation, source, target)))\n",
    "        \n",
    "        final_result = []\n",
    "        relation_eye = tf.eye(len(relations))\n",
    "        proposition_eye = tf.eye(len(propositions))\n",
    "        for output in zip(*outputs):\n",
    "\n",
    "            # Reset voting vectors\n",
    "            relation_tag_tensor = tf.zeros(shape=(len(relations)))\n",
    "            target_tag_tensor = tf.zeros(shape=(len(propositions)))\n",
    "            source_tag_tensor = tf.zeros(shape=(len(propositions)))\n",
    "            \n",
    "            for relation_output, source_output, target_output in zip(*output):\n",
    "                # Add the vote for each class\n",
    "                relation_tag_tensor = tf.add(relation_tag_tensor, relation_eye[tf.argmax(relation_output)])\n",
    "                target_tag_tensor = tf.add(target_tag_tensor, proposition_eye[tf.argmax(target_output)])\n",
    "                source_tag_tensor = tf.add(source_tag_tensor, proposition_eye[tf.argmax(source_output)])\n",
    "            \n",
    "            # Get the most voted class\n",
    "            relation_tag = relations[tf.argmax(relation_tag_tensor)]\n",
    "            target_tag_tensor = propositions[tf.argmax(target_tag_tensor)]\n",
    "            source_tag_tensor = propositions[tf.argmax(source_tag_tensor)]\n",
    "            \n",
    "            final_result.append((relation_tag, source_tag_tensor, target_tag_tensor))\n",
    "            \n",
    "        return final_result\n",
    "    \n",
    "    def call(self, source_inputs, target_inputs, distance_inputs):\n",
    "        \n",
    "        outputs = [[], [], []]\n",
    "        if source_inputs == [] or target_inputs == [] or distance_inputs == []:\n",
    "            return outputs\n",
    "\n",
    "        if len(set([len(source_inputs), len(target_inputs), len(distance_inputs)])) > 1:\n",
    "            print(\"WARNING: source_inputs, target_inputs, distance_inputs with different lengths\")\n",
    "\n",
    "        source_ds = tf.data.Dataset.from_tensor_slices(tf.constant(source_inputs)).map(lambda x: self.sequence_vectorizer(x))\n",
    "        target_ds = tf.data.Dataset.from_tensor_slices(tf.constant(target_inputs)).map(lambda x: self.sequence_vectorizer(x))\n",
    "        distance_ds = tf.data.Dataset.from_tensor_slices(tf.constant(distance_inputs)).map(lambda x: encode_distance(x, self.distance_encoding_bits))\n",
    "    \n",
    "        inputs_ds = tf.data.Dataset.zip((source_ds, target_ds, distance_ds)).batch(self.batch_size)\n",
    "        \n",
    "        for inputs in inputs_ds:\n",
    "            relations = []\n",
    "            sources = []\n",
    "            targets = []\n",
    "            for model in self.models:\n",
    "                output = model(list(inputs))\n",
    "                for i, (relation, source, target) in enumerate(zip(*output)):\n",
    "                    if i == len(relations):\n",
    "                        relations.append([])\n",
    "                    relations[i].append(relation)\n",
    "                    if i == len(sources):\n",
    "                        sources.append([])\n",
    "                    sources[i].append(source)\n",
    "                    if i == len(targets):\n",
    "                        targets.append([])\n",
    "                    targets[i].append(target)\n",
    "            outputs[0].extend(relations)\n",
    "            outputs[1].extend(sources)\n",
    "            outputs[2].extend(targets)\n",
    "        return self.__decode_outputs(outputs)\n",
    "\n",
    "def build_link_prediction_model(params: dict):\n",
    "    models = params[params['model_name']]\n",
    "    sequence_vectorizer = params['sequence_vectorizer']\n",
    "    proposition_tag_vectorizer = params['proposition_tag_vectorizer']\n",
    "    relation_tag_vectorizer = params['relation_tag_vectorizer']\n",
    "    distance_encoding_bits = params['max_distance_encoded'] * 2\n",
    "    \n",
    "    \n",
    "    model = LinkPredictionModel(\n",
    "        models=models,\n",
    "        sequence_vectorizer=sequence_vectorizer,\n",
    "        proposition_tag_vectorizer=proposition_tag_vectorizer,\n",
    "        relation_tag_vectorizer=relation_tag_vectorizer,\n",
    "        distance_encoding_bits=distance_encoding_bits\n",
    "    )\n",
    "    \n",
    "    source = \"muchos años , la gente tenía que pagar una gran cantidad de dinero prar enviar sus cartas , y sus pagos estaban relacionados con el peso de sus cartas o cajas , y muchos accidentes pueden causar el problema de que el correo no se pueda entregar\"\n",
    "    target = \"electrónico puede contarse como uno de los resultados más beneficiosos de la tecnología moderna\"\n",
    "    \n",
    "    result = model([source, source, source], [target, target, target], [-1, 0 , 1])\n",
    "    \n",
    "    print(result)\n",
    "    print(len(result))\n",
    "\n",
    "    params[params['model_name'] + \"_final\"] = model\n",
    "    \n",
    "build_link_prediction_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1\n",
      "batch: 2\n",
      "batch: 3\n",
      "batch: 4\n",
      "batch: 5\n",
      "batch: 6\n",
      "batch: 7\n",
      "batch: 8\n",
      "batch: 9\n",
      "batch: 10\n",
      "batch: 11\n",
      "batch: 12\n",
      "batch: 13\n",
      "batch: 14\n",
      "batch: 15\n",
      "batch: 16\n",
      "batch: 17\n",
      "batch: 18\n",
      "batch: 19\n",
      "batch: 20\n",
      "batch: 21\n",
      "batch: 22\n",
      "batch: 23\n",
      "batch: 24\n",
      "batch: 25\n",
      "batch: 26\n",
      "batch: 27\n",
      "batch: 28\n",
      "batch: 29\n",
      "batch: 30\n",
      "batch: 31\n",
      "batch: 32\n",
      "batch: 33\n",
      "batch: 34\n",
      "batch: 35\n",
      "batch: 36\n",
      "batch: 37\n",
      "batch: 38\n",
      "batch: 39\n",
      "batch: 40\n",
      "batch: 41\n",
      "batch: 42\n",
      "batch: 43\n",
      "batch: 44\n",
      "batch: 45\n",
      "batch: 46\n",
      "batch: 47\n",
      "batch: 48\n",
      "batch: 49\n",
      "batch: 50\n",
      "batch: 51\n",
      "batch: 52\n",
      "batch: 53\n",
      "batch: 54\n",
      "batch: 55\n",
      "batch: 56\n",
      "batch: 57\n",
      "batch: 58\n",
      "batch: 59\n",
      "batch: 60\n",
      "batch: 61\n",
      "batch: 62\n",
      "batch: 63\n",
      "batch: 64\n",
      "batch: 65\n",
      "batch: 66\n",
      "batch: 67\n",
      "batch: 68\n",
      "batch: 69\n",
      "batch: 70\n",
      "batch: 71\n",
      "batch: 72\n",
      "batch: 73\n",
      "batch: 74\n",
      "batch: 75\n",
      "batch: 76\n",
      "batch: 77\n",
      "batch: 78\n",
      "batch: 79\n",
      "batch: 80\n",
      "batch: 81\n",
      "batch: 82\n",
      "batch: 83\n",
      "batch: 84\n",
      "batch: 85\n",
      "batch: 86\n",
      "batch: 87\n",
      "batch: 88\n",
      "batch: 89\n",
      "batch: 90\n",
      "batch: 91\n",
      "batch: 92\n",
      "batch: 93\n",
      "batch: 94\n",
      "batch: 95\n",
      "batch: 96\n",
      "batch: 97\n",
      "batch: 98\n",
      "batch: 99\n",
      "batch: 100\n",
      "batch: 101\n",
      "batch: 102\n",
      "                                         source_prop_text  \\\n",
      "count                                                3236   \n",
      "unique                                               1035   \n",
      "top     vivir con un compañero de cuarto también me pe...   \n",
      "freq                                                   10   \n",
      "\n",
      "                                         target_prop_text source_prop_type  \\\n",
      "count                                                3236             3236   \n",
      "unique                                               1035                2   \n",
      "top     vivir con un compañero de cuarto me permite ob...          Premise   \n",
      "freq                                                   12             2306   \n",
      "\n",
      "       target_prop_type relation_type infered_source_prop_type  \\\n",
      "count              3236          3236                     3236   \n",
      "unique                2             5                        1   \n",
      "top             Premise                                Premise   \n",
      "freq               2302          1618                     3236   \n",
      "\n",
      "       infered_target_prop_type infered_relation_type  \\\n",
      "count                      3236                  3236   \n",
      "unique                        2                     3   \n",
      "top                     Premise                         \n",
      "freq                       2805                  1618   \n",
      "\n",
      "                                   distance  \n",
      "count                                  3236  \n",
      "unique                                   19  \n",
      "top     tf.Tensor(0, shape=(), dtype=int32)  \n",
      "freq                                   1618  \n"
     ]
    }
   ],
   "source": [
    "def compute_statistic(params: dict):\n",
    "    data_dataframe = params[f'raw_test_data_dataframe']\n",
    "\n",
    "    statistic = {\n",
    "        'source_prop_text': [],\n",
    "        'target_prop_text': [],\n",
    "        'source_prop_type': [],\n",
    "        'target_prop_type': [],\n",
    "        'relation_type': [],\n",
    "        'infered_source_prop_type': [],\n",
    "        'infered_target_prop_type': [],\n",
    "        'infered_relation_type': [], \n",
    "        'distance': [],\n",
    "    }\n",
    "    \n",
    "    source_ds = tf.data.Dataset.from_tensor_slices(data_dataframe['source_prop_text'])\n",
    "    target_ds = tf.data.Dataset.from_tensor_slices(data_dataframe['target_prop_text'])\n",
    "    distance_ds = tf.data.Dataset.from_tensor_slices(list(data_dataframe['distance'].to_numpy(dtype=int)))\n",
    "    source_tag_ds = tf.data.Dataset.from_tensor_slices(data_dataframe['source_prop_type'])\n",
    "    target_tag_ds = tf.data.Dataset.from_tensor_slices(data_dataframe['target_prop_type'])\n",
    "    relation_tag_ds = tf.data.Dataset.from_tensor_slices(data_dataframe['relation_type'])\n",
    "\n",
    "    batch_num = 1\n",
    "    for sources, targets, distances, source_tags, target_tags, relation_tags in tf.data.Dataset.zip((source_ds, target_ds, distance_ds, source_tag_ds, target_tag_ds, relation_tag_ds)).batch(32):\n",
    "        print(\"batch:\", batch_num)\n",
    "        batch_num += 1\n",
    "        \n",
    "        inference = model(sources, targets, distances)\n",
    "        \n",
    "        statistic['source_prop_text'].extend([x.numpy().decode() for x in sources])\n",
    "        statistic['target_prop_text'].extend([x.numpy().decode() for x in targets])\n",
    "        statistic['source_prop_type'].extend([x.numpy().decode() for x in source_tags])\n",
    "        statistic['target_prop_type'].extend([x.numpy().decode() for x in target_tags])\n",
    "        statistic['relation_type'].extend([x.numpy().decode() for x in relation_tags])\n",
    "        statistic['distance'].extend(distances)\n",
    "        \n",
    "        for relation_tag, source_tag, target_tag in inference:\n",
    "            statistic['infered_source_prop_type'].append(source_tag)\n",
    "            statistic['infered_target_prop_type'].append(target_tag)\n",
    "            statistic['infered_relation_type'].append(relation_tag)\n",
    "        \n",
    "        if not params['in_production']:\n",
    "            if batch_num > 10:\n",
    "                break\n",
    "    \n",
    "    statistic = pandas.DataFrame(statistic)\n",
    "    print(statistic.describe())\n",
    "    params['statistic'] = statistic\n",
    "    \n",
    "compute_statistic(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show statistic\n",
    "\n",
    "- [ ] Calculate consistency (If support or Inverse_support are present its inverse should be present as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "Relation Accuracy: 0.8247836835599506\n",
      "Source Accuracy: 0.7126081582200248\n",
      "Target Accuracy: 0.761742892459827\n",
      "Source Counter: Counter({'Premise': 2306, 'Claim': 930})\n",
      "Target Counter: Counter({'Premise': 2302, 'Claim': 934})\n",
      "Relation Counter: Counter({'': 1618, 'supports': 767, 'supports_Inverse': 767, 'attacks_Inverse': 42, 'attacks': 42})\n",
      "Relation\n",
      "                  precision    recall  f1-score   support\n",
      "\n",
      "                       1.00      1.00      1.00      1618\n",
      "         attacks       0.00      0.00      0.00        42\n",
      " attacks_Inverse       0.00      0.00      0.00        42\n",
      "        supports       0.65      0.68      0.66       767\n",
      "supports_Inverse       0.65      0.69      0.67       767\n",
      "\n",
      "        accuracy                           0.82      3236\n",
      "       macro avg       0.46      0.47      0.47      3236\n",
      "    weighted avg       0.81      0.82      0.82      3236\n",
      "\n",
      "Source\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Claim       0.00      0.00      0.00       930\n",
      "     Premise       0.71      1.00      0.83      2306\n",
      "\n",
      "    accuracy                           0.71      3236\n",
      "   macro avg       0.36      0.50      0.42      3236\n",
      "weighted avg       0.51      0.71      0.59      3236\n",
      "\n",
      "Target\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       Claim       0.69      0.32      0.44       934\n",
      "     Premise       0.77      0.94      0.85      2302\n",
      "\n",
      "    accuracy                           0.76      3236\n",
      "   macro avg       0.73      0.63      0.64      3236\n",
      "weighted avg       0.75      0.76      0.73      3236\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiUAAAHHCAYAAABgCSj/AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8qNh9FAAAACXBIWXMAAA9hAAAPYQGoP6dpAABM7klEQVR4nO3de1xUZf4H8M+ZgRnuN4FBEEG8oHhDMflhqbmRmL+8ZLtZ2YqUbCmYP0lTMwQ1pcKIbE1cFS2zlbaLa2q4hpGapJtK26aSNwQvIISCgNzmnN8fxOgIGMMMcGg+79frvLbzzPOc851i8ev3ec5zBEmSJBARERF1MEVHB0BEREQEMCkhIiIimWBSQkRERLLApISIiIhkgUkJERERyQKTEiIiIpIFJiVEREQkC0xKiIiISBaYlBAREZEsMCkhIiIiWWBSQmRmBEFo0ZGZmdnRoeo5fPgw4uPjcePGjY4OhYjaiEVHB0BE7Wvr1q165x988AH27dvXqL1fv37tGdZvOnz4MJYtW4YZM2bAycmpo8MhojbApITIzDzzzDN659999x327dvXqL01JElCVVUVrK2tjb4WEZkfTt8QUSObN2/GH/7wB7i7u0OtViMgIADr1q1r1M/X1xePPvoo9u7di2HDhsHa2hrr168HAFy8eBETJ06Era0t3N3dMW/ePOzdu7fJqaEjR45g3LhxcHR0hI2NDUaPHo1vv/1W93l8fDwWLFgAAOjRo4duiik3N7fN/h0QUftjpYSIGlm3bh369++PiRMnwsLCAl988QVmz54NURQRFRWl1zcnJwdPPfUUnn/+eURGRsLf3x8VFRX4wx/+gKtXr2Lu3Lnw8PDARx99hK+//rrRvfbv349HHnkEQUFBiIuLg0Kh0CVFBw8exPDhwzFlyhT8/PPP+Pvf/463334brq6uAAA3N7d2+fdBRO1EIiKzFhUVJd39q6CysrJRv7CwMMnPz0+vzcfHRwIgpaen67W/9dZbEgBpx44durZbt25Jffv2lQBIX3/9tSRJkiSKotS7d28pLCxMEkVR7/49evSQHn74YV1bYmKiBEC6cOFCa78qEckcp2+IqJE714SUlpaiuLgYo0ePxvnz51FaWqrXt0ePHggLC9NrS09Ph5eXFyZOnKhrs7KyQmRkpF6/7OxsnDlzBk8//TR++eUXFBcXo7i4GBUVFXjooYdw4MABiKLYBt+QiOSI0zdE1Mi3336LuLg4ZGVlobKyUu+z0tJSODo66s579OjRaPzFixfRs2dPCIKg196rVy+98zNnzgAAwsPDm42ltLQUzs7OBn8HIup8mJQQkZ5z587hoYceQt++fZGUlARvb2+oVCrs2bMHb7/9dqPKhTFP2jRcKzExEYGBgU32sbOza/X1iahzYVJCRHq++OILVFdXY+fOnejevbuuvalFqs3x8fHByZMnIUmSXrXk7Nmzev169uwJAHBwcEBoaOg9r3l31YWIfn+4poSI9CiVSgD1e440KC0txebNm1t8jbCwMFy+fBk7d+7UtVVVVWHDhg16/YKCgtCzZ0+sXr0a5eXlja5TVFSk+2dbW1sA4I6uRL9jrJQQkZ6xY8dCpVJhwoQJeP7551FeXo4NGzbA3d0dV69ebdE1nn/+efz1r3/FU089hblz56Jr167Ytm0brKysANyueigUCmzcuBGPPPII+vfvj4iICHh5eeHy5cv4+uuv4eDggC+++AJAfQIDAEuWLMGTTz4JS0tLTJgwQZesEFHnx6SEiPT4+/vjk08+wauvvor58+fDw8MDs2bNgpubG5599tkWXcPOzg779+/HnDlz8M4778DOzg7Tp0/HiBEj8Pjjj+uSEwB48MEHkZWVhRUrVuCvf/0rysvL4eHhgeDgYDz//PO6fvfddx9WrFiBlJQUpKenQxRFXLhwgUkJ0e+IIN1ZoyUiakPJycmYN28eLl26BC8vr44Oh4hkhkkJEbWJW7du6T2ZU1VVhSFDhkCr1eLnn3/uwMiISK44fUNEbWLKlCno3r07AgMDUVpaig8//BCnT5/Gtm3bOjo0IpIpJiVE1CbCwsKwceNGbNu2DVqtFgEBAdi+fTumTp3a0aERkUxx+oaIiIhkgfuUEBERkSwwKSEiIiJZ4JqSDiCKIq5cuQJ7e3tunU1E1AlJkoSbN2/C09MTCkXb/f2+qqoKNTU1Rl9HpVLp7Q8kV0xKOsCVK1fg7e3d0WEQEZGR8vPz0a1btza5dlVVFXr42KHgmtboa3l4eODChQuyT0yYlHQAe3t7AMDgKa9CaSnvHxCi1nL886WODoGozdRV1uDgE6m63+dtoaamBgXXtLh4zBcO9q2vxpTdFOETlIuamhomJdRYw5SN0tIKSpW8f0CIWsvCVt3RIRC1ufaYgrezF2Bn3/r7iOg8ywSYlBAREcmYVhKhNWLzDq0kmi6YNsakhIiISMZESBDR+qzEmLHtjY8EExERkSywUkJERCRjIkQYMwFj3Oj2xaSEiIhIxrSSBK0Rb4QxZmx74/QNERERyQIrJURERDJmTgtdmZQQERHJmAgJWjNJSjh9Q0RERLLASgkREZGMmdP0DSslREREMtbw9I0xR2usXbsWvr6+sLKyQnBwMI4ePdps39raWixfvhw9e/aElZUVBg8ejPT0dIPvyaSEiIiI9KSlpSEmJgZxcXE4fvw4Bg8ejLCwMFy7dq3J/q+++irWr1+Pd999FydPnsQLL7yAxx57DCdOnDDovkxKiIiIZEw0wWGopKQkREZGIiIiAgEBAUhJSYGNjQ1SU1Ob7L9161a88sorGD9+PPz8/DBr1iyMHz8eb731lkH3ZVJCREQkY9pfn74x5jBETU0Njh07htDQUF2bQqFAaGgosrKymhxTXV0NKyv9t95bW1vj0KFDBt2bC12JiIhkTCvByLcE1/9vWVmZXrtarYZarW7Uv7i4GFqtFhqNRq9do9Hg9OnTTd4jLCwMSUlJGDVqFHr27ImMjAx89tln0Gq1BsXKSgkREZEZ8Pb2hqOjo+5ISEgw2bXfeecd9O7dG3379oVKpUJ0dDQiIiKgUBiWZrBSQkREJGOtXRdy53gAyM/Ph4ODg669qSoJALi6ukKpVKKwsFCvvbCwEB4eHk2OcXNzw44dO1BVVYVffvkFnp6eWLRoEfz8/AyKlZUSIiIiGRMhQGvEIUIAADg4OOgdzSUlKpUKQUFByMjIuB2DKCIjIwMhISH3jNXKygpeXl6oq6vDp59+ikmTJhn0XVkpISIiIj0xMTEIDw/HsGHDMHz4cCQnJ6OiogIREREAgOnTp8PLy0s3BXTkyBFcvnwZgYGBuHz5MuLj4yGKIl5++WWD7sukhIiISMZEqf4wZryhpk6diqKiIixduhQFBQUIDAxEenq6bvFrXl6e3nqRqqoqvPrqqzh//jzs7Owwfvx4bN26FU5OTgbdl0kJERGRjDVMwxgzvjWio6MRHR3d5GeZmZl656NHj8bJkydbdZ87cU0JERERyQIrJURERDLWUZWSjsCkhIiISMZESYAotT6xMGZse+P0DREREckCKyVEREQyxukbIiIikgUtFNAaMbFh2NtnOhaTEiIiIhmTjFxTInFNCREREZFhWCkhIiKSMa4pISIiIlnQSgpoJSPWlBixRX174/QNERERyQIrJURERDImQoBoRA1BROcplTApISIikjFzWlPC6RsiIiKSBVZKiIiIZMz4ha6cviEiIiITqF9TYsQL+Th9Q0RERGQYVkqIiIhkTDTy3Td8+oaIiIhMgmtKiIiISBZEKMxmnxKuKSEiIiJZYKWEiIhIxrSSAK1kxOZpRoxtb0xKiIiIZExr5EJXLadviIiIiAzDSgkREZGMiZICohFP34h8+oaIiIhMgdM3RERERO2MlRIiIiIZE2HcEzSi6UJpc0xKiIiIZMz4zdM6z6RI54mUiIiIftdYKSEiIpIx499903nqD50nUiIiIjMkQjD6aI21a9fC19cXVlZWCA4OxtGjR+/ZPzk5Gf7+/rC2toa3tzfmzZuHqqoqg+7JSgkREZGMdUSlJC0tDTExMUhJSUFwcDCSk5MRFhaGnJwcuLu7N+r/0UcfYdGiRUhNTcWIESPw888/Y8aMGRAEAUlJSS2+LyslREREpCcpKQmRkZGIiIhAQEAAUlJSYGNjg9TU1Cb7Hz58GPfffz+efvpp+Pr6YuzYsXjqqad+s7pyNyYlREREMtaweZoxBwCUlZXpHdXV1U3er6amBseOHUNoaKiuTaFQIDQ0FFlZWU2OGTFiBI4dO6ZLQs6fP489e/Zg/PjxBn1XTt8QERHJmCgJEI3Zp+TXsd7e3nrtcXFxiI+Pb9S/uLgYWq0WGo1Gr12j0eD06dNN3uPpp59GcXExHnjgAUiShLq6Orzwwgt45ZVXDIqVSQkREZEZyM/Ph4ODg+5crVab7NqZmZlYtWoV3nvvPQQHB+Ps2bOYO3cuVqxYgdjY2BZfh0kJERGRjIlGvvumYfM0BwcHvaSkOa6urlAqlSgsLNRrLywshIeHR5NjYmNj8ec//xkzZ84EAAwcOBAVFRX4y1/+giVLlkChaFn8XFNCREQkYw1vCTbmMIRKpUJQUBAyMjJuxyCKyMjIQEhISJNjKisrGyUeSqUSACAZ8JZiVkqIiIhIT0xMDMLDwzFs2DAMHz4cycnJqKioQEREBABg+vTp8PLyQkJCAgBgwoQJSEpKwpAhQ3TTN7GxsZgwYYIuOWkJJiVEREQypoUAbSs3QGsYb6ipU6eiqKgIS5cuRUFBAQIDA5Genq5b/JqXl6dXGXn11VchCAJeffVVXL58GW5ubpgwYQJWrlxp0H0FyZC6CplEWVkZHB0dMXTqa1CqrDo6HKI24fRsfkeHQNRm6iqq8fWjKSgtLW3ROo3WaPizYtmRUFjZtb6GUFVeh7jgr9o0VlPhmhIiIiKSBU7fEBERyZgWrZuCuXN8Z8GkhIiISMZa8wTN3eM7CyYlREREMtYRL+TrKJ0nUiIiIvpdY6WEiIhIxiQIEI1YUyIZMba9MSkhIiKSMU7fEBEREbUzVkqIiIhkTJQEiFLrp2CMGdvemJQQERHJmNbItwQbM7a9dZ5IiYiI6HeNlRIiIiIZ4/QNERERyYIIBUQjJjaMGdveOk+kRERE9LvGSgkREZGMaSUBWiOmYIwZ296YlBAREckY15QQERGRLEhGviVY4o6uRERERIZhpYSIiEjGtBCgNeKlesaMbW9MSoiIiGRMlIxbFyJKJgymjXH6hoiIiGThd18pEQQBn3/+OSZPntyi/vHx8dixYweys7PbNC4yzuMh/8Uzo3+Ai/0tnL3aBW/9836czHdvsu+DA84j/A8n0K1LGSyUIvKLHfHRgUFIP94HAKBUaPFC2L8R0jcfXl3KUF6lwr/PeOG9L4NRXGbbnl+LSEfaUQ6klQMlWqCnJTDHCUI/VfP9y0VgUxlw8BZwUwQ0SmC2E4T/sar/XCsB798Evqqsv2YXJTDOBnjGHoLQecr75kg0cqGrMWPbW+eJtBkFBQWYM2cO/Pz8oFar4e3tjQkTJiAjI6NV15s/f36rx1L7CB18FnMnZGHjV0EIf+dxnLnqguTndsPZ9laT/csqrbAlYygi107GM0l/xK5/++PVP2UiuE8+AMBKVQd/r2JszhiK8Hcex6IPxsLHrRSJM9Lb82sR6UhfVwLrSoHp9sB69/qkZGExpOvapvvXSsCCYqCgDoh3Ad7XAC85A27K2522lwM7K4AXnYAtGuAvjvVtn1e0z5eiVhMhGH10Fp26UpKbm4v7778fTk5OSExMxMCBA1FbW4u9e/ciKioKp0+fNviadnZ2sLOza4NoyVSeGvkj/nmkH3Z/3xcA8MZnozCibx4eve80tmYOadT/+HlPvfOPvx2I/x32Mwb7FuDIz96oqFLjxY2P6vVZveN+bH7xc2icbqLwhn3bfRmipvyjHBhvC+GR+kqdNM8J+K4K+LISeLqJn8cvK4EyEXjXDYLFr38Aedz16/2nauB+K13lBB4WkPZXAqdr2u57EBmoU1dKZs+eDUEQcPToUTz++OPo06cP+vfvj5iYGHz33XdNjlm4cCH69OkDGxsb+Pn5ITY2FrW1tbrP4+PjERgYqDufMWMGJk+ejFWrVkGj0cDJyQnLly9HXV0dFixYABcXF3Tr1g2bN29u669LACyUWvh7FeHfZ710bZIk4N9numGgT2ELriBhWK9L6O52A9kXujbby86qBqII3LylNkHURC0n1UrAz7VA0O2fPUEh1J+fbCaBOHwL6K8C3rkB6fGrkJ4thLTtZv2UTYP+auB4NaT8+t930rla4L81wHCrtvw6ZAINO7oac3QWnbZSUlJSgvT0dKxcuRK2to3n/Z2cnJocZ29vjy1btsDT0xM//vgjIiMjYW9vj5dffrnZe+3fvx/dunXDgQMH8O233+K5557D4cOHMWrUKBw5cgRpaWl4/vnn8fDDD6Nbt26m+orUBCfbKlgoJZTctNZrv15uDV/3G82Os7WqxhdLPoTKQoRWFJD4+QM4eqbp/1YqizpEjT+CfT/0QmV183P4RG2iVAREAM53/Z3RWQnkVTc95qoWOFENhNoACV2Ay3XAOzeAOgkId6jv85QdUCECM65BUqD+Hs85QAi1abvvQiZhTmtKOm1ScvbsWUiShL59+xo07tVXX9X9s6+vL+bPn4/t27ffMylxcXHBmjVroFAo4O/vjzfffBOVlZV45ZVXAACLFy/G66+/jkOHDuHJJ59sNL66uhrV1bd/mZSVlRkUMxmvslqF6cl/hLWqFvf1voy5E7JwpcSh0dSOUqHFyme+giAAb3w2soOiJTKQJNUnLTFOEJQC0EcFqVhbv1C2ISnJvAVk3AKWOAO+lsDZWuC9G5C6KCCEcUE3yUOnTUokqXUPXqelpWHNmjU4d+4cysvLUVdXBwcHh3uO6d+/PxSK25mmRqPBgAEDdOdKpRJdunTBtWvXmhyfkJCAZcuWtSpe0nejwgp1WgEu9vqLWp3tbuGXu6ond5IkAZd+cQQAnLnqCl/3G5g+5oReUtKQkHg43UTU3yawSkIdw1FRP7F+XdRvv64FXJRNDoGLErAQ6hOSBt0tgRIRUq0EwVIA1pcBT9lB+MOvlRE/S0iFdcBH5QCTElkTYeS7bzrRQtfOU9O5S+/evSEIgkGLWbOysjBt2jSMHz8eu3btwokTJ7BkyRLU1Nx7oZelpaXeuSAITbaJ4l2/RH61ePFilJaW6o78/PwWx0z66rRK5Fx2w329LuvaBEHCfb0u48eLmhZfRxAkqCxuP8nQkJB4u5ZizoZHUVbJeXbqGIKlAPSxBI7frq5KolR/HtBMojxABVyuq+/X4FId0EVRfz0AqBbR6M8mpVBfZSFZk4x88kbqRElJp62UuLi4ICwsDGvXrsWLL77YaF3JjRs3Gq0rOXz4MHx8fLBkyRJd28WLF9s8VrVaDbWaCyZN5e8HByL2iUycuuSGk/numPrAj7BS1WL39/4AgKVT96Oo1Bbr0oMBANPHnMDpS2649IsDVBZajOibh0eGnsGbnz8AoD4hSfjzPvh7FeOlzY9AIUhwsasEAJTdUqNO28zfTonayp/sgNevQ/K3BPqqgE/LgSqpfl8RAFJCCeCqhBBZX/3DRFtgRwXw11JIj9kCl7XARzeBx+54kjDEGth2E5LGAvC1AM7U1j/l8wjXlMgd3xLcSaxduxb3338/hg8fjuXLl2PQoEGoq6vDvn37sG7dOpw6dUqvf+/evZGXl4ft27fjvvvuw+7du/H55593UPTUWl/90AtOtlWIHPs9uthX4swVV8zbNB4l5fW/XD2cyiHd8X9Ca1UtFjx2EG6OFaiutcDFa06I3z4GX/3QCwDg7liJUf3rk9MP532id6/ZKRMarTshamvCGBtIN0Rg8836aZuelsAbrhAapm+uaQHF7Z9xwd0C0htdgPdKgZkVgKsSmGIHPHlHUjLHEUgVgOQbwI1fN0971LZ+LxQimejUSYmfnx+OHz+OlStX4qWXXsLVq1fh5uaGoKAgrFu3rlH/iRMnYt68eYiOjkZ1dTX+93//F7GxsYiPj2//4MkonxwegE8OD2jys9nrJ+qdr987HOv3Dm/2Wlev2+N/Xn7epPERGUt4zE6/0nHnZ2+7NW7rrwbWNr2rMQAINgog2gmINlWE1F466umbtWvXIjExEQUFBRg8eDDeffddDB/e9O/SBx98EN98802j9vHjx2P37t0tvqcgtXbFKLVaWVkZHB0dMXTqa1CquHaBfp+cnuXaKfr9qquoxtePpqC0tPQ3H5ZorYY/Kyb961lY2rZ+4X1tRQ3+OTbVoFjT0tIwffp0pKSkIDg4GMnJyfjHP/6BnJwcuLs3Tn5LSkr01mf+8ssvGDx4MDZu3IgZM2a0ONZOu9CViIiI2kZSUhIiIyMRERGBgIAApKSkwMbGBqmpqU32d3FxgYeHh+7Yt28fbGxs8Kc//cmg+zIpISIikjFTvfumrKxM77hz/6w71dTU4NixYwgNDdW1KRQKhIaGIisrq0Uxb9q0CU8++WSTm5veC5MSIiIiGWt4+saYAwC8vb3h6OioOxISEpq8X3FxMbRaLTQa/W0WNBoNCgoKfjPeo0eP4r///S9mzpxp8Hft1AtdiYiIqGXy8/P11pS01VYVmzZtwsCBA5tdFHsvTEqIiIhkzFT7lDg4OLRooaurqyuUSiUKC/VfclpYWAgPD497jq2oqMD27duxfPnyVsXK6RsiIiIZM9X0TUupVCoEBQUhIyPjdgyiiIyMDISEhNxz7D/+8Q9UV1fjmWeeadV3ZaWEiIiI9MTExCA8PBzDhg3D8OHDkZycjIqKCkRERAAApk+fDi8vr0brUjZt2oTJkyejS5curbovkxIiIiIZ64ht5qdOnYqioiIsXboUBQUFCAwMRHp6um7xa15ent6LagEgJycHhw4dwr/+9a9Wx8qkhIiISMYkGPem39bukBodHY3o6Ka3AM7MzGzU5u/vD2P3Y2VSQkREJGPm9EI+LnQlIiIiWWClhIiISMbMqVLCpISIiEjGzCkp4fQNERERyQIrJURERDJmTpUSJiVEREQyJkkCJCMSC2PGtjdO3xAREZEssFJCREQkYyIEozZPM2Zse2NSQkREJGPmtKaE0zdEREQkC6yUEBERyZg5LXRlUkJERCRj5jR9w6SEiIhIxsypUsI1JURERCQLrJQQERHJmGTk9E1nqpQwKSEiIpIxCYAkGTe+s+D0DREREckCKyVEREQyJkKAwB1diYiIqKPx6RsiIiKidsZKCRERkYyJkgCBm6cRERFRR5MkI5++6USP33D6hoiIiGSBlRIiIiIZM6eFrkxKiIiIZIxJCREREcmCOS105ZoSIiIikgVWSoiIiGTMnJ6+YVJCREQkY/VJiTFrSkwYTBvj9A0RERHJApMSIiIiGWt4+saYozXWrl0LX19fWFlZITg4GEePHr1n/xs3biAqKgpdu3aFWq1Gnz59sGfPHoPuyekbIiIiGZN+PYwZb6i0tDTExMQgJSUFwcHBSE5ORlhYGHJycuDu7t6of01NDR5++GG4u7vjk08+gZeXFy5evAgnJyeD7sukhIiIiPQkJSUhMjISERERAICUlBTs3r0bqampWLRoUaP+qampKCkpweHDh2FpaQkA8PX1Nfi+nL4hIiKSMVNN35SVlekd1dXVTd6vpqYGx44dQ2hoqK5NoVAgNDQUWVlZTY7ZuXMnQkJCEBUVBY1GgwEDBmDVqlXQarUGfVcmJURERHImmeAA4O3tDUdHR92RkJDQ5O2Ki4uh1Wqh0Wj02jUaDQoKCpocc/78eXzyySfQarXYs2cPYmNj8dZbb+G1114z6Kty+oaIiEjOjNxmHr+Ozc/Ph4ODg65ZrVYbG5mOKIpwd3fH3/72NyiVSgQFBeHy5ctITExEXFxci6/DpISIiMgMODg46CUlzXF1dYVSqURhYaFee2FhITw8PJoc07VrV1haWkKpVOra+vXrh4KCAtTU1EClUrUoRk7fEBERyVjDjq7GHIZQqVQICgpCRkaGrk0URWRkZCAkJKTJMffffz/Onj0LURR1bT///DO6du3a4oQEYFJCREQkax2xT0lMTAw2bNiA999/H6dOncKsWbNQUVGhexpn+vTpWLx4sa7/rFmzUFJSgrlz5+Lnn3/G7t27sWrVKkRFRRl0X07fEBERkZ6pU6eiqKgIS5cuRUFBAQIDA5Genq5b/JqXlweF4nZdw9vbG3v37sW8efMwaNAgeHl5Ye7cuVi4cKFB92VSQkREJGeSoFus2urxrRAdHY3o6OgmP8vMzGzUFhISgu+++65V92rApISIiEjGzOktwVxTQkRERLLASgkREZGcdcTLbzpIi5KSnTt3tviCEydObHUwREREpM+YN/02jO8sWpSUTJ48uUUXEwTB4H3uiYiIiIAWJiV3boZCRERE7awTTcEYw6g1JVVVVbCysjJVLERERHQXc5q+MfjpG61WixUrVsDLywt2dnY4f/48ACA2NhabNm0yeYBERERmzURvCe4MDE5KVq5ciS1btuDNN9/U289+wIAB2Lhxo0mDIyIiIvNhcFLywQcf4G9/+xumTZum9zbAwYMH4/Tp0yYNjoiIiAQTHJ2DwWtKLl++jF69ejVqF0URtbW1JgmKiIiIfmVG+5QYXCkJCAjAwYMHG7V/8sknGDJkiEmCIiIiIvNjcKVk6dKlCA8Px+XLlyGKIj777DPk5OTggw8+wK5du9oiRiIiIvPFSknzJk2ahC+++AJfffUVbG1tsXTpUpw6dQpffPEFHn744baIkYiIyHw1vCXYmKOTaNU+JSNHjsS+fftMHQsRERGZsVZvnvb999/j1KlTAOrXmQQFBZksKCIiIqonSfWHMeM7C4OTkkuXLuGpp57Ct99+CycnJwDAjRs3MGLECGzfvh3dunUzdYxERETmi2tKmjdz5kzU1tbi1KlTKCkpQUlJCU6dOgVRFDFz5sy2iJGIiIjMgMGVkm+++QaHDx+Gv7+/rs3f3x/vvvsuRo4cadLgiIiIzJ6xi1V/zwtdvb29m9wkTavVwtPT0yRBERERUT1Bqj+MGd9ZGDx9k5iYiDlz5uD777/XtX3//feYO3cuVq9ebdLgiIiIzJ4ZvZCvRZUSZ2dnCMLt8k9FRQWCg4NhYVE/vK6uDhYWFnj22WcxefLkNgmUiIiIft9alJQkJye3cRhERETUJK4p0RceHt7WcRAREVFTzOiR4FZvngYAVVVVqKmp0WtzcHAwKiAiIiIyTwYvdK2oqEB0dDTc3d1ha2sLZ2dnvYOIiIhMyIwWuhqclLz88svYv38/1q1bB7VajY0bN2LZsmXw9PTEBx980BYxEhERmS8zSkoMnr754osv8MEHH+DBBx9EREQERo4ciV69esHHxwfbtm3DtGnT2iJOIiIi+p0zuFJSUlICPz8/APXrR0pKSgAADzzwAA4cOGDa6IiIiMxdw9M3xhydhMFJiZ+fHy5cuAAA6Nu3Lz7++GMA9RWUhhf0ERERkWk07OhqzNFZGJyURERE4IcffgAALFq0CGvXroWVlRXmzZuHBQsWmDxAIiIiMg8GJyXz5s3Diy++CAAIDQ3F6dOn8dFHH+HEiROYO3euyQMkIiIyax200HXt2rXw9fWFlZUVgoODcfTo0Wb7btmyBYIg6B1WVlYG39OofUoAwMfHBz4+PsZehoiIiGQiLS0NMTExSElJQXBwMJKTkxEWFoacnBy4u7s3OcbBwQE5OTm68ztfT9NSLUpK1qxZ0+ILNlRRiIiIyHgCjHxLcCvGJCUlITIyEhEREQCAlJQU7N69G6mpqVi0aFHT9xEEeHh4tD5QtDApefvtt1t0MUEQmJQQERHJUFlZmd65Wq2GWq1u1K+mpgbHjh3D4sWLdW0KhQKhoaHIyspq9vrl5eXw8fGBKIoYOnQoVq1ahf79+xsUY4uSkoanbci0HNL+DQvBsqPDIGoT6W9md3QIRG2m7KaIdtvD3EQv5PP29tZrjouLQ3x8fKPuxcXF0Gq10Gg0eu0ajQanT59u8hb+/v5ITU3FoEGDUFpaitWrV2PEiBH46aef0K1btxaHavSaEiIiImpDJnohX35+vt776ZqqkrRWSEgIQkJCdOcjRoxAv379sH79eqxYsaLF12FSQkREZAYcHBxa9NJcV1dXKJVKFBYW6rUXFha2eM2IpaUlhgwZgrNnzxoUo8GPBBMREVE7audHglUqFYKCgpCRkaFrE0URGRkZetWQe9Fqtfjxxx/RtWtXg+7NSgkREZGMGbsra2vGxsTEIDw8HMOGDcPw4cORnJyMiooK3dM406dPh5eXFxISEgAAy5cvx//8z/+gV69euHHjBhITE3Hx4kXMnDnToPsyKSEiIiI9U6dORVFREZYuXYqCggIEBgYiPT1dt/g1Ly8PCsXtyZbr168jMjISBQUFcHZ2RlBQEA4fPoyAgACD7itIkmRwDnXw4EGsX78e586dwyeffAIvLy9s3boVPXr0wAMPPGDo5cxOWVkZHB0d8SAm8ekb+t3aeyW7o0MgajNlN0U49zmP0tLSFq3TaNU9fv2zwve1lVC0YnfUBmJVFXJfXdKmsZqKwWtKPv30U4SFhcHa2honTpxAdXU1AKC0tBSrVq0yeYBERERmrYO2me8IBiclr732GlJSUrBhwwZYWt7+W/7999+P48ePmzQ4IiIiMh8GrynJycnBqFGjGrU7Ojrixo0bpoiJiIiIftURC107isGVEg8PjyafOz506BD8/PxMEhQRERH9qmFHV2OOTsLgpCQyMhJz587FkSNHIAgCrly5gm3btmH+/PmYNWtWW8RIRERkvsxoTYnB0zeLFi2CKIp46KGHUFlZiVGjRkGtVmP+/PmYM2dOW8RIREREZsDgpEQQBCxZsgQLFizA2bNnUV5ejoCAANjZ2bVFfERERGbNnNaUtHrzNJVKZfCmKERERGQgE72QrzMwOCkZM2YMBKH5RTP79+83KiAiIiIyTwYnJYGBgXrntbW1yM7Oxn//+1+Eh4ebKi4iIiICACOnb37XlZK33367yfb4+HiUl5cbHRARERHdwYymbwx+JLg5zzzzDFJTU011OSIiIjIzJntLcFZWFqyMeGEQERERNcGMKiUGJyVTpkzRO5ckCVevXsX333+P2NhYkwVGREREfCT4nhwdHfXOFQoF/P39sXz5cowdO9ZkgREREZF5MSgp0Wq1iIiIwMCBA+Hs7NxWMREREZEZMmihq1KpxNixY/k2YCIiovZiRu++MfjpmwEDBuD8+fNtEQsRERHdpWFNiTFHZ2FwUvLaa69h/vz52LVrF65evYqysjK9g4iIiKg1WrymZPny5XjppZcwfvx4AMDEiRP1tpuXJAmCIECr1Zo+SiIiInPWiaodxmhxUrJs2TK88MIL+Prrr9syHiIiIroT9ylpTJLqv9Xo0aPbLBgiIiIyXwY9EnyvtwMTERGR6XHztGb06dPnNxOTkpISowIiIiKiO3D6pmnLli1rtKMrERERkSkYlJQ8+eSTcHd3b6tYiIiI6C6cvmkC15MQERF1ADOavmnx5mkNT98QERERtYUWV0pEUWzLOIiIiKgpZlQpMWhNCREREbUvc1pTYvC7b4iIiKgdddBbgteuXQtfX19YWVkhODgYR48ebdG47du3QxAETJ482eB7MikhIiIiPWlpaYiJiUFcXByOHz+OwYMHIywsDNeuXbvnuNzcXMyfPx8jR45s1X2ZlBAREclZB1RKkpKSEBkZiYiICAQEBCAlJQU2NjZITU1tdoxWq8W0adOwbNky+Pn5GX5TMCkhIiKStYY1JcYchqipqcGxY8cQGhqqa1MoFAgNDUVWVlaz45YvXw53d3c899xzrf2qXOhKRERkDsrKyvTO1Wo11Gp1o37FxcXQarXQaDR67RqNBqdPn27y2ocOHcKmTZuQnZ1tVIyslBAREcmZiaZvvL294ejoqDsSEhJMEt7Nmzfx5z//GRs2bICrq6tR12KlhIiISMZM9Uhwfn4+HBwcdO1NVUkAwNXVFUqlEoWFhXrthYWF8PDwaNT/3LlzyM3NxYQJE3RtDXubWVhYICcnBz179mxRrKyUEBERmQEHBwe9o7mkRKVSISgoCBkZGbo2URSRkZGBkJCQRv379u2LH3/8EdnZ2bpj4sSJGDNmDLKzs+Ht7d3iGFkpISIikrMO2NE1JiYG4eHhGDZsGIYPH47k5GRUVFQgIiICADB9+nR4eXkhISEBVlZWGDBggN54JycnAGjU/luYlBAREclZByQlU6dORVFREZYuXYqCggIEBgYiPT1dt/g1Ly8PCoXpJ1uYlBAREVEj0dHRiI6ObvKzzMzMe47dsmVLq+7JpISIiEjGhF8PY8Z3FkxKiIiI5IxvCSYiIiI54FuCiYiIiNoZKyVERERyxukbIiIiko1OlFgYg9M3REREJAuslBAREcmYOS10ZVJCREQkZ2a0poTTN0RERCQLrJQQERHJGKdviIiISB44fUNERETUvlgpISIikjFO3xAREZE8mNH0DZMSIiIiOTOjpIRrSoiIiEgWWCkhIiKSMa4pISIiInng9A0RERFR+2KlhIiISMYESYIgtb7cYczY9sakhIiISM44fUNERETUvlgpISIikjE+fUNERETywOkbIiIiovbFSgkREZGMcfqGiIiI5MGMpm+YlBAREcmYOVVKuKaEiIiIZIGVEiIiIjkzo+kbVkqIiIhkrmEKpzVHa61duxa+vr6wsrJCcHAwjh492mzfzz77DMOGDYOTkxNsbW0RGBiIrVu3GnxPJiVERESkJy0tDTExMYiLi8Px48cxePBghIWF4dq1a032d3FxwZIlS5CVlYX//Oc/iIiIQEREBPbu3WvQfZmUEBERyZkkGX8YKCkpCZGRkYiIiEBAQABSUlJgY2OD1NTUJvs/+OCDeOyxx9CvXz/07NkTc+fOxaBBg3Do0CGD7sukhIiISMaMmbppzRROTU0Njh07htDQUF2bQqFAaGgosrKyfnO8JEnIyMhATk4ORo0aZdC9udCViIjIDJSVlemdq9VqqNXqRv2Ki4uh1Wqh0Wj02jUaDU6fPt3s9UtLS+Hl5YXq6moolUq89957ePjhhw2KkZUSIiIiOZNMcADw9vaGo6Oj7khISDBpmPb29sjOzsa///1vrFy5EjExMcjMzDToGqyUEBERyZgg1h/GjAeA/Px8ODg46NqbqpIAgKurK5RKJQoLC/XaCwsL4eHh0ex9FAoFevXqBQAIDAzEqVOnkJCQgAcffLDFsbJSQkREZAYcHBz0juaSEpVKhaCgIGRkZOjaRFFERkYGQkJCWnw/URRRXV1tUIyslADIzc1Fjx49cOLECQQGBnZ0ONSECTOK8cdZ1+DiVofzJ63x3qteyMm2abb/yEdvIPzlAmi61eDyBTU2reyKf++//TeEl97Ow9ip1/XGfP+1PZZM89Ode/lVIzL2CgLuq4CFpYQLp6zwwZtd8cNhO9N/QaK77Nzsik/WuaOkyAJ+Abcw+7XL6Dukssm+dbXA9nc1+OofLigusES3ntV4bskV3DfmZpP90951R2qCJybPLMKs5Zfb8muQKXTA5mkxMTEIDw/HsGHDMHz4cCQnJ6OiogIREREAgOnTp8PLy0s3BZSQkIBhw4ahZ8+eqK6uxp49e7B161asW7fOoPt2aFIyY8YMvP/++wAAS0tLdO/eHdOnT8crr7wCC4v2C83b2xtXr16Fq6tru92TWm70xOv4S9wVvLuoG04ft8FjkUVY+dF5PDfSH6W/WDbqHzCsAovfu4jUhK44ss8BYx67jrjUXESF9cbFHGtdv3/vt8db87x157U1gt51lr9/HpcvqLHwTz1RXaXAY5FFWP7BBcwI6YvrRY3vS2Qqmf90wt+WeWLO65fQd2gFPt/ghiVP+2HTwdNwcq1r1H/LG12x/zNn/F9iPrx7VeP7THssf64H3v7nGfQaeEuvb062NXZ/2AU9Am41ug7JU0e8+2bq1KkoKirC0qVLUVBQgMDAQKSnp+sWv+bl5UGhuD3ZUlFRgdmzZ+PSpUuwtrZG37598eGHH2Lq1KkG3bfDp2/GjRuHq1ev4syZM3jppZcQHx+PxMTERv1qamraLAalUgkPD492TYSo5ab8pRjpH7ngX2kuyDtjhTULu6H6loCwp0qa7D95ZhG+/9oen6xzR/5ZK3yQ2BVnf7TGpIhf9PrV1gi4XmSpO8pLb//3d3CpQ7eeNfj4r+64cMoaVy6okbqyK6xsRPj2rWrT70v02d/cMO7pXxD2ZAl8+lTjxTcuQW0tYu/fXZrsn/GpC56ccw3DH7qJrj41mBD+C+77Qxk+Xe+m1+9WhQJvRPvg/xLzYe+obY+vQqbQAfuUAEB0dDQuXryI6upqHDlyBMHBwbrPMjMzsWXLFt35a6+9hjNnzuDWrVsoKSnB4cOHDU5IABkkJWq1Gh4eHvDx8cGsWbMQGhqKnTt3YsaMGZg8eTJWrlwJT09P+Pv7A6hfqPPEE0/AyckJLi4umDRpEnJzc3XXaxi3atUqaDQaODk5Yfny5airq8OCBQvg4uKCbt26YfPmzboxubm5EAQB2dnZAIDr169j2rRpcHNzg7W1NXr37q3X/7diINOxsBTRe1Aljh+017VJkoATB+0RENR0KbtfUCVO3NEfAI59Y49+QRV6bYNCypH2n5+w8eBpzEm4BHvn238DLStRIv+sGqF/ug61tRYKpYT//fMvuF5kgTP/sQZRW6mtEXDmPzYYOrJc16ZQAENGluPkMdtmx6jU+ish1VYifjqqP9X411e6YfhDZRg6qhxEctThScndrK2tdVWRhs1X9u3bh127dqG2thZhYWGwt7fHwYMH8e2338LOzg7jxo3Tq6Ts378fV65cwYEDB5CUlIS4uDg8+uijcHZ2xpEjR/DCCy/g+eefx6VLl5qMITY2FidPnsSXX36JU6dOYd26dbqpnZbGcKfq6mqUlZXpHdQyDi5aKC2AG0X6VazrxRZwdmtcxgYAZ7c6XC++q3+RBZzdb/f/PtMeiXO7Y+ETfti0sisGhpRj5YfnoVA0/I1CwKKpfug54BZ2nPkvdl34D6b8pQhLpvXQq6gQmVpZiRKiVoCTW61eu7NrLa4XNf2zFzT6Jj79mxsun1dBFIFj39jh2z1OKLl2u3/mDiec/dEazy6+2qbxk+m19+ZpHUk2v10bdoDbu3cv5syZg6KiItja2mLjxo1QqVQAgA8//BCiKGLjxo0QhPr5/82bN8PJyQmZmZkYO3YsgPo9+NesWQOFQgF/f3+8+eabqKysxCuvvAIAWLx4MV5//XUcOnQITz75ZKNY8vLyMGTIEAwbNgwA4Ovrq/ssLS2tRTHcKSEhAcuWLTPdvywy2jf/dNb9c+5pa1w4aYX3vzuNQSPKkX3IHoCE6FWXcaPYAi891gs1VQLGPVWCZVty8eL43ii5xjUlJB+zVlxC8vzumDmqHyAAnj7VGDv1F+xN6wIAuHbZEuuWeiFh+zmorDrRn1BUz4zeEtzhScmuXbtgZ2eH2tpaiKKIp59+GvHx8YiKisLAgQN1CQkA/PDDDzh79izs7fVL81VVVTh37pzuvH///noLcDQaDQYMGKA7VyqV6NKlS7MvFpo1axYef/xxHD9+HGPHjsXkyZMxYsQIg2K40+LFixETE6M7Lysrg7e3d5N9SV9ZiRLaOsDprqqIs2tds39rvF5kAee7FgM6u9Xh+rXmf9wL8tS48YsSnr41yD4EBD5QjuGhZfhjvwGoLFcCAP76ow2GjjqF0CdK8PFfNc1ei8gYDi7104U37lpMfb3YstnqoFMXLeI3X0BNlYCy6xbo4lGLTSu7wqN7/eOYZ/9jgxvFlogK89eNEbUCfvzOFjs3u2JX7g9QKtvuOxG1VIcnJWPGjMG6deugUqng6empt9jU1lZ//rS8vBxBQUHYtm1bo+u4ud1e0GVpqf9/ZkEQmmwTxaZ3o3nkkUdw8eJF7NmzB/v27cNDDz2EqKgorF69usUx3Km5rXzpt9XVKnDmPzYY8sBNZKU7AgAEQULgA+XYuaVLk2NOHbNB4MhyfL7x9n+PoaNu4lQz8/EA4Nq1Bg7OWl25W21d/7Nx94+IKAlQCHePJjIdS5WE3oMqceKQHUY8Ugqg/ucw+5AdJs4ovudYlZUE1661qKsFDu1xwqgJNwAAgSNvYv1+/e3B35rXHd69qvBE1DUmJDLXEU/fdJQOT0psbW11O8D9lqFDhyItLQ3u7u56u9K1BTc3N4SHhyM8PBwjR47EggULsHr16naNgep99jdXzE/Ox88/2CDnRP0jwVY2Iv61vf5JhAXv5KG4wBKbE7oCAHZsdEPip2fx+PPXcDTDAaMn3UDvQbeQvKAbAMDKRotnXirEod2OuH7NEl19qzHz1au4ckGFY5n1FbBTx2xRXqrEgnfyse1tDaqrFHhk2i/w8K7B0Qz+d6e2NeUvRVj9f93RZ3Al/IdU4vMNbqiqVGDsk/VPnL35Yne4etTi2Vfq14ecPm6D4gJL9Ox/C8UFlvjwLQ9IIvDE7PpqsI1d46fGrGxE2Dtr+TRZZ2DEEzS68Z1Ehyclhpg2bRoSExMxadIkLF++HN26dcPFixfx2Wef4eWXX0a3bt1Mcp+lS5ciKCgI/fv3R3V1NXbt2oV+/fq1awx02zc7neHYRYvpCwrg7FaH8z9ZY8m0HrhRXF/9cvOq0atonPzeFq9H+SB8YQFmLCrAlQtqLHvWV7dHiSgK6NHvFh7+03XYOmjxS6EFjn9jj/ff9EBtTf20X1mJBZY87YcZi67ijY/PQWkp4WKOFeIjfHH+JJ++obb14KQbKP3FAh8kdsX1Igv49b+FldvO66Zvii6rcMcMNWqqBbz/RldczVPB2kbEfQ+V4eU1F2HHx36pk+lUSYmNjQ0OHDiAhQsXYsqUKbh58ya8vLzw0EMPmbRqoVKpsHjxYuTm5sLa2hojR47E9u3b2zUG0rdzsyt2bm56c7uX/9i40nZwlxMO7nJqsn9NlQJLnu75m/c88x+bFvUjaguTni3GpGebnq5J/PSs3vmgkAps+Kb5t7e25BokX+Y0fSNIUieq6/xOlJWVwdHREQ9iEiwEPsVBv097r2R3dAhEbabspgjnPudRWlraZn8hbfizImTcclhYWrX6OnW1VchKX9qmsZqK7PYpISIiIvPUqaZviIiIzI05Td8wKSEiIpIzUao/jBnfSTApISIikjMz2tGVa0qIiIhIFlgpISIikjEBRq4pMVkkbY9JCRERkZyZ0Y6unL4hIiIiWWClhIiISMb4SDARERHJA5++ISIiImpfrJQQERHJmCBJEIxYrGrM2PbGpISIiEjOxF8PY8Z3Epy+ISIiIllgpYSIiEjGOH1DRERE8mBGT98wKSEiIpIz7uhKRERE1L5YKSEiIpIx7uhKRERE8sDpGyIiIqL2xUoJERGRjAli/WHM+M6ClRIiIiI5a5i+MeZohbVr18LX1xdWVlYIDg7G0aNHm+27YcMGjBw5Es7OznB2dkZoaOg9+zeHSQkRERHpSUtLQ0xMDOLi4nD8+HEMHjwYYWFhuHbtWpP9MzMz8dRTT+Hrr79GVlYWvL29MXbsWFy+fNmg+zIpISIikjPJBIeBkpKSEBkZiYiICAQEBCAlJQU2NjZITU1tsv+2bdswe/ZsBAYGom/fvti4cSNEUURGRoZB92VSQkREJGMN28wbcwBAWVmZ3lFdXd3k/WpqanDs2DGEhobq2hQKBUJDQ5GVldWimCsrK1FbWwsXFxeDviuTEiIiIjPg7e0NR0dH3ZGQkNBkv+LiYmi1Wmg0Gr12jUaDgoKCFt1r4cKF8PT01EtsWoJP3xAREcmZifYpyc/Ph4ODg65ZrVYbG1mTXn/9dWzfvh2ZmZmwsrIyaCyTEiIiIjmTABjzWO+v+YyDg4NeUtIcV1dXKJVKFBYW6rUXFhbCw8PjnmNXr16N119/HV999RUGDRpkcKicviEiIpIxU60paSmVSoWgoCC9RaoNi1ZDQkKaHffmm29ixYoVSE9Px7Bhw1r1XVkpISIiIj0xMTEIDw/HsGHDMHz4cCQnJ6OiogIREREAgOnTp8PLy0u3LuWNN97A0qVL8dFHH8HX11e39sTOzg52dnYtvi+TEiIiIjmTYOSaEsOHTJ06FUVFRVi6dCkKCgoQGBiI9PR03eLXvLw8KBS3J1vWrVuHmpoa/PGPf9S7TlxcHOLj41t8XyYlREREctZBL+SLjo5GdHR0k59lZmbqnefm5rbqHnfjmhIiIiKSBVZKiIiI5EwEIBg5vpNgUkJERCRjrXmC5u7xnQWnb4iIiEgWWCkhIiKSsw5a6NoRmJQQERHJmRklJZy+ISIiIllgpYSIiEjOzKhSwqSEiIhIzvhIMBEREckBHwkmIiIiameslBAREckZ15QQERGRLIgSIBiRWIidJynh9A0RERHJAislREREcsbpGyIiIpIHI5MSdJ6khNM3REREJAuslBAREckZp2+IiIhIFkQJRk3B8OkbIiIiIsOwUkJERCRnklh/GDO+k2BSQkREJGdcU0JERESywDUlRERERO2LlRIiIiI54/QNERERyYIEI5MSk0XS5jh9Q0RERLLASgkREZGccfqGiIiIZEEUARix14jYefYp4fQNERERyQIrJURERHJmRtM3rJQQERHJWUNSYszRCmvXroWvry+srKwQHByMo0ePNtv3p59+wuOPPw5fX18IgoDk5ORW3ZNJCREREelJS0tDTEwM4uLicPz4cQwePBhhYWG4du1ak/0rKyvh5+eH119/HR4eHq2+L5MSIiIiORMl4w8DJSUlITIyEhEREQgICEBKSgpsbGyQmpraZP/77rsPiYmJePLJJ6FWq1v9VbmmhIiISMYkSYRkxJt+G8aWlZXptavV6iYTiJqaGhw7dgyLFy/WtSkUCoSGhiIrK6vVcbQEKyVERERyJhlZJfl1TYm3tzccHR11R0JCQpO3Ky4uhlarhUaj0WvXaDQoKCho06/KSgkREZEZyM/Ph4ODg+7cmGmWtsKkhIiISM4kCUa9wObXSomDg4NeUtIcV1dXKJVKFBYW6rUXFhYatYi1JTh9Q0REJGeiaPxhAJVKhaCgIGRkZNwRgoiMjAyEhISY+tvpYaWEiIiI9MTExCA8PBzDhg3D8OHDkZycjIqKCkRERAAApk+fDi8vL926lJqaGpw8eVL3z5cvX0Z2djbs7OzQq1evFt+XSQkREZGcmWj6xhBTp05FUVERli5dioKCAgQGBiI9PV23+DUvLw8Kxe3JlitXrmDIkCG689WrV2P16tUYPXo0MjMzW3xfJiVEREQyJokiJMH4R4INFR0djejo6CY/uzvR8PX1hWSC7ey5poSIiIhkgZUSIiIiOeuA6ZuOwqSEiIhIzkQJEMwjKeH0DREREckCKyVERERyJkkAWr/QtTNVSpiUEBERyZgkSpCMmL4xxVMx7YVJCRERkZxJIoyrlBgxtp1xTQkRERHJAislREREMsbpGyIiIpIHM5q+YVLSARqy1jrUGrUfDpGcld3sPL8IiQxVVl7/890eVQhj/6yoQ63pgmljTEo6wM2bNwEAh7CngyMhajvOfTo6AqK2d/PmTTg6OrbJtVUqFTw8PHCowPg/Kzw8PKBSqUwQVdsSpM402fQ7IYoirly5Ant7ewiC0NHhmIWysjJ4e3sjPz8fDg4OHR0OkcnxZ7x9SZKEmzdvwtPTU+9tuaZWVVWFmpoao6+jUqlgZWVlgojaFislHUChUKBbt24dHYZZcnBw4C9s+l3jz3j7aasKyZ2srKw6RTJhKnwkmIiIiGSBSQkRERHJApMSMgtqtRpxcXFQq9UdHQpRm+DPOP0ecKErERERyQIrJURERCQLTEqIiIhIFpiUEBERkSwwKaHfBUEQsGPHjhb3j4+PR2BgYJvFQyQ3ubm5EAQB2dnZHR0KUbOYlFCnUFBQgDlz5sDPzw9qtRre3t6YMGECMjIyWnW9+fPnt3oskSFmzJgBQRAgCAJUKhV69eqF5cuXo66url3j8Pb2xtWrVzFgwIB2vS+RIbijK8lebm4u7r//fjg5OSExMREDBw5EbW0t9u7di6ioKJw+fdrga9rZ2cHOzq4NoiVqbNy4cdi8eTOqq6uxZ88eREVFwdLSEosXL9brV1NT02bvJ1EqlfDw8GiTaxOZCislJHuzZ8+GIAg4evQoHn/8cfTp0wf9+/dHTEwMvvvuuybHLFy4EH369IGNjQ38/PwQGxuL2trbb8q8e/pmxowZmDx5MlatWgWNRgMnJyfd32YXLFgAFxcXdOvWDZs3b27rr0u/Q2q1Gh4eHvDx8cGsWbMQGhqKnTt36n7uVq5cCU9PT/j7+wMA8vPz8cQTT8DJyQkuLi6YNGkScnNzdddrzc/r3dM3169fx7Rp0+Dm5gZra2v07t1br/9vxUDUFpiUkKyVlJQgPT0dUVFRsLW1bfS5k5NTk+Ps7e2xZcsWnDx5Eu+88w42bNiAt99++5732r9/P65cuYIDBw4gKSkJcXFxePTRR+Hs7IwjR47ghRdewPPPP49Lly6Z4quRGbO2tta9ZC0jIwM5OTnYt28fdu3ahdraWoSFhcHe3h4HDx7Et99+Czs7O4wbN07vxWzG/rzGxsbi5MmT+PLLL3Hq1CmsW7cOrq6uANDiGIhMTiKSsSNHjkgApM8+++ye/QBIn3/+ebOfJyYmSkFBQbrzuLg4afDgwbrz8PBwycfHR9Jqtbo2f39/aeTIkbrzuro6ydbWVvr73/9u+BchsxUeHi5NmjRJkiRJEkVR2rdvn6RWq6X58+dL4eHhkkajkaqrq3X9t27dKvn7+0uiKOraqqurJWtra2nv3r26axr683rhwgUJgHTixAlJkiRpwoQJUkRERJMxtyQGorbANSUka1IrNxxOS0vDmjVrcO7cOZSXl6Ouru4335zav39/vVeQazQavUWBSqUSXbp0wbVr11oVE5mvXbt2wc7ODrW1tRBFEU8//TTi4+MRFRWFgQMH6q0j+eGHH3D27FnY29vrXaOqqgrnzp3TnRv78zpr1iw8/vjjOH78OMaOHYvJkydjxIgRBsVAZGpMSkjWevfuDUEQDFrMmpWVhWnTpmHZsmUICwuDo6Mjtm/fjrfeeuue4ywtLfXOBUFosk0UxZZ/ASIAY8aMwbp166BSqeDp6QkLi9u/eu+eliwvL0dQUBC2bdvW6Dpubm66fzb25/WRRx7BxYsXsWfPHuzbtw8PPfQQoqKisHr16hbHQGRqTEpI1lxcXBAWFoa1a9fixRdfbPQL/MaNG43WlRw+fBg+Pj5YsmSJru3ixYvtES5Rk2xtbdGrV68W9R06dCjS0tLg7u7+m9U9Y7m5uSE8PBzh4eEYOXIkFixYgNWrV7drDER34kJXkr21a9dCq9Vi+PDh+PTTT3HmzBmcOnUKa9asQUhISKP+vXv3Rl5eHrZv345z585hzZo1+PzzzzsgciLDTZs2Da6urpg0aRIOHjyICxcuIDMzEy+++KJJF1kvXboU//znP3H27Fn89NNP2LVrF/r169euMRDdjUkJyZ6fnx+OHz+OMWPG4KWXXsKAAQPw8MMPIyMjA+vWrWvUf+LEiZg3bx6io6MRGBiIw4cPIzY2tgMiJzKcjY0NDhw4gO7du2PKlCno168fnnvuOVRVVZm0aqFSqbB48WIMGjQIo0aNglKpxPbt29s1BqK7CVJrVxISERERmRArJURERCQLTEqIiIhIFpiUEBERkSwwKSEiIiJZYFJCREREssCkhIiIiGSBSQkRERHJApMSIjM1Y8YMTJ48WXf+4IMP4v/+7//aPY7MzEwIgoAbN24020cQBOzYsaPF14yPj0dgYKBRceXm5kIQBGRnZxt1HSJqOSYlRDIyY8YMCIIAQRCgUqnQq1cvLF++HHV1dW1+788++wwrVqxoUd+WJBJERIbiC/mIZGbcuHHYvHkzqqursWfPHkRFRcHS0hKLFy9u1LempkbvtffGcHFxMcl1iIhai5USIplRq9Xw8PCAj48PZs2ahdDQUOzcuRPA7SmXlStXwtPTE/7+/gCA/Px8PPHEE3BycoKLiwsmTZqE3Nxc3TW1Wi1iYmLg5OSELl264OWXX8bdb5i4e/qmuroaCxcuhLe3N9RqNXr16oVNmzYhNzcXY8aMAQA4OztDEATMmDEDACCKIhISEtCjRw9YW1tj8ODB+OSTT/Tus2fPHvTp0wfW1tYYM2aMXpwttXDhQvTp0wc2Njbw8/NDbGwsamtrG/Vbv349vL29YWNjgyeeeAKlpaV6n2/cuBH9+vWDlZUV+vbti/fee8/gWIjIdJiUEMmctbU1ampqdOcZGRnIycnBvn37sGvXLtTW1iIsLAz29vY4ePAgvv32W9jZ2WHcuHG6cW+99Ra2bNmC1NRUHDp0CCUlJb/55uTp06fj73//O9asWYNTp05h/fr1sLOzg7e3Nz799FMAQE5ODq5evYp33nkHAJCQkIAPPvgAKSkp+OmnnzBv3jw888wz+OabbwDUJ09TpkzBhAkTkJ2djZkzZ2LRokUG/zuxt7fHli1bcPLkSbzzzjvYsGED3n77bb0+Z8+exccff4wvvvgC6enpOHHiBGbPnq37fNu2bVi6dClWrlyJU6dOYdWqVYiNjcX7779vcDxEZCISEclGeHi4NGnSJEmSJEkURWnfvn2SWq2W5s+fr/tco9FI1dXVujFbt26V/P39JVEUdW3V1dWStbW1tHfvXkmSJKlr167Sm2++qfu8trZW6tatm+5ekiRJo0ePlubOnStJkiTl5ORIAKR9+/Y1GefXX38tAZCuX7+ua6uqqpJsbGykw4cP6/V97rnnpKeeekqSJElavHixFBAQoPf5woULG13rbgCkzz//vNnPExMTpaCgIN15XFycpFQqpUuXLunavvzyS0mhUEhXr16VJEmSevbsKX300Ud611mxYoUUEhIiSZIkXbhwQQIgnThxotn7EpFpcU0Jkczs2rULdnZ2qK2thSiKePrppxEfH6/7fODAgXrrSH744QecPXsW9vb2etepqqrCuXPnUFpaiqtXryI4OFj3mYWFBYYNG9ZoCqdBdnY2lEolRo8e3eK4z549i8rKSjz88MN67TU1NRgyZAgA4NSpU3pxAEBISEiL79EgLS0Na9aswblz51BeXo66ujo4ODjo9enevTu8vLz07iOKInJycmBvb49z587hueeeQ2RkpK5PXV0dHB0dDY6HiEyDSQmRzIwZMwbr1q2DSqWCp6cnLCz0/29qa2urd15eXo6goCBs27at0bXc3NxaFYO1tbXBY8rLywEAu3fv1ksGgPp1MqaSlZWFadOmYdmyZQgLC4OjoyO2b9+Ot956y+BYN2zY0ChJUiqVJouViAzDpIRIZmxtbdGrV68W9x86dCjS0tLg7u7eqFrQoGvXrjhy5AhGjRoFoL4icOzYMQwdOrTJ/gMHDoQoivjmm28QGhra6POGSo1Wq9W1BQQEQK1WIy8vr9kKS79+/XSLdht89913v/0l73D48GH4+PhgyZIluraLFy826peXl4crV67A09NTdx+FQgF/f39oNBp4enri/PnzmDZtmkH3J6K2w4WuRJ3ctGnT4OrqikmTJuHgwYO4cOECMjMz8eKLL+LSpUsAgLlz5+L111/Hjh07cPr0acyePfuee4z4+voiPDwczz77LHbs2KG75scffwwA8PHxgSAI2LVrF4qKilBeXg57e3vMnz8f8+bNw/vvv49z587h+PHjePfdd3WLR1944QWcOXMGCxYsQE5ODj766CNs2bLFoO/bu3dv5OXlYfv27Th37hzWrFnT5KJdKysrhIeH44cffsDBgwfx4osv4oknnoCHhwcAYNmyZUhISMCaNWvw888/48cff8TmzZuRlJRkUDxEZDpMSog6ORsbGxw4cADdu3fHlClT0K9fPzz33HOoqqrSVU5eeukl/PnPf0Z4eDhCQkJgb2+Pxx577J7XXbduHf74xz9i9uzZ6Nu3LyIjI1FRUQEA8PLywrJly7Bo0SJoNBpER0cDAFasWIHY2FgkJCSgX79+GDduHHbv3o0ePXoAqF/n8emnn2LHjh0YPHgwUlJSsGrVKoO+78SJEzFv3jxER0cjMDAQhw8fRmxsbKN+vXr1wpQpUzB+/HiMHTsWgwYN0nvkd+bMmdi4cSM2b96MgQMHYvTo0diyZYsuViJqf4LU3Eo3IiIionbESgkRERHJApMSIiIikgUmJURERCQLTEqIiIhIFpiUEBERkSwwKSEiIiJZYFJCREREssCkhIiIiGSBSQkRERHJApMSIiIikgUmJURERCQLTEqIiIhIFv4fEjgnK+Q4lwsAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def show_statistic(params: dict):\n",
    "    statistic = params['statistic']\n",
    "#     statistic = {\n",
    "#         'source_prop_text': [],\n",
    "#         'target_prop_text': [],\n",
    "#         'source_prop_type': [],\n",
    "#         'target_prop_type': [],\n",
    "#         'relation_type': [],\n",
    "#         'infered_source_prop_type': [],\n",
    "#         'infered_target_prop_type': [],\n",
    "#         'infered_relation_type': [], \n",
    "#         'distance': [],\n",
    "#     }\n",
    "    true_positive_relation = statistic[statistic['relation_type'] == statistic['infered_relation_type']]\n",
    "    true_positive_source = statistic[statistic['source_prop_type'] == statistic['infered_source_prop_type']]\n",
    "    true_positive_target = statistic[statistic['target_prop_type'] == statistic['infered_target_prop_type']]\n",
    "    \n",
    "    print(\"Accuracy:\")\n",
    "    relation_accuracy = len(true_positive_relation) / len(statistic)\n",
    "    print(\"Relation Accuracy:\", relation_accuracy)\n",
    "    source_accuracy = len(true_positive_source) / len(statistic)\n",
    "    print(\"Source Accuracy:\", source_accuracy)\n",
    "    target_accuracy = len(true_positive_target) / len(statistic)\n",
    "    print(\"Target Accuracy:\", target_accuracy)\n",
    "    \n",
    "    source_counter = Counter(statistic['source_prop_type'])\n",
    "    target_counter = Counter(statistic['target_prop_type'])\n",
    "    relation_counter = Counter(statistic['relation_type'])\n",
    "    print(\"Source Counter:\", source_counter)\n",
    "    print(\"Target Counter:\", target_counter)\n",
    "    print(\"Relation Counter:\", relation_counter)\n",
    "    \n",
    "    def plot_confusion_matrix(true_y, pred_y, title, xticks_rotation=0):\n",
    "        ConfusionMatrixDisplay.from_predictions(true_y, pred_y, normalize=\"true\")\n",
    "        plt.xticks(rotation = xticks_rotation)\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "        \n",
    "    def sk_f1_report(title, y_true, y_infered):\n",
    "        print(title)\n",
    "        print(classification_report(y_true, y_infered, zero_division=0))\n",
    "    \n",
    "    sk_f1_report(\"Relation\", statistic['relation_type'], statistic['infered_relation_type'])\n",
    "    sk_f1_report(\"Source\", statistic['source_prop_type'], statistic['infered_source_prop_type'])\n",
    "    sk_f1_report(\"Target\", statistic['target_prop_type'], statistic['infered_target_prop_type'])\n",
    "    \n",
    "    plot_confusion_matrix(statistic['relation_type'], statistic['infered_relation_type'], \"Relation\", xticks_rotation=45)\n",
    "    plot_confusion_matrix(statistic['source_prop_type'], statistic['infered_source_prop_type'], \"Source\")\n",
    "    plot_confusion_matrix(statistic['target_prop_type'], statistic['infered_target_prop_type'], \"Target\")\n",
    "    \n",
    "show_statistic(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_build_model_from_params(params: dict):\n",
    "    extract_propositions(params)\n",
    "    load_saved_model(params)\n",
    "    build_link_prediction_model(params)\n",
    "    return params[params['model_name'] + \"_final\"]\n",
    "\n",
    "load_and_build_model_from_params(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipeline(params: dict):\n",
    "    extract_propositions(params)\n",
    "    creating_glove_embeddings(params)\n",
    "    encode_datasets(params)\n",
    "    build_model(params)\n",
    "    train_and_save_model(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_file(params: dict, content: str, target_file: Path = None, source_language: str=\"english\", source_file: str = None, **kwargs):\n",
    "    model = params[params['model_name'] + \"_final\"]\n",
    "    max_argumentative_distance = params['max_proposition_distance']\n",
    "    \n",
    "#     print(\"Processing\", file)\n",
    "    \n",
    "    parser = ConllParser(bioes=True)\n",
    "    argumentative, _, non_argumentative = parser.parse(content)\n",
    "\n",
    "    source_ids = []\n",
    "    target_ids = []\n",
    "    sources = []\n",
    "    targets = []\n",
    "    distances = []\n",
    "    \n",
    "    predictions: Dict[Tuple[int,int], Tuple[str,str,str]] = {\n",
    "            \n",
    "    }\n",
    "\n",
    "    for _, source in argumentative.iterrows():\n",
    "        for _, target in argumentative.iterrows():\n",
    "            distance = target['prop_id'] - source['prop_id']\n",
    "            if source['prop_id'] == target['prop_id'] or abs(distance) > max_argumentative_distance:\n",
    "                continue\n",
    "            source_ids.append(source['prop_id'])\n",
    "            target_ids.append(target['prop_id'])\n",
    "            sources.append(source['prop_text'])\n",
    "            targets.append(target['prop_text'])\n",
    "            distances.append(distance)\n",
    "\n",
    "#     print(\"Inference\", file)\n",
    "#     print(sources)\n",
    "    inference = model(sources, targets, distances)\n",
    "\n",
    "    for source_id, target_id, (predicted_relation_tag, predicted_source_tag, predicted_target_tag) in zip(source_ids, target_ids, inference):\n",
    "        if predicted_relation_tag:\n",
    "            predictions[source_id, target_id] = predicted_relation_tag, predicted_source_tag, predicted_target_tag\n",
    "\n",
    "    # Remove inverse relations. If the forward relation doesn't exist then\n",
    "    # it will be added in either case the inverse relation will be removed.\n",
    "    to_add = {}\n",
    "    to_remove = set()\n",
    "#     print(\"Removing Inverse relations\", file)\n",
    "    for (source_id, target_id), (predicted_relation_tag, predicted_source_tag, predicted_target_tag) in predictions.items():\n",
    "        inverse_relation = predicted_relation_tag.endswith(\"_Inverse\")\n",
    "        if inverse_relation:\n",
    "            try:\n",
    "                _ = predictions[target_id, source_id]\n",
    "            except KeyError:\n",
    "                # Add the forward relation\n",
    "                no_inverse_tag = predicted_relation_tag[:-len(\"_Inverse\")]\n",
    "                to_add[target_id, source_id] = no_inverse_tag, predicted_target_tag, predicted_source_tag\n",
    "            # Remove inverse relation\n",
    "            to_remove.add((source_id, target_id))\n",
    "\n",
    "    # Commit actions to predictions\n",
    "    for key in to_remove:\n",
    "        predictions.pop(key)\n",
    "    predictions.update(to_add)\n",
    "\n",
    "    # Empty relations table and fill with calculated values\n",
    "    relation_dict = {\n",
    "        'relation_id': [],\n",
    "        'relation_type': [],\n",
    "        'prop_id_source': [],\n",
    "        'prop_id_target': [],\n",
    "    }\n",
    "    relation_id = 1\n",
    "    for (source_id, target_id), (predicted_relation_tag, predicted_source_tag, predicted_target_tag) in predictions.items():\n",
    "        relation_dict['relation_id'].append(relation_id)\n",
    "        relation_dict['relation_type'].append(predicted_relation_tag)\n",
    "        relation_dict['prop_id_source'].append(source_id)\n",
    "        relation_dict['prop_id_target'].append(target_id)\n",
    "        relation_id += 1\n",
    "    relations = pandas.DataFrame(relation_dict)\n",
    "\n",
    "    file_key = \"str(file)\" if not source_file else source_file\n",
    "#     print(\"Parsing from dataframe\")\n",
    "#     print(\"Relations:\", len(relations))\n",
    "    result = parser.from_dataframes({file_key: (argumentative, relations, non_argumentative)}, source_language=source_language, **kwargs)\n",
    "    \n",
    "    if target_file:\n",
    "        target_file.write_text(result[file_key][0])\n",
    "\n",
    "    return result[file_key][0]\n",
    "\n",
    "def use_model(params: dict):\n",
    "    to_process_dir = params['to_process_data_path']\n",
    "    processed_data_dir = params['processed_data_path']\n",
    "    \n",
    "    segmentation_models = sorted(list(os.walk(to_process_dir))[0][1])\n",
    "    print(segmentation_models)\n",
    "    \n",
    "    for segmentation_model in segmentation_models:\n",
    "        \n",
    "        base_path = Path(processed_data_dir) / params['model_name']\n",
    "        base_path.mkdir(exist_ok=True, parents=True)\n",
    "        \n",
    "        current_to_process_dir = Path(to_process_dir, segmentation_model)\n",
    "        corpus_labels = sorted(list(os.walk(current_to_process_dir))[0][1])\n",
    "        print(corpus_labels)\n",
    "        \n",
    "        for corpus_label in corpus_labels:\n",
    "            final_current_to_process_dir = current_to_process_dir / corpus_label\n",
    "            dest_folder = base_path / segmentation_model / corpus_label\n",
    "            dest_folder.mkdir(exist_ok=True, parents=True)\n",
    "            \n",
    "            for file in final_current_to_process_dir.iterdir():\n",
    "                if file.exists() and file.is_file():\n",
    "                    dest_file = dest_folder / file.name\n",
    "                    dest_file.touch(exist_ok=True)\n",
    "                    process_file(params, file.read_text(), dest_file)\n",
    "            \n",
    "use_model(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export jupyter as module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from pathlib import Path\n",
    "    try:\n",
    "        if Path(__file__).suffix == \".ipynb\":\n",
    "            raise NameError()\n",
    "    except NameError:\n",
    "        # In Jupyer Notebook\n",
    "        from utils.notebook_utils import export_notebook_as_module\n",
    "        export_notebook_as_module(Path(\"link_prediction.ipynb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
