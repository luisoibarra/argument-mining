{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Prediction\n",
    "\n",
    "## TODO\n",
    "\n",
    "- [ ] Remove unnecesary tags in relation and proposition vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from typing import Dict, Tuple\n",
    "try:\n",
    "    BASE_PATH = str(Path(__file__, \"..\", \"..\", \"..\").resolve())\n",
    "    import sys\n",
    "except NameError:\n",
    "    import sys\n",
    "    BASE_PATH = str(Path(\"..\", \"..\").resolve())\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    if BASE_PATH not in sys.path:\n",
    "        sys.path.insert(0, BASE_PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import corpus_parser.conll_parser\n",
    "# import importlib\n",
    "# importlib.reload(corpus_parser.conll_parser)\n",
    "import os\n",
    "\n",
    "from corpus_parser.unified_parser import UnifiedParser\n",
    "from corpus_parser.conll_parser import ConllParser\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import keras.backend as K\n",
    "\n",
    "import json\n",
    "import pandas\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rand\n",
    "\n",
    "from collections import Counter\n",
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "from link_prediction.models.link_utils import create_lr_annealing_function\n",
    "from link_prediction.models.attention import apply_attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define model initial params\n",
    "\n",
    "INFO_TAG = \"persuasive_essays_paragraph\"\n",
    "\n",
    "DATA_PATH = Path(BASE_PATH, \"data/\")\n",
    "\n",
    "# LANGUAGE = \"english\"\n",
    "LANGUAGE = \"spanish\"\n",
    "if LANGUAGE == \"english\":\n",
    "    GLOVE_PATH = Path(DATA_PATH, 'glove.840B.300d.txt')\n",
    "elif LANGUAGE == \"spanish\":\n",
    "    GLOVE_PATH = Path(DATA_PATH, 'glove-sbwc.i25.vec')\n",
    "else:\n",
    "    raise Exception(\"Not supported language\")\n",
    "\n",
    "EXPORT_PATH = Path(DATA_PATH, 'link_prediction', INFO_TAG)\n",
    "TO_PROCESS_DATADIR = Path(DATA_PATH, 'segmenter_processed', INFO_TAG)\n",
    "PROCESSED_DATADIR = Path(DATA_PATH, 'link_prediction_processed', INFO_TAG)\n",
    "DIM = 300\n",
    "\n",
    "params = {\n",
    "    'in_production': True,\n",
    "    \n",
    "    # Model Training Hyperparameters\n",
    "    'epochs': 70,\n",
    "    'batch_size': 20,\n",
    "    'metrics': ['acc'],\n",
    "    \n",
    "    # Ensemble Hyperparameters\n",
    "    'ensemble_amount': 3,\n",
    "    \n",
    "    # Model Hyperparameters\n",
    "    'dim': DIM,\n",
    "    'dropout': 0.1,\n",
    "    'lstm_size': 200,\n",
    "    'max_distance_encoded': 5,\n",
    "    'linear_embedders_dims': [50, 50, 50, DIM],\n",
    "    'regularizer_weight': 0.001,\n",
    "    'encoder_dense_units': 50,\n",
    "    'encoder_pool_size': 1, # If 1 no tranformation is made to the input.\n",
    "    'lstm_units': 25,\n",
    "    'final_size': 20,\n",
    "    'residual_size': 50,\n",
    "    'with_attention': True, # If the attention block is used\n",
    "    'loss_weights': {\n",
    "        'relation': 10,\n",
    "        'source': 1,\n",
    "        'target': 1,\n",
    "    },\n",
    "    \n",
    "    # Adam Optimizer Hyperparameters\n",
    "    'lr_alpha': 0.003,\n",
    "    'lr_kappa': 0.001,\n",
    "    'beta_1': 0.9,\n",
    "    'beta_2': 0.999,\n",
    "    \n",
    "    # Early Stopping Hyperparameters\n",
    "    'min_delta': 0,\n",
    "    'patience': 5,\n",
    "    \n",
    "    # Corpus Info\n",
    "    'corpus_path': str(Path(DATA_PATH, 'projection', INFO_TAG)),\n",
    "    'glove_path': str(Path(EXPORT_PATH, 'glove.npz')),\n",
    "    'export_path': str(EXPORT_PATH),\n",
    "    'model_path': str(EXPORT_PATH / \"model\"),\n",
    "    'glove_raw_path': str(Path(GLOVE_PATH)),\n",
    "    'language': LANGUAGE,\n",
    "    \n",
    "    # Vectorizer Hyperparameters\n",
    "    'sequence_standardize': None,\n",
    "    'sequence_split': 'whitespace',\n",
    "    \n",
    "    # Corpus Hyperparameters\n",
    "    'max_proposition_distance': 10, # Max distance allowed between argumentation\n",
    "    'non_related_max_proportion': 0.5, # Max proportion allowed between non related links and the total of links\n",
    "    \n",
    "    # Data info\n",
    "    'to_process_data_path': str(Path(TO_PROCESS_DATADIR)), # Directory with text to be processed\n",
    "    'processed_data_path': str(Path(PROCESSED_DATADIR)), # Directory to save the processed data\n",
    "}\n",
    "\n",
    "params['model_name'] = \"model\" + (\"_attention\" if params['with_attention'] else \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev relations 652\n",
      "dev source argumentative units 326\n",
      "dev target argumentative units 144\n",
      "test relations 1618\n",
      "test source argumentative units 809\n",
      "test target argumentative units 365\n",
      "train relations 5392\n",
      "train source argumentative units 2696\n",
      "train target argumentative units 1198\n",
      "Vocab size 8958\n",
      "Relation tags ['attacks_Inverse', 'attacks', 'supports', 'supports_Inverse']\n",
      "Proposition tags ['MajorClaim', 'Premise', 'Claim']\n",
      "max_size_prop 70\n",
      "max_amount_doc 20\n"
     ]
    }
   ],
   "source": [
    "# Load Dataset \n",
    "\n",
    "def find_duplicates(dataframe, first, second, group):\n",
    "\n",
    "    for g, dataframe in dataframe.groupby(by=group):\n",
    "        rows = [row for _, row in dataframe.iterrows()]\n",
    "        for i, row in enumerate(rows):\n",
    "            for row2 in rows[i+1:]:\n",
    "                if row[first] == row2[second] and row[second] == row2[first]:\n",
    "                    print(\"DUPLICATED ROW\")\n",
    "                    print(g)\n",
    "                    print(row)\n",
    "                    print(row2)\n",
    "\n",
    "                \n",
    "def extract_propositions(params: dict):\n",
    "    corpus_path = Path(params['corpus_path'])\n",
    "    \n",
    "    parser = UnifiedParser()\n",
    "    \n",
    "    names = [\n",
    "        \"dev\", \n",
    "        \"test\",\n",
    "        \"train\",\n",
    "    ]\n",
    "    \n",
    "    relation_tags = set()\n",
    "    proposition_tags = set()\n",
    "    \n",
    "    source_vocabulary = set()\n",
    "    target_vocabulary = set()\n",
    "    \n",
    "    # Max amount of propositions in a document\n",
    "    max_amount_source_in_doc = 0\n",
    "    max_amount_target_in_doc = 0\n",
    "    \n",
    "    # Max amount of tokens in a proposition\n",
    "    max_size_in_source_prop = 0\n",
    "    max_size_in_target_prop = 0\n",
    "    \n",
    "    for name in names:\n",
    "        \n",
    "        proposition_dict = parser.parse_dir(corpus_path / name)\n",
    "        \n",
    "        current_source_arg_units = {\n",
    "            'prop_id': [], \n",
    "            'prop_type': [], \n",
    "            'prop_text': [], \n",
    "            'file_key': []\n",
    "        }\n",
    "        current_target_arg_units = {\n",
    "            'prop_id': [], \n",
    "            'prop_type': [], \n",
    "            'prop_text': [], \n",
    "            'file_key': []\n",
    "        }\n",
    "        current_relations = {\n",
    "            'prop_id_source': [], \n",
    "            'prop_id_target': [], \n",
    "            'relation_type': [], \n",
    "            'distance': [], \n",
    "            'file_key': []\n",
    "        }\n",
    "\n",
    "        for key, (args_unit, relations, _) in proposition_dict.items():\n",
    "            args_unit['file_key'] = [key for _ in range(len(args_unit))]\n",
    "            args_unit = args_unit[['prop_id', 'prop_type', 'prop_text', 'file_key']]\n",
    "            \n",
    "            \n",
    "            relations = relations[['prop_id_source', 'prop_id_target', 'relation_type']]\n",
    "            relations['distance'] = relations.aggregate(lambda x: x['prop_id_target']-x['prop_id_source'], axis=1)\n",
    "            relations['file_key'] = relations.aggregate(lambda x: key, axis=1)\n",
    "            \n",
    "            source_prop = args_unit[args_unit['prop_id'].isin(relations['prop_id_source'])]\n",
    "            target_prop = args_unit[args_unit['prop_id'].isin(relations['prop_id_target'])]\n",
    "            \n",
    "            source_vocabulary.update([t for s in source_prop['prop_text'] for t in s.split()])\n",
    "            target_vocabulary.update([t for s in target_prop['prop_text'] for t in s.split()])\n",
    "            \n",
    "            max_size_in_source_prop = max(max_size_in_source_prop, source_prop.aggregate(lambda x: len(x['prop_text'].split()), axis=1).max())\n",
    "            max_size_in_target_prop = max(max_size_in_target_prop, target_prop.aggregate(lambda x: len(x['prop_text'].split()), axis=1).max())\n",
    "            \n",
    "            \n",
    "            max_amount_source_in_doc = max(max_amount_source_in_doc, len(relations['prop_id_source'].drop_duplicates()))\n",
    "            max_amount_target_in_doc = max(max_amount_target_in_doc, len(relations['prop_id_target'].drop_duplicates()))\n",
    "            \n",
    "            current_source_arg_units['prop_id'].extend(source_prop['prop_id'])\n",
    "            current_source_arg_units['prop_type'].extend(source_prop['prop_type'])\n",
    "            current_source_arg_units['prop_text'].extend(source_prop['prop_text'])\n",
    "            current_source_arg_units['file_key'].extend(source_prop['file_key'])\n",
    "            \n",
    "            current_target_arg_units['prop_id'].extend(target_prop['prop_id'])\n",
    "            current_target_arg_units['prop_type'].extend(target_prop['prop_type'])\n",
    "            current_target_arg_units['prop_text'].extend(target_prop['prop_text'])\n",
    "            current_target_arg_units['file_key'].extend(target_prop['file_key'])\n",
    "            \n",
    "            current_relations['prop_id_source'].extend(relations['prop_id_source'])\n",
    "            current_relations['prop_id_target'].extend(relations['prop_id_target'])\n",
    "            current_relations['relation_type'].extend(relations['relation_type'])\n",
    "            current_relations['distance'].extend(relations['distance'])\n",
    "            current_relations['file_key'].extend(relations['file_key'])\n",
    "\n",
    "            \n",
    "        # Add Inverse Relations\n",
    "        inverse_relations = {\n",
    "            'prop_id_source': current_relations['prop_id_target'].copy(),\n",
    "            'prop_id_target': current_relations['prop_id_source'].copy(),\n",
    "            'relation_type': [relation_type + \"_Inverse\" for relation_type in current_relations['relation_type']],\n",
    "            'distance': [-distance for distance in current_relations['distance']],\n",
    "            'file_key': current_relations['file_key'].copy(),\n",
    "        }\n",
    "        current_relations['prop_id_source'].extend(inverse_relations['prop_id_source'])\n",
    "        current_relations['prop_id_target'].extend(inverse_relations['prop_id_target'])\n",
    "        current_relations['relation_type'].extend(inverse_relations['relation_type'])\n",
    "        current_relations['distance'].extend(inverse_relations['distance'])\n",
    "        current_relations['file_key'].extend(inverse_relations['file_key'])\n",
    "        \n",
    "        \n",
    "        current_relations = pandas.DataFrame(current_relations)\n",
    "        current_source_arg_units = pandas.DataFrame(current_source_arg_units)\n",
    "        current_target_arg_units = pandas.DataFrame(current_target_arg_units)\n",
    "        \n",
    "        # Sanity checks\n",
    "#         print(\"NEGATIVE PROP IDs\")\n",
    "#         print(\"TARGET < 0\", current_target_arg_units[current_target_arg_units['prop_id'] < 0])\n",
    "#         print(\"SOURCE < 0\", current_source_arg_units[current_source_arg_units['prop_id'] < 0])\n",
    "#         print(\"RELATION TARGET < 0:\", list(current_relations[current_relations['prop_id_target'] < 0]['file_key']))\n",
    "#         print(\"RELATION SOURCE < 0:\", list(current_relations[current_relations['prop_id_source'] < 0]['file_key']))\n",
    "#         def check_max(s_t_data, data, max_column, compare_to, title):\n",
    "#             for file, df in data.groupby(by='file_key'):\n",
    "#                 maxim = s_t_data[s_t_data['file_key'] == file][max_column].max()\n",
    "#                 print(title, maxim, file)\n",
    "#                 print(df[df[compare_to] > maxim])\n",
    "#         check_max(current_target_arg_units, current_relations, 'prop_id', 'prop_id_target', \"RELATION TARGET > max\")\n",
    "#         check_max(current_source_arg_units, current_relations, 'prop_id', 'prop_id_source', \"RELATION SOURCE > max\")\n",
    "#         print(\"BEFORE\")\n",
    "#         find_duplicates(current_relations, 'prop_id_source', 'prop_id_target', 'file_key')\n",
    "\n",
    "        params[f'{name}_source_propositions'] = current_source_arg_units\n",
    "        params[f'{name}_target_propositions'] = current_target_arg_units\n",
    "        params[f'{name}_relations'] = current_relations\n",
    "\n",
    "        print(name, \"relations\", len(current_relations))\n",
    "        print(name, \"source argumentative units\", len(current_source_arg_units))\n",
    "        print(name, \"target argumentative units\", len(current_target_arg_units))\n",
    "\n",
    "        relation_tags.update(current_relations['relation_type'])\n",
    "        proposition_tags.update(current_source_arg_units['prop_type'])\n",
    "        proposition_tags.update(current_target_arg_units['prop_type'])\n",
    "    \n",
    "\n",
    "    vocabulary = source_vocabulary.union(target_vocabulary)\n",
    "    params['vocabulary'] = vocabulary\n",
    "    print(\"Vocab size\", len(vocabulary))\n",
    "    \n",
    "    relation_tags = list(relation_tags)\n",
    "    proposition_tags = list(proposition_tags)\n",
    "    print(\"Relation tags\", relation_tags)\n",
    "    print(\"Proposition tags\", proposition_tags)\n",
    "    params['relation_tags'] = relation_tags\n",
    "    params['proposition_tags'] = proposition_tags\n",
    "    \n",
    "    max_size_prop = max(max_size_in_source_prop, max_size_in_target_prop)\n",
    "    max_amount_doc = max(max_amount_source_in_doc, max_amount_target_in_doc)\n",
    "    params['max_size_prop'] = max_size_prop\n",
    "    params['max_amount_doc'] = max_amount_doc\n",
    "    \n",
    "    print('max_size_prop', max_size_prop)\n",
    "    print('max_amount_doc', max_amount_doc)\n",
    "\n",
    "    # Vectorizers\n",
    "    sequence_vectorizer = layers.TextVectorization(\n",
    "        output_mode = \"int\",\n",
    "        max_tokens = len(vocabulary) + 2, # Plus PAD and UNK\n",
    "        output_sequence_length = int(max_size_prop),\n",
    "        standardize = params['sequence_standardize'],\n",
    "        split = params['sequence_split']\n",
    "    )\n",
    "    sequence_vectorizer.adapt(pandas.concat([\n",
    "        params['train_source_propositions'],\n",
    "        params['train_target_propositions'],\n",
    "    ], ignore_index=True)['prop_text'])\n",
    "    params['sequence_vectorizer'] = sequence_vectorizer\n",
    "    \n",
    "    relation_tag_vectorizer = layers.TextVectorization(\n",
    "        output_mode = \"int\",\n",
    "        max_tokens = len(relation_tags) + 2, # Plus PAD and UNK\n",
    "        output_sequence_length = 1,\n",
    "        standardize = None,\n",
    "        split = None\n",
    "    )\n",
    "    relation_tag_vectorizer.adapt(relation_tags)\n",
    "    params['relation_tag_vectorizer'] = relation_tag_vectorizer\n",
    "    \n",
    "    proposition_tag_vectorizer = layers.TextVectorization(\n",
    "        output_mode = \"int\",\n",
    "        max_tokens = len(proposition_tags) + 2, # Plus PAD and UNK\n",
    "        output_sequence_length = 1,\n",
    "        standardize = None,\n",
    "        split = None\n",
    "    )\n",
    "    proposition_tag_vectorizer.adapt(proposition_tags)\n",
    "    params['proposition_tag_vectorizer'] = proposition_tag_vectorizer\n",
    "    \n",
    "    # One-Hot Encoders\n",
    "    relation_encoder = layers.CategoryEncoding(\n",
    "        num_tokens=len(relation_tag_vectorizer.get_vocabulary()), # Plus PAD and UNK\n",
    "        output_mode=\"one_hot\",\n",
    "    )\n",
    "    params['relation_encoder'] = relation_encoder\n",
    "    \n",
    "    proposition_encoder = layers.CategoryEncoding(\n",
    "        num_tokens=len(proposition_tag_vectorizer.get_vocabulary()), # Plus PAD and UNK\n",
    "        output_mode=\"one_hot\",\n",
    "    )\n",
    "    params['proposition_encoder'] = proposition_encoder\n",
    "    \n",
    "    \n",
    "extract_propositions(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dataset_statistics(params: dict):\n",
    "    \n",
    "    def plot_relation_info(relation_df: pandas.DataFrame):\n",
    "        relation_df = relation_df[~relation_df['relation_type'].str.endswith(\"_Inverse\")]\n",
    "        bins = set(relation_df['distance'])\n",
    "        relation_df['distance'].hist(bins=len(bins))\n",
    "        plt.title(\"Relation distances\")\n",
    "        plt.show()\n",
    "    \n",
    "    for name in ['train']:\n",
    "        current_relations = params[f'{name}_relations']\n",
    "\n",
    "        plot_relation_info(current_relations)\n",
    "    \n",
    "dataset_statistics(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Glove Embedding Matrix Found\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def creating_glove_embeddings(params: dict):\n",
    "    \n",
    "    if Path(params[\"glove_path\"]).exists():\n",
    "        print(\"Glove Embedding Matrix Found\")\n",
    "        embedding_matrix = np.load(params[\"glove_path\"])[\"embeddings\"]\n",
    "        params['embedding_matrix'] = embedding_matrix\n",
    "        return\n",
    "    \n",
    "    # Loading Glove\n",
    "    hits = 0\n",
    "    embedding_dim = params['dim']\n",
    "    word_to_index = dict(map(lambda x: (x[1], x[0]), enumerate(params['sequence_vectorizer'].get_vocabulary())))\n",
    "    num_tokens = len(word_to_index) # Plus padding and unknown \n",
    "\n",
    "    embedding_matrix = np.zeros((num_tokens, embedding_dim))\n",
    "    with Path(params[\"glove_raw_path\"]).open() as f:\n",
    "        for line_idx, line in enumerate(f):\n",
    "            if line_idx % 100000 == 0:\n",
    "                print('- At line {}'.format(line_idx))\n",
    "            line = line.strip().split()\n",
    "            if len(line) != 300 + 1:\n",
    "                continue\n",
    "            word = line[0]\n",
    "            embedding = line[1:]\n",
    "            if word in word_to_index:\n",
    "                hits += 1\n",
    "                word_idx = word_to_index[word]\n",
    "                embedding_matrix[word_idx] = embedding\n",
    "                \n",
    "    print('- Done. Found {} vectors for {} words'.format(hits, num_tokens - 2))\n",
    "    \n",
    "    params['embedding_matrix'] = embedding_matrix\n",
    "    Path(params[\"glove_path\"], \"..\").resolve().mkdir(exist_ok=True, parents=True)\n",
    "    np.savez_compressed(params[\"glove_path\"], embeddings=embedding_matrix)\n",
    "\n",
    "creating_glove_embeddings(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Dataframe Found\n",
      "55534\n",
      "dev Counter({'': 652, 'supports': 304, 'supports_Inverse': 304, 'attacks': 22, 'attacks_Inverse': 22})\n",
      "test Counter({'': 1618, 'supports': 767, 'supports_Inverse': 767, 'attacks_Inverse': 42, 'attacks': 42})\n",
      "train Counter({'': 5390, 'supports': 2540, 'supports_Inverse': 2540, 'attacks_Inverse': 155, 'attacks': 155})\n"
     ]
    }
   ],
   "source": [
    "# Encode Dataset\n",
    "\n",
    "def encode_distance(distance, encode_size):\n",
    "    \"\"\"\n",
    "    return: Tensor with the encoded distance\n",
    "    \"\"\"\n",
    "    middle = encode_size // 2\n",
    "\n",
    "    abs_distance = tf.cast(tf.abs(distance), dtype=\"int32\") \n",
    "    zeros = tf.zeros((tf.maximum(1, abs_distance), middle))\n",
    "\n",
    "    to_sum = tf.concat([zeros, tf.eye(abs_distance, num_columns=middle)], axis=0)\n",
    "    distance_vec = tf.foldl(lambda x, y: tf.add(x, y), to_sum)\n",
    "\n",
    "    if distance < 0:\n",
    "        first_vec = tf.reverse(distance_vec, axis=[0])\n",
    "        second_vec = zeros[0]\n",
    "    else:\n",
    "        first_vec = zeros[0]\n",
    "        second_vec = distance_vec\n",
    "\n",
    "    return tf.concat([first_vec, second_vec], axis=0)\n",
    "\n",
    "\n",
    "def encode_datasets(params: dict):\n",
    "    sequence_vectorizer = params['sequence_vectorizer']\n",
    "    proposition_tag_vectorizer = params['proposition_tag_vectorizer']\n",
    "    relation_tag_vectorizer = params['relation_tag_vectorizer']\n",
    "    proposition_encoder = params['proposition_encoder']\n",
    "    relation_encoder = params['relation_encoder']\n",
    "    distance_encoding_bits = params['max_distance_encoded'] * 2\n",
    "    max_proposition_distance = params['max_proposition_distance']\n",
    "    non_related_max_proportion = params['non_related_max_proportion']\n",
    "\n",
    "    df_path = Path(params['export_path'], f'data_df_{max_proposition_distance}.pkl')\n",
    "    if df_path.exists():\n",
    "        data_dataframe = pandas.read_pickle(df_path)\n",
    "        print(\"Data Dataframe Found\")\n",
    "    else:\n",
    "        data_dataframe = pandas.DataFrame(\n",
    "            columns = [\n",
    "                'file_key', \n",
    "                'source_prop_id', \n",
    "                'target_prop_id', \n",
    "                'source_prop_text',\n",
    "                'target_prop_text',\n",
    "                'source_prop_type',\n",
    "                'target_prop_type',\n",
    "                'relation_type', \n",
    "                'distance',\n",
    "                'split',\n",
    "            ])\n",
    "\n",
    "        for split in ['dev', 'test', 'train']:\n",
    "\n",
    "            source_arg_units = params[f'{split}_source_propositions']\n",
    "            target_arg_units = params[f'{split}_target_propositions']\n",
    "            relations = params[f'{split}_relations']\n",
    "\n",
    "            all_arg_units = pandas.concat([source_arg_units, target_arg_units], ignore_index=True)\n",
    "            all_arg_units = all_arg_units.drop_duplicates()\n",
    "            all_arg_units = [(file, df) for file, df in all_arg_units.groupby(by='file_key')]\n",
    "            \n",
    "            for file_key, file_source_df in all_arg_units:\n",
    "                file_target_df = file_source_df.copy()\n",
    "                file_relations = relations[relations['file_key'] == file_key]\n",
    "\n",
    "                current_file_info = {\n",
    "                    'file_key': [], \n",
    "                    'source_prop_id': [],\n",
    "                    'target_prop_id': [],\n",
    "                    'source_prop_text': [],\n",
    "                    'target_prop_text': [],\n",
    "                    'source_prop_type': [],\n",
    "                    'target_prop_type': [],\n",
    "                    'relation_type': [],\n",
    "                    'distance': [],\n",
    "                    'split': [],\n",
    "                }\n",
    "                \n",
    "                for _, source_row in file_source_df.iterrows():\n",
    "                    source_id = source_row['prop_id']\n",
    "                    for _, target_row in file_target_df.iterrows():\n",
    "                        target_id = target_row['prop_id']\n",
    "\n",
    "                        # Same relations not allowed\n",
    "                        if source_id == target_id:\n",
    "                            continue\n",
    "\n",
    "                        distance = target_id - source_id\n",
    "                        # Distance is greater than the max alowed distance between propositions\n",
    "                        if abs(distance) > max_proposition_distance:\n",
    "                            continue\n",
    "\n",
    "\n",
    "                        source_target_relation = file_relations[(file_relations['prop_id_target'] == target_id) & (file_relations['prop_id_source'] == source_id)]\n",
    "                        \n",
    "                        if len(source_target_relation) == 0:\n",
    "                            # No related propositions\n",
    "                            relation_type = '' # No Relation\n",
    "                            distance = 0 # Mock Distance\n",
    "                            source_target_relation = pandas.concat([source_target_relation, pandas.DataFrame({\n",
    "                                'prop_id_source': [source_id],\n",
    "                                'prop_id_target': [target_id],\n",
    "                                'relation_type': [relation_type],\n",
    "                                'distance': [distance],\n",
    "                                'file_key': [file_key]\n",
    "                            })])\n",
    "                            \n",
    "                        if len(source_target_relation) > 1:\n",
    "                            print(\"WARNING: Multiple relation with single source-target pair\")\n",
    "                            print(source_target_relation)\n",
    "\n",
    "                        for _, relation_row in source_target_relation.iterrows():\n",
    "\n",
    "                            assert relation_row['distance'] == distance, f\"{relation_row['distance']} != {distance}\"\n",
    "\n",
    "                            # Adding data\n",
    "                            current_file_info['file_key'].append(file_key)\n",
    "                            current_file_info['source_prop_id'].append(source_id)\n",
    "                            current_file_info['target_prop_id'].append(target_id)\n",
    "                            current_file_info['source_prop_text'].append(source_row['prop_text'])\n",
    "                            current_file_info['target_prop_text'].append(target_row['prop_text'])\n",
    "                            current_file_info['source_prop_type'].append(source_row['prop_type'])\n",
    "                            current_file_info['target_prop_type'].append(target_row['prop_type'])\n",
    "                            current_file_info['relation_type'].append(relation_row['relation_type'])\n",
    "                            current_file_info['distance'].append(distance)\n",
    "                            current_file_info['split'].append(split)\n",
    "                    \n",
    "                current_file_info = pandas.DataFrame(current_file_info)\n",
    "                \n",
    "\n",
    "                data_dataframe = pandas.concat([data_dataframe, current_file_info], ignore_index=True)\n",
    "        data_dataframe.to_pickle(df_path)\n",
    "\n",
    "    params['raw_data_dataframe'] = data_dataframe\n",
    "    print(len(data_dataframe))\n",
    "    \n",
    "    # Encoding\n",
    "    for split, data_dataframe in data_dataframe.groupby(by=\"split\"):\n",
    "        \n",
    "        relation_counter = Counter(data_dataframe['relation_type'])\n",
    "        \n",
    "        non_related_proportion = relation_counter[''] / len(data_dataframe)\n",
    "        if non_related_proportion > non_related_max_proportion:\n",
    "            amount_to_drop = int((relation_counter[''] - non_related_max_proportion * len(data_dataframe)) / (1 - non_related_max_proportion))\n",
    "            index = list(data_dataframe[data_dataframe['relation_type'] == ''].index)\n",
    "            rand.shuffle(index)\n",
    "            \n",
    "            data_dataframe = data_dataframe.drop(index[:amount_to_drop])\n",
    "            \n",
    "        relation_counter = Counter(data_dataframe['relation_type'])\n",
    "        print(split, relation_counter)\n",
    "        \n",
    "        source_ds = tf.data.Dataset.from_tensor_slices(tf.constant(data_dataframe['source_prop_text'])).map(lambda x: sequence_vectorizer(x))\n",
    "        target_ds = tf.data.Dataset.from_tensor_slices(tf.constant(data_dataframe['target_prop_text'])).map(lambda x: sequence_vectorizer(x))\n",
    "        source_type_ds = tf.data.Dataset.from_tensor_slices(tf.constant(data_dataframe['source_prop_type'])).map(lambda x: proposition_encoder(proposition_tag_vectorizer([x])))\n",
    "        target_type_ds = tf.data.Dataset.from_tensor_slices(tf.constant(data_dataframe['target_prop_type'])).map(lambda x: proposition_encoder(proposition_tag_vectorizer([x])))\n",
    "        relation_type_ds = tf.data.Dataset.from_tensor_slices(tf.constant(data_dataframe['relation_type'])).map(lambda x: relation_encoder(relation_tag_vectorizer([x])))\n",
    "        distance_ds = tf.data.Dataset.from_tensor_slices(list(data_dataframe['distance'].to_numpy(dtype=int))).map(lambda x: encode_distance(x, distance_encoding_bits))\n",
    "        \n",
    "        # Order matters\n",
    "        input_ds = tf.data.Dataset.zip((source_ds, target_ds, distance_ds))\n",
    "        output_ds = tf.data.Dataset.zip((relation_type_ds, source_type_ds, target_type_ds))\n",
    "        \n",
    "        ds = tf.data.Dataset.zip((input_ds, output_ds))\n",
    "        \n",
    "        params[f\"{split}_ds\"] = ds\n",
    "\n",
    "        \n",
    "encode_datasets(params)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the model\n",
    "\n",
    "Two versions of the model can be buit. The difference is the presence or not of an attention layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_attention_0\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 70)]         0           []                               \n",
      "                                                                                                  \n",
      " input_4 (InputLayer)           [(None, 70)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_1 (Embedding)        (None, 70, 300)      2242500     ['input_4[0][0]']                \n",
      "                                                                                                  \n",
      " embedding (Embedding)          (None, 70, 300)      2242500     ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " time_distributed_1 (TimeDistri  (None, 70, 300)     37250       ['embedding_1[0][0]']            \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_distributed (TimeDistribu  (None, 70, 300)     37250       ['embedding[0][0]']              \n",
      " ted)                                                                                             \n",
      "                                                                                                  \n",
      " add_1 (Add)                    (None, 70, 300)      0           ['embedding_1[0][0]',            \n",
      "                                                                  'time_distributed_1[0][0]']     \n",
      "                                                                                                  \n",
      " add (Add)                      (None, 70, 300)      0           ['embedding[0][0]',              \n",
      "                                                                  'time_distributed[0][0]']       \n",
      "                                                                                                  \n",
      " model_2 (Functional)           (None, 70, 50)       15250       ['add[0][0]',                    \n",
      "                                                                  'add_1[0][0]']                  \n",
      "                                                                                                  \n",
      " model_3 (Functional)           (None, 70, 25)       15200       ['model_2[0][0]',                \n",
      "                                                                  'model_2[1][0]']                \n",
      "                                                                                                  \n",
      " avg_query_target_0 (GlobalAver  (None, 25)          0           ['model_3[1][0]']                \n",
      " agePooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " avg_query_source_0 (GlobalAver  (None, 25)          0           ['model_3[0][0]']                \n",
      " agePooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " att_linearity_query_source_0 (  (None, 20)          520         ['avg_query_target_0[0][0]']     \n",
      " Dense)                                                                                           \n",
      "                                                                                                  \n",
      " att_linearity_query_target_0 (  (None, 20)          520         ['avg_query_source_0[0][0]']     \n",
      " Dense)                                                                                           \n",
      "                                                                                                  \n",
      " repeat_query_source_0 (RepeatV  (None, 70, 20)      0           ['att_linearity_query_source_0[0]\n",
      " ector)                                                          [0]']                            \n",
      "                                                                                                  \n",
      " att_K_source_0 (TimeDistribute  (None, 70, 20)      520         ['model_3[0][0]']                \n",
      " d)                                                                                               \n",
      "                                                                                                  \n",
      " repeat_query_target_0 (RepeatV  (None, 70, 20)      0           ['att_linearity_query_target_0[0]\n",
      " ector)                                                          [0]']                            \n",
      "                                                                                                  \n",
      " att_K_target_0 (TimeDistribute  (None, 70, 20)      520         ['model_3[1][0]']                \n",
      " d)                                                                                               \n",
      "                                                                                                  \n",
      " att_addition_source_0 (Add)    (None, 70, 20)       0           ['repeat_query_source_0[0][0]',  \n",
      "                                                                  'att_K_source_0[0][0]']         \n",
      "                                                                                                  \n",
      " att_addition_target_0 (Add)    (None, 70, 20)       0           ['repeat_query_target_0[0][0]',  \n",
      "                                                                  'att_K_target_0[0][0]']         \n",
      "                                                                                                  \n",
      " att_activation_source_0 (Activ  (None, 70, 20)      0           ['att_addition_source_0[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " att_activation_target_0 (Activ  (None, 70, 20)      0           ['att_addition_target_0[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " masking (Lambda)               (None, 70)           0           ['input_2[0][0]',                \n",
      "                                                                  'input_4[0][0]']                \n",
      "                                                                                                  \n",
      " att_scores_source_0 (TimeDistr  (None, 70, 1)       21          ['att_activation_source_0[0][0]']\n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " att_scores_target_0 (TimeDistr  (None, 70, 1)       21          ['att_activation_target_0[0][0]']\n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " negative_mul (Lambda)          (None, 70)           0           ['masking[0][0]',                \n",
      "                                                                  'masking[1][0]']                \n",
      "                                                                                                  \n",
      " att_scores_flat_source_0 (Flat  (None, 70)          0           ['att_scores_source_0[0][0]']    \n",
      " ten)                                                                                             \n",
      "                                                                                                  \n",
      " att_scores_flat_target_0 (Flat  (None, 70)          0           ['att_scores_target_0[0][0]']    \n",
      " ten)                                                                                             \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " att_masked_addition_source_0 (  (None, 70)          0           ['negative_mul[0][0]',           \n",
      " Add)                                                             'att_scores_flat_source_0[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " att_masked_addition_target_0 (  (None, 70)          0           ['negative_mul[1][0]',           \n",
      " Add)                                                             'att_scores_flat_target_0[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " att_weights_source_0 (Activati  (None, 70)          0           ['att_masked_addition_source_0[0]\n",
      " on)                                                             [0]']                            \n",
      "                                                                                                  \n",
      " att_weights_target_0 (Activati  (None, 70)          0           ['att_masked_addition_target_0[0]\n",
      " on)                                                             [0]']                            \n",
      "                                                                                                  \n",
      " att_weights_reshape_source_0 (  (None, 70, 1)       0           ['att_weights_source_0[0][0]']   \n",
      " Reshape)                                                                                         \n",
      "                                                                                                  \n",
      " att_weights_reshape_target_0 (  (None, 70, 1)       0           ['att_weights_target_0[0][0]']   \n",
      " Reshape)                                                                                         \n",
      "                                                                                                  \n",
      " att_multiply_source_0 (Multipl  (None, 70, 50)      0           ['att_weights_reshape_source_0[0]\n",
      " y)                                                              [0]',                            \n",
      "                                                                  'model_2[0][0]']                \n",
      "                                                                                                  \n",
      " att_multiply_target_0 (Multipl  (None, 70, 50)      0           ['att_weights_reshape_target_0[0]\n",
      " y)                                                              [0]',                            \n",
      "                                                                  'model_2[1][0]']                \n",
      "                                                                                                  \n",
      " att_cv_source_0 (Lambda)       (None, 50)           0           ['att_multiply_source_0[0][0]']  \n",
      "                                                                                                  \n",
      " att_cv_target_0 (Lambda)       (None, 50)           0           ['att_multiply_target_0[0][0]']  \n",
      "                                                                                                  \n",
      " input_1 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 110)          0           ['att_cv_source_0[0][0]',        \n",
      "                                                                  'att_cv_target_0[0][0]',        \n",
      "                                                                  'input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_9 (BatchNo  (None, 110)         440         ['concatenate[0][0]']            \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_8 (Dropout)            (None, 110)          0           ['batch_normalization_9[0][0]']  \n",
      "                                                                                                  \n",
      " dense_9 (Dense)                (None, 20)           2220        ['dropout_8[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_10 (BatchN  (None, 20)          80          ['dense_9[0][0]']                \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_9 (Dropout)            (None, 20)           0           ['batch_normalization_10[0][0]'] \n",
      "                                                                                                  \n",
      " activation_8 (Activation)      (None, 20)           0           ['dropout_9[0][0]']              \n",
      "                                                                                                  \n",
      " dense_10 (Dense)               (None, 50)           1050        ['activation_8[0][0]']           \n",
      "                                                                                                  \n",
      " batch_normalization_11 (BatchN  (None, 50)          200         ['dense_10[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_10 (Dropout)           (None, 50)           0           ['batch_normalization_11[0][0]'] \n",
      "                                                                                                  \n",
      " activation_9 (Activation)      (None, 50)           0           ['dropout_10[0][0]']             \n",
      "                                                                                                  \n",
      " dense_11 (Dense)               (None, 20)           1020        ['activation_9[0][0]']           \n",
      "                                                                                                  \n",
      " add_2 (Add)                    (None, 20)           0           ['dense_9[0][0]',                \n",
      "                                                                  'dense_11[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_12 (BatchN  (None, 20)          80          ['add_2[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_11 (Dropout)           (None, 20)           0           ['batch_normalization_12[0][0]'] \n",
      "                                                                                                  \n",
      " activation_10 (Activation)     (None, 20)           0           ['dropout_11[0][0]']             \n",
      "                                                                                                  \n",
      " dense_12 (Dense)               (None, 50)           1050        ['activation_10[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_13 (BatchN  (None, 50)          200         ['dense_12[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_12 (Dropout)           (None, 50)           0           ['batch_normalization_13[0][0]'] \n",
      "                                                                                                  \n",
      " activation_11 (Activation)     (None, 50)           0           ['dropout_12[0][0]']             \n",
      "                                                                                                  \n",
      " dense_13 (Dense)               (None, 20)           1020        ['activation_11[0][0]']          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " add_3 (Add)                    (None, 20)           0           ['add_2[0][0]',                  \n",
      "                                                                  'dense_13[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_14 (BatchN  (None, 20)          80          ['add_3[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_13 (Dropout)           (None, 20)           0           ['batch_normalization_14[0][0]'] \n",
      "                                                                                                  \n",
      " relation_0 (Dense)             (None, 6)            126         ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " source_0 (Dense)               (None, 5)            105         ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      " target_0 (Dense)               (None, 5)            105         ['dropout_13[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,599,848\n",
      "Trainable params: 112,408\n",
      "Non-trainable params: 4,487,440\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_attention_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_9 (InputLayer)           [(None, 70)]         0           []                               \n",
      "                                                                                                  \n",
      " input_11 (InputLayer)          [(None, 70)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_3 (Embedding)        (None, 70, 300)      2242500     ['input_11[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_2 (Embedding)        (None, 70, 300)      2242500     ['input_9[0][0]']                \n",
      "                                                                                                  \n",
      " time_distributed_4 (TimeDistri  (None, 70, 300)     37250       ['embedding_3[0][0]']            \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_distributed_3 (TimeDistri  (None, 70, 300)     37250       ['embedding_2[0][0]']            \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " add_5 (Add)                    (None, 70, 300)      0           ['embedding_3[0][0]',            \n",
      "                                                                  'time_distributed_4[0][0]']     \n",
      "                                                                                                  \n",
      " add_4 (Add)                    (None, 70, 300)      0           ['embedding_2[0][0]',            \n",
      "                                                                  'time_distributed_3[0][0]']     \n",
      "                                                                                                  \n",
      " model_6 (Functional)           (None, 70, 50)       15250       ['add_4[0][0]',                  \n",
      "                                                                  'add_5[0][0]']                  \n",
      "                                                                                                  \n",
      " model_7 (Functional)           (None, 70, 25)       15200       ['model_6[0][0]',                \n",
      "                                                                  'model_6[1][0]']                \n",
      "                                                                                                  \n",
      " avg_query_target_1 (GlobalAver  (None, 25)          0           ['model_7[1][0]']                \n",
      " agePooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " avg_query_source_1 (GlobalAver  (None, 25)          0           ['model_7[0][0]']                \n",
      " agePooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " att_linearity_query_source_1 (  (None, 20)          520         ['avg_query_target_1[0][0]']     \n",
      " Dense)                                                                                           \n",
      "                                                                                                  \n",
      " att_linearity_query_target_1 (  (None, 20)          520         ['avg_query_source_1[0][0]']     \n",
      " Dense)                                                                                           \n",
      "                                                                                                  \n",
      " repeat_query_source_1 (RepeatV  (None, 70, 20)      0           ['att_linearity_query_source_1[0]\n",
      " ector)                                                          [0]']                            \n",
      "                                                                                                  \n",
      " att_K_source_1 (TimeDistribute  (None, 70, 20)      520         ['model_7[0][0]']                \n",
      " d)                                                                                               \n",
      "                                                                                                  \n",
      " repeat_query_target_1 (RepeatV  (None, 70, 20)      0           ['att_linearity_query_target_1[0]\n",
      " ector)                                                          [0]']                            \n",
      "                                                                                                  \n",
      " att_K_target_1 (TimeDistribute  (None, 70, 20)      520         ['model_7[1][0]']                \n",
      " d)                                                                                               \n",
      "                                                                                                  \n",
      " att_addition_source_1 (Add)    (None, 70, 20)       0           ['repeat_query_source_1[0][0]',  \n",
      "                                                                  'att_K_source_1[0][0]']         \n",
      "                                                                                                  \n",
      " att_addition_target_1 (Add)    (None, 70, 20)       0           ['repeat_query_target_1[0][0]',  \n",
      "                                                                  'att_K_target_1[0][0]']         \n",
      "                                                                                                  \n",
      " att_activation_source_1 (Activ  (None, 70, 20)      0           ['att_addition_source_1[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " att_activation_target_1 (Activ  (None, 70, 20)      0           ['att_addition_target_1[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " masking (Lambda)               (None, 70)           0           ['input_9[0][0]',                \n",
      "                                                                  'input_11[0][0]']               \n",
      "                                                                                                  \n",
      " att_scores_source_1 (TimeDistr  (None, 70, 1)       21          ['att_activation_source_1[0][0]']\n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " att_scores_target_1 (TimeDistr  (None, 70, 1)       21          ['att_activation_target_1[0][0]']\n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " negative_mul (Lambda)          (None, 70)           0           ['masking[0][0]',                \n",
      "                                                                  'masking[1][0]']                \n",
      "                                                                                                  \n",
      " att_scores_flat_source_1 (Flat  (None, 70)          0           ['att_scores_source_1[0][0]']    \n",
      " ten)                                                                                             \n",
      "                                                                                                  \n",
      " att_scores_flat_target_1 (Flat  (None, 70)          0           ['att_scores_target_1[0][0]']    \n",
      " ten)                                                                                             \n",
      "                                                                                                  \n",
      " att_masked_addition_source_1 (  (None, 70)          0           ['negative_mul[0][0]',           \n",
      " Add)                                                             'att_scores_flat_source_1[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " att_masked_addition_target_1 (  (None, 70)          0           ['negative_mul[1][0]',           \n",
      " Add)                                                             'att_scores_flat_target_1[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " att_weights_source_1 (Activati  (None, 70)          0           ['att_masked_addition_source_1[0]\n",
      " on)                                                             [0]']                            \n",
      "                                                                                                  \n",
      " att_weights_target_1 (Activati  (None, 70)          0           ['att_masked_addition_target_1[0]\n",
      " on)                                                             [0]']                            \n",
      "                                                                                                  \n",
      " att_weights_reshape_source_1 (  (None, 70, 1)       0           ['att_weights_source_1[0][0]']   \n",
      " Reshape)                                                                                         \n",
      "                                                                                                  \n",
      " att_weights_reshape_target_1 (  (None, 70, 1)       0           ['att_weights_target_1[0][0]']   \n",
      " Reshape)                                                                                         \n",
      "                                                                                                  \n",
      " att_multiply_source_1 (Multipl  (None, 70, 50)      0           ['att_weights_reshape_source_1[0]\n",
      " y)                                                              [0]',                            \n",
      "                                                                  'model_6[0][0]']                \n",
      "                                                                                                  \n",
      " att_multiply_target_1 (Multipl  (None, 70, 50)      0           ['att_weights_reshape_target_1[0]\n",
      " y)                                                              [0]',                            \n",
      "                                                                  'model_6[1][0]']                \n",
      "                                                                                                  \n",
      " att_cv_source_1 (Lambda)       (None, 50)           0           ['att_multiply_source_1[0][0]']  \n",
      "                                                                                                  \n",
      " att_cv_target_1 (Lambda)       (None, 50)           0           ['att_multiply_target_1[0][0]']  \n",
      "                                                                                                  \n",
      " input_8 (InputLayer)           [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 110)          0           ['att_cv_source_1[0][0]',        \n",
      "                                                                  'att_cv_target_1[0][0]',        \n",
      "                                                                  'input_8[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_24 (BatchN  (None, 110)         440         ['concatenate_1[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_22 (Dropout)           (None, 110)          0           ['batch_normalization_24[0][0]'] \n",
      "                                                                                                  \n",
      " dense_23 (Dense)               (None, 20)           2220        ['dropout_22[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_25 (BatchN  (None, 20)          80          ['dense_23[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_23 (Dropout)           (None, 20)           0           ['batch_normalization_25[0][0]'] \n",
      "                                                                                                  \n",
      " activation_20 (Activation)     (None, 20)           0           ['dropout_23[0][0]']             \n",
      "                                                                                                  \n",
      " dense_24 (Dense)               (None, 50)           1050        ['activation_20[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_26 (BatchN  (None, 50)          200         ['dense_24[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_24 (Dropout)           (None, 50)           0           ['batch_normalization_26[0][0]'] \n",
      "                                                                                                  \n",
      " activation_21 (Activation)     (None, 50)           0           ['dropout_24[0][0]']             \n",
      "                                                                                                  \n",
      " dense_25 (Dense)               (None, 20)           1020        ['activation_21[0][0]']          \n",
      "                                                                                                  \n",
      " add_6 (Add)                    (None, 20)           0           ['dense_23[0][0]',               \n",
      "                                                                  'dense_25[0][0]']               \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " batch_normalization_27 (BatchN  (None, 20)          80          ['add_6[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_25 (Dropout)           (None, 20)           0           ['batch_normalization_27[0][0]'] \n",
      "                                                                                                  \n",
      " activation_22 (Activation)     (None, 20)           0           ['dropout_25[0][0]']             \n",
      "                                                                                                  \n",
      " dense_26 (Dense)               (None, 50)           1050        ['activation_22[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_28 (BatchN  (None, 50)          200         ['dense_26[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_26 (Dropout)           (None, 50)           0           ['batch_normalization_28[0][0]'] \n",
      "                                                                                                  \n",
      " activation_23 (Activation)     (None, 50)           0           ['dropout_26[0][0]']             \n",
      "                                                                                                  \n",
      " dense_27 (Dense)               (None, 20)           1020        ['activation_23[0][0]']          \n",
      "                                                                                                  \n",
      " add_7 (Add)                    (None, 20)           0           ['add_6[0][0]',                  \n",
      "                                                                  'dense_27[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_29 (BatchN  (None, 20)          80          ['add_7[0][0]']                  \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_27 (Dropout)           (None, 20)           0           ['batch_normalization_29[0][0]'] \n",
      "                                                                                                  \n",
      " relation_1 (Dense)             (None, 6)            126         ['dropout_27[0][0]']             \n",
      "                                                                                                  \n",
      " source_1 (Dense)               (None, 5)            105         ['dropout_27[0][0]']             \n",
      "                                                                                                  \n",
      " target_1 (Dense)               (None, 5)            105         ['dropout_27[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,599,848\n",
      "Trainable params: 112,408\n",
      "Non-trainable params: 4,487,440\n",
      "__________________________________________________________________________________________________\n",
      "Model: \"model_attention_2\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_16 (InputLayer)          [(None, 70)]         0           []                               \n",
      "                                                                                                  \n",
      " input_18 (InputLayer)          [(None, 70)]         0           []                               \n",
      "                                                                                                  \n",
      " embedding_5 (Embedding)        (None, 70, 300)      2242500     ['input_18[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_4 (Embedding)        (None, 70, 300)      2242500     ['input_16[0][0]']               \n",
      "                                                                                                  \n",
      " time_distributed_7 (TimeDistri  (None, 70, 300)     37250       ['embedding_5[0][0]']            \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " time_distributed_6 (TimeDistri  (None, 70, 300)     37250       ['embedding_4[0][0]']            \n",
      " buted)                                                                                           \n",
      "                                                                                                  \n",
      " add_9 (Add)                    (None, 70, 300)      0           ['embedding_5[0][0]',            \n",
      "                                                                  'time_distributed_7[0][0]']     \n",
      "                                                                                                  \n",
      " add_8 (Add)                    (None, 70, 300)      0           ['embedding_4[0][0]',            \n",
      "                                                                  'time_distributed_6[0][0]']     \n",
      "                                                                                                  \n",
      " model_10 (Functional)          (None, 70, 50)       15250       ['add_8[0][0]',                  \n",
      "                                                                  'add_9[0][0]']                  \n",
      "                                                                                                  \n",
      " model_11 (Functional)          (None, 70, 25)       15200       ['model_10[0][0]',               \n",
      "                                                                  'model_10[1][0]']               \n",
      "                                                                                                  \n",
      " avg_query_target_2 (GlobalAver  (None, 25)          0           ['model_11[1][0]']               \n",
      " agePooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " avg_query_source_2 (GlobalAver  (None, 25)          0           ['model_11[0][0]']               \n",
      " agePooling1D)                                                                                    \n",
      "                                                                                                  \n",
      " att_linearity_query_source_2 (  (None, 20)          520         ['avg_query_target_2[0][0]']     \n",
      " Dense)                                                                                           \n",
      "                                                                                                  \n",
      " att_linearity_query_target_2 (  (None, 20)          520         ['avg_query_source_2[0][0]']     \n",
      " Dense)                                                                                           \n",
      "                                                                                                  \n",
      " repeat_query_source_2 (RepeatV  (None, 70, 20)      0           ['att_linearity_query_source_2[0]\n",
      " ector)                                                          [0]']                            \n",
      "                                                                                                  \n",
      " att_K_source_2 (TimeDistribute  (None, 70, 20)      520         ['model_11[0][0]']               \n",
      " d)                                                                                               \n",
      "                                                                                                  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " repeat_query_target_2 (RepeatV  (None, 70, 20)      0           ['att_linearity_query_target_2[0]\n",
      " ector)                                                          [0]']                            \n",
      "                                                                                                  \n",
      " att_K_target_2 (TimeDistribute  (None, 70, 20)      520         ['model_11[1][0]']               \n",
      " d)                                                                                               \n",
      "                                                                                                  \n",
      " att_addition_source_2 (Add)    (None, 70, 20)       0           ['repeat_query_source_2[0][0]',  \n",
      "                                                                  'att_K_source_2[0][0]']         \n",
      "                                                                                                  \n",
      " att_addition_target_2 (Add)    (None, 70, 20)       0           ['repeat_query_target_2[0][0]',  \n",
      "                                                                  'att_K_target_2[0][0]']         \n",
      "                                                                                                  \n",
      " att_activation_source_2 (Activ  (None, 70, 20)      0           ['att_addition_source_2[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " att_activation_target_2 (Activ  (None, 70, 20)      0           ['att_addition_target_2[0][0]']  \n",
      " ation)                                                                                           \n",
      "                                                                                                  \n",
      " masking (Lambda)               (None, 70)           0           ['input_16[0][0]',               \n",
      "                                                                  'input_18[0][0]']               \n",
      "                                                                                                  \n",
      " att_scores_source_2 (TimeDistr  (None, 70, 1)       21          ['att_activation_source_2[0][0]']\n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " att_scores_target_2 (TimeDistr  (None, 70, 1)       21          ['att_activation_target_2[0][0]']\n",
      " ibuted)                                                                                          \n",
      "                                                                                                  \n",
      " negative_mul (Lambda)          (None, 70)           0           ['masking[0][0]',                \n",
      "                                                                  'masking[1][0]']                \n",
      "                                                                                                  \n",
      " att_scores_flat_source_2 (Flat  (None, 70)          0           ['att_scores_source_2[0][0]']    \n",
      " ten)                                                                                             \n",
      "                                                                                                  \n",
      " att_scores_flat_target_2 (Flat  (None, 70)          0           ['att_scores_target_2[0][0]']    \n",
      " ten)                                                                                             \n",
      "                                                                                                  \n",
      " att_masked_addition_source_2 (  (None, 70)          0           ['negative_mul[0][0]',           \n",
      " Add)                                                             'att_scores_flat_source_2[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " att_masked_addition_target_2 (  (None, 70)          0           ['negative_mul[1][0]',           \n",
      " Add)                                                             'att_scores_flat_target_2[0][0]'\n",
      "                                                                 ]                                \n",
      "                                                                                                  \n",
      " att_weights_source_2 (Activati  (None, 70)          0           ['att_masked_addition_source_2[0]\n",
      " on)                                                             [0]']                            \n",
      "                                                                                                  \n",
      " att_weights_target_2 (Activati  (None, 70)          0           ['att_masked_addition_target_2[0]\n",
      " on)                                                             [0]']                            \n",
      "                                                                                                  \n",
      " att_weights_reshape_source_2 (  (None, 70, 1)       0           ['att_weights_source_2[0][0]']   \n",
      " Reshape)                                                                                         \n",
      "                                                                                                  \n",
      " att_weights_reshape_target_2 (  (None, 70, 1)       0           ['att_weights_target_2[0][0]']   \n",
      " Reshape)                                                                                         \n",
      "                                                                                                  \n",
      " att_multiply_source_2 (Multipl  (None, 70, 50)      0           ['att_weights_reshape_source_2[0]\n",
      " y)                                                              [0]',                            \n",
      "                                                                  'model_10[0][0]']               \n",
      "                                                                                                  \n",
      " att_multiply_target_2 (Multipl  (None, 70, 50)      0           ['att_weights_reshape_target_2[0]\n",
      " y)                                                              [0]',                            \n",
      "                                                                  'model_10[1][0]']               \n",
      "                                                                                                  \n",
      " att_cv_source_2 (Lambda)       (None, 50)           0           ['att_multiply_source_2[0][0]']  \n",
      "                                                                                                  \n",
      " att_cv_target_2 (Lambda)       (None, 50)           0           ['att_multiply_target_2[0][0]']  \n",
      "                                                                                                  \n",
      " input_15 (InputLayer)          [(None, 10)]         0           []                               \n",
      "                                                                                                  \n",
      " concatenate_2 (Concatenate)    (None, 110)          0           ['att_cv_source_2[0][0]',        \n",
      "                                                                  'att_cv_target_2[0][0]',        \n",
      "                                                                  'input_15[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_39 (BatchN  (None, 110)         440         ['concatenate_2[0][0]']          \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_36 (Dropout)           (None, 110)          0           ['batch_normalization_39[0][0]'] \n",
      "                                                                                                  \n",
      " dense_37 (Dense)               (None, 20)           2220        ['dropout_36[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_40 (BatchN  (None, 20)          80          ['dense_37[0][0]']               \n",
      " ormalization)                                                                                    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 20)           0           ['batch_normalization_40[0][0]'] \n",
      "                                                                                                  \n",
      " activation_32 (Activation)     (None, 20)           0           ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      " dense_38 (Dense)               (None, 50)           1050        ['activation_32[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_41 (BatchN  (None, 50)          200         ['dense_38[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_38 (Dropout)           (None, 50)           0           ['batch_normalization_41[0][0]'] \n",
      "                                                                                                  \n",
      " activation_33 (Activation)     (None, 50)           0           ['dropout_38[0][0]']             \n",
      "                                                                                                  \n",
      " dense_39 (Dense)               (None, 20)           1020        ['activation_33[0][0]']          \n",
      "                                                                                                  \n",
      " add_10 (Add)                   (None, 20)           0           ['dense_37[0][0]',               \n",
      "                                                                  'dense_39[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_42 (BatchN  (None, 20)          80          ['add_10[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_39 (Dropout)           (None, 20)           0           ['batch_normalization_42[0][0]'] \n",
      "                                                                                                  \n",
      " activation_34 (Activation)     (None, 20)           0           ['dropout_39[0][0]']             \n",
      "                                                                                                  \n",
      " dense_40 (Dense)               (None, 50)           1050        ['activation_34[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_43 (BatchN  (None, 50)          200         ['dense_40[0][0]']               \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_40 (Dropout)           (None, 50)           0           ['batch_normalization_43[0][0]'] \n",
      "                                                                                                  \n",
      " activation_35 (Activation)     (None, 50)           0           ['dropout_40[0][0]']             \n",
      "                                                                                                  \n",
      " dense_41 (Dense)               (None, 20)           1020        ['activation_35[0][0]']          \n",
      "                                                                                                  \n",
      " add_11 (Add)                   (None, 20)           0           ['add_10[0][0]',                 \n",
      "                                                                  'dense_41[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_44 (BatchN  (None, 20)          80          ['add_11[0][0]']                 \n",
      " ormalization)                                                                                    \n",
      "                                                                                                  \n",
      " dropout_41 (Dropout)           (None, 20)           0           ['batch_normalization_44[0][0]'] \n",
      "                                                                                                  \n",
      " relation_2 (Dense)             (None, 6)            126         ['dropout_41[0][0]']             \n",
      "                                                                                                  \n",
      " source_2 (Dense)               (None, 5)            105         ['dropout_41[0][0]']             \n",
      "                                                                                                  \n",
      " target_2 (Dense)               (None, 5)            105         ['dropout_41[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4,599,848\n",
      "Trainable params: 112,408\n",
      "Non-trainable params: 4,487,440\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Build Model\n",
    "\n",
    "def build_model(params: dict):\n",
    "    linear_embedders_dims = params['linear_embedders_dims'] # [50, 50, 50, 300]\n",
    "    max_sequence_size = params['max_size_prop']\n",
    "    words_amount = len(params['sequence_vectorizer'].get_vocabulary()) # Plus UNK and Pad\n",
    "    embedding_dim = params['dim']\n",
    "    embedding_matrix = params['embedding_matrix']\n",
    "    regularizer_weight = params['regularizer_weight']\n",
    "    dropout = params['dropout']\n",
    "    final_embedding_dimension = params['encoder_dense_units']\n",
    "    final_layer_size = params['final_size']\n",
    "    pool_size = params['encoder_pool_size']\n",
    "    distance_encoding_bits = params['max_distance_encoded'] * 2\n",
    "    lstm_units = params['lstm_units']\n",
    "    res_size = params['residual_size']\n",
    "    relation_amount = len(params['relation_tag_vectorizer'].get_vocabulary()) # Plus UNK and Pad\n",
    "    proposition_tag_amount = len(params['proposition_tag_vectorizer'].get_vocabulary()) # Plus UNK and Pad\n",
    "    with_attention = params['with_attention']\n",
    "    ensemble_amount = params['ensemble_amount']\n",
    "    \n",
    "    def build_embedder(max_sequence_size, words_amount, embedding_dim, embedding_matrix, linear_layers_dims, regularizer_weight, dropout):\n",
    "        \"\"\"\n",
    "        Builds a proposition embedder\n",
    "        \"\"\"\n",
    "        \n",
    "        # Input layer\n",
    "        int_sequence_input = keras.Input(\n",
    "            shape=(max_sequence_size,), \n",
    "            dtype=\"int64\"\n",
    "        )\n",
    "\n",
    "        # Embedding layer, convert an index vector into a embedding vector, by accessing embedding_matrix\n",
    "        embedding_layer = layers.Embedding(\n",
    "            words_amount,\n",
    "            embedding_dim,\n",
    "            embeddings_initializer=keras.initializers.Constant(embedding_matrix),\n",
    "            trainable=False,\n",
    "            input_length=max_sequence_size,\n",
    "        )\n",
    "\n",
    "        initial_layer = model_layers = embedding_layer(int_sequence_input)\n",
    "\n",
    "        def get_linear_layer(dense_dim, linear_layer=None):\n",
    "            \"\"\"\n",
    "            Creates a single dense layer for the embedder\n",
    "            \"\"\"\n",
    "            \n",
    "            if linear_layer is None:\n",
    "                input_vec = keras.Input(shape=(embedding_dim,))\n",
    "            else:\n",
    "                input_vec = linear_layer\n",
    "            \n",
    "            linear_layer = layers.Dense(\n",
    "                units=dense_dim,\n",
    "                activation=None,\n",
    "                kernel_initializer='he_normal',\n",
    "                kernel_regularizer=keras.regularizers.l2(regularizer_weight),\n",
    "                bias_regularizer=keras.regularizers.l2(regularizer_weight)\n",
    "            )(input_vec)\n",
    "            \n",
    "            linear_layer = layers.BatchNormalization()(linear_layer)\n",
    "            linear_layer = layers.Dropout(dropout)(linear_layer)\n",
    "            linear_layer = layers.Activation('relu')(linear_layer)\n",
    "            return input_vec, linear_layer\n",
    "        \n",
    "        # Linear transformation\n",
    "        linear_input, linear_layer = get_linear_layer(linear_layers_dims[0])\n",
    "        for dim in linear_layers_dims[1:]:\n",
    "            _, linear_layer = get_linear_layer(dim, linear_layer)\n",
    "        linear_layer = keras.Model(inputs=linear_input, outputs=linear_layer)\n",
    "        \n",
    "        # Apply linear_layer to each word embedding\n",
    "        model_layers = layers.TimeDistributed(linear_layer)(model_layers)\n",
    "        \n",
    "        # Residual connection\n",
    "        model_layers = layers.Add()([initial_layer, model_layers])\n",
    "        \n",
    "        return int_sequence_input, model_layers\n",
    "    \n",
    "    def build_dense_encoder(max_sequence_size, embedding_dim, final_dimension, pool_size, regularizer_weight):\n",
    "        \n",
    "        # Input layer\n",
    "        embedding_inputs = keras.Input(\n",
    "            shape=(max_sequence_size, embedding_dim)\n",
    "        )\n",
    "        \n",
    "        encoder_layer = embedding_inputs\n",
    "        \n",
    "        linear_layer = layers.Dense(\n",
    "            units=final_dimension,\n",
    "            activation='relu',\n",
    "            kernel_regularizer=keras.regularizers.l2(regularizer_weight),\n",
    "            bias_regularizer=keras.regularizers.l2(regularizer_weight)\n",
    "        )\n",
    "        \n",
    "        # Apply linear_layer to each word embedding\n",
    "        encoder_layer = layers.TimeDistributed(linear_layer)(encoder_layer)\n",
    "        \n",
    "        # Average the words embeddings\n",
    "        encoder_layer = layers.AveragePooling1D(\n",
    "            pool_size=pool_size,\n",
    "        )(encoder_layer)\n",
    "    \n",
    "        encoder_layer = layers.BatchNormalization()(encoder_layer)\n",
    "    \n",
    "        return keras.Model(inputs=embedding_inputs, outputs=encoder_layer)\n",
    "    \n",
    "    def build_bilstm_encoder(sequence_size, encoded_dim, lstm_units, dropout, regularizer_weight, return_sequences):\n",
    "\n",
    "        # Input layer\n",
    "        embedding_inputs = keras.Input(\n",
    "            shape=(sequence_size, encoded_dim)\n",
    "        )\n",
    "        \n",
    "        bilstm_layer = layers.Bidirectional(\n",
    "            layers.LSTM(\n",
    "                units=lstm_units,\n",
    "                dropout=dropout,\n",
    "                recurrent_dropout=dropout,\n",
    "                kernel_regularizer=keras.regularizers.l2(regularizer_weight),\n",
    "                recurrent_regularizer=keras.regularizers.l2(regularizer_weight),\n",
    "                bias_regularizer=keras.regularizers.l2(regularizer_weight),\n",
    "                return_sequences=return_sequences,\n",
    "            ),\n",
    "            merge_mode='mul'\n",
    "        )(embedding_inputs)\n",
    "        \n",
    "        return keras.Model(inputs=embedding_inputs, outputs=bilstm_layer)\n",
    "    \n",
    "    def apply_resnet(input_layer, regularizer_weight, res_size, dropout):\n",
    "        prev_layer = input_layer\n",
    "        prev_block = prev_layer\n",
    "        \n",
    "        layers_dims = (2, 2)\n",
    "        blocks = layers_dims[0]\n",
    "        res_layers = layers_dims[1]\n",
    "\n",
    "        shape = int(np.shape(input_layer)[1])\n",
    "\n",
    "        for i in range(1, blocks + 1):\n",
    "            for j in range(1, res_layers):\n",
    "                prev_layer = layers.BatchNormalization()(prev_layer)\n",
    "\n",
    "                prev_layer = layers.Dropout(dropout)(prev_layer)\n",
    "\n",
    "                prev_layer = layers.Activation('relu')(prev_layer)\n",
    "\n",
    "                prev_layer = layers.Dense(\n",
    "                    units=res_size,\n",
    "                    activation=None,\n",
    "                    kernel_initializer='he_normal',\n",
    "                    kernel_regularizer=keras.regularizers.l2(regularizer_weight),\n",
    "                    bias_regularizer=keras.regularizers.l2(regularizer_weight),\n",
    "                )(prev_layer)\n",
    "            \n",
    "            prev_layer = layers.BatchNormalization()(prev_layer)\n",
    "\n",
    "            prev_layer = layers.Dropout(dropout)(prev_layer)\n",
    "\n",
    "            prev_layer = layers.Activation('relu')(prev_layer)\n",
    "\n",
    "            prev_layer = layers.Dense(units=shape,\n",
    "                               activation=None,\n",
    "                               kernel_initializer='he_normal',\n",
    "                               kernel_regularizer=keras.regularizers.l2(regularizer_weight),\n",
    "                               bias_regularizer=keras.regularizers.l2(regularizer_weight),\n",
    "                               )(prev_layer)\n",
    "\n",
    "            prev_layer = layers.Add()([prev_block, prev_layer])\n",
    "            prev_block = prev_layer\n",
    "\n",
    "        return prev_block\n",
    "    \n",
    "    def create_single_model(index):\n",
    "        \"\"\"\n",
    "        Create a single model for the ensemble learning\n",
    "        \"\"\"\n",
    "        \n",
    "        input_distance = keras.Input(\n",
    "            shape=(distance_encoding_bits, )\n",
    "        )\n",
    "\n",
    "        input_source_embedder, source_embedder = build_embedder(\n",
    "            max_sequence_size, \n",
    "            words_amount, \n",
    "            embedding_dim, \n",
    "            embedding_matrix, \n",
    "            linear_embedders_dims, \n",
    "            regularizer_weight, \n",
    "            dropout\n",
    "        )\n",
    "\n",
    "        input_target_embedder, target_embedder = build_embedder(\n",
    "            max_sequence_size, \n",
    "            words_amount, \n",
    "            embedding_dim, \n",
    "            embedding_matrix, \n",
    "            linear_embedders_dims, \n",
    "            regularizer_weight, \n",
    "            dropout\n",
    "        )\n",
    "\n",
    "        dense_encoder = build_dense_encoder(\n",
    "            max_sequence_size, \n",
    "            embedding_dim, \n",
    "            final_embedding_dimension, \n",
    "            pool_size, \n",
    "            regularizer_weight\n",
    "        )\n",
    "\n",
    "        bilstm_encoder = build_bilstm_encoder(\n",
    "            max_sequence_size, \n",
    "            final_embedding_dimension, \n",
    "            lstm_units, \n",
    "            dropout, \n",
    "            regularizer_weight,\n",
    "            with_attention\n",
    "        )\n",
    "\n",
    "        # Apply dense encoder to source and target sequence features\n",
    "        prev_source_layers = source_layers = dense_encoder(source_embedder)\n",
    "        prev_target_layers = target_layers = dense_encoder(target_embedder)\n",
    "\n",
    "        # Apply bilstm encoder to source and target sequence features\n",
    "        source_layers = bilstm_encoder(source_layers)\n",
    "        target_layers = bilstm_encoder(target_layers)\n",
    "\n",
    "        if with_attention:\n",
    "            source_layers, target_layers = apply_attention(\n",
    "                input_source_embedder, \n",
    "                input_target_embedder,\n",
    "                prev_source_layers,\n",
    "                prev_target_layers,\n",
    "                source_layers,\n",
    "                target_layers,\n",
    "                final_layer_size,\n",
    "                index,\n",
    "            )\n",
    "\n",
    "        # Concatenate source and target sequence features with other features \n",
    "        model_layers = layers.Concatenate()([source_layers, target_layers, input_distance])\n",
    "        model_layers = layers.BatchNormalization()(model_layers)\n",
    "        model_layers = layers.Dropout(dropout)(model_layers)\n",
    "\n",
    "        # Middle dense layer\n",
    "        model_layers = layers.Dense(\n",
    "            units=final_layer_size,\n",
    "            activation='relu',\n",
    "            kernel_initializer='he_normal',\n",
    "            kernel_regularizer=keras.regularizers.l2(regularizer_weight),\n",
    "            bias_regularizer=keras.regularizers.l2(regularizer_weight),\n",
    "        )(model_layers)\n",
    "\n",
    "        # Apply a residual network\n",
    "        model_layers = apply_resnet(\n",
    "            model_layers,\n",
    "            regularizer_weight,\n",
    "            res_size,\n",
    "            dropout\n",
    "        )\n",
    "\n",
    "\n",
    "        model_layers = layers.BatchNormalization()(model_layers)\n",
    "        model_layers = layers.Dropout(dropout)(model_layers)\n",
    "\n",
    "        # Classifiers\n",
    "        relation_classifier = layers.Dense(\n",
    "            units=relation_amount,\n",
    "            activation='softmax',\n",
    "            name=f\"relation_{index}\",\n",
    "        )(model_layers)\n",
    "\n",
    "        source_classifier = layers.Dense(\n",
    "            units=proposition_tag_amount,\n",
    "            activation='softmax',\n",
    "            name=f\"source_{index}\",\n",
    "        )(model_layers)\n",
    "\n",
    "        target_classifier = layers.Dense(\n",
    "            units=proposition_tag_amount,\n",
    "            activation='softmax',\n",
    "            name=f\"target_{index}\",\n",
    "        )(model_layers)\n",
    "\n",
    "        # Creating final model\n",
    "        model = keras.Model(\n",
    "            inputs=(input_source_embedder, input_target_embedder, input_distance),\n",
    "            outputs=(relation_classifier, source_classifier, target_classifier),\n",
    "            name=f\"{params['model_name']}_{index}\"\n",
    "        )\n",
    "    \n",
    "        model.summary()\n",
    "        \n",
    "        return model\n",
    "    \n",
    "    models = []\n",
    "    \n",
    "    for i in range(ensemble_amount):\n",
    "        model = create_single_model(i)\n",
    "        models.append(model)\n",
    "    \n",
    "    params[params['model_name']] = models\n",
    "\n",
    "build_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNEW LR: 0.003\n",
      "\tNEW LR: 0.003\n",
      "Epoch 1/70\n",
      "1948/1948 [==============================] - 461s 222ms/step - loss: 5.5677 - relation_0_loss: 0.2297 - source_0_loss: 0.6124 - target_0_loss: 0.5811 - relation_0_acc: 0.9269 - relation_0_relation_0F1Macro: 0.3743 - source_0_acc: 0.7564 - source_0_source_0F1Macro: 0.1785 - target_0_acc: 0.7722 - target_0_target_0F1Macro: 0.2238 - val_loss: 4.3130 - val_relation_0_loss: 0.1667 - val_source_0_loss: 0.5226 - val_target_0_loss: 0.5508 - val_relation_0_acc: 0.9335 - val_relation_0_relation_0F1Macro: 0.3427 - val_source_0_acc: 0.7846 - val_source_0_source_0F1Macro: 0.1759 - val_target_0_acc: 0.7433 - val_target_0_target_0F1Macro: 0.2386 - lr: 0.0030\n",
      "\tNEW LR: 0.0029970029970029974\n",
      "Epoch 2/70\n",
      "1948/1948 [==============================] - 421s 216ms/step - loss: 3.6088 - relation_0_loss: 0.1387 - source_0_loss: 0.5340 - target_0_loss: 0.4790 - relation_0_acc: 0.9561 - relation_0_relation_0F1Macro: 0.4080 - source_0_acc: 0.7791 - source_0_source_0F1Macro: 0.1752 - target_0_acc: 0.7953 - target_0_target_0F1Macro: 0.2312 - val_loss: 3.3317 - val_relation_0_loss: 0.1430 - val_source_0_loss: 0.5242 - val_target_0_loss: 0.5065 - val_relation_0_acc: 0.9375 - val_relation_0_relation_0F1Macro: 0.3602 - val_source_0_acc: 0.7846 - val_source_0_source_0F1Macro: 0.1759 - val_target_0_acc: 0.7852 - val_target_0_target_0F1Macro: 0.2015 - lr: 0.0030\n",
      "\tNEW LR: 0.0029940119760479044\n",
      "Epoch 3/70\n",
      "1948/1948 [==============================] - 422s 217ms/step - loss: 3.0023 - relation_0_loss: 0.1315 - source_0_loss: 0.5331 - target_0_loss: 0.4595 - relation_0_acc: 0.9578 - relation_0_relation_0F1Macro: 0.4122 - source_0_acc: 0.7791 - source_0_source_0F1Macro: 0.1752 - target_0_acc: 0.7989 - target_0_target_0F1Macro: 0.2408 - val_loss: 3.0509 - val_relation_0_loss: 0.1411 - val_source_0_loss: 0.5159 - val_target_0_loss: 0.4958 - val_relation_0_acc: 0.9368 - val_relation_0_relation_0F1Macro: 0.3591 - val_source_0_acc: 0.7846 - val_source_0_source_0F1Macro: 0.1759 - val_target_0_acc: 0.7819 - val_target_0_target_0F1Macro: 0.2232 - lr: 0.0030\n",
      "\tNEW LR: 0.0029910269192422734\n",
      "Epoch 4/70\n",
      "1948/1948 [==============================] - 420s 216ms/step - loss: 2.8253 - relation_0_loss: 0.1316 - source_0_loss: 0.5330 - target_0_loss: 0.4546 - relation_0_acc: 0.9584 - relation_0_relation_0F1Macro: 0.4134 - source_0_acc: 0.7792 - source_0_source_0F1Macro: 0.1752 - target_0_acc: 0.7983 - target_0_target_0F1Macro: 0.2399 - val_loss: 2.8153 - val_relation_0_loss: 0.1363 - val_source_0_loss: 0.5095 - val_target_0_loss: 0.4720 - val_relation_0_acc: 0.9421 - val_relation_0_relation_0F1Macro: 0.3719 - val_source_0_acc: 0.7846 - val_source_0_source_0F1Macro: 0.1759 - val_target_0_acc: 0.7828 - val_target_0_target_0F1Macro: 0.2134 - lr: 0.0030\n",
      "\tNEW LR: 0.00298804780876494\n",
      "Epoch 5/70\n",
      "1948/1948 [==============================] - 422s 217ms/step - loss: 2.6394 - relation_0_loss: 0.1224 - source_0_loss: 0.5320 - target_0_loss: 0.4472 - relation_0_acc: 0.9598 - relation_0_relation_0F1Macro: 0.4162 - source_0_acc: 0.7792 - source_0_source_0F1Macro: 0.1752 - target_0_acc: 0.8001 - target_0_target_0F1Macro: 0.2452 - val_loss: 3.0952 - val_relation_0_loss: 0.1527 - val_source_0_loss: 0.5043 - val_target_0_loss: 0.4975 - val_relation_0_acc: 0.9384 - val_relation_0_relation_0F1Macro: 0.3579 - val_source_0_acc: 0.7846 - val_source_0_source_0F1Macro: 0.1759 - val_target_0_acc: 0.7650 - val_target_0_target_0F1Macro: 0.2343 - lr: 0.0030\n",
      "\tNEW LR: 0.002985074626865672\n",
      "Epoch 6/70\n",
      "1948/1948 [==============================] - 422s 217ms/step - loss: 2.7072 - relation_0_loss: 0.1228 - source_0_loss: 0.5308 - target_0_loss: 0.4456 - relation_0_acc: 0.9602 - relation_0_relation_0F1Macro: 0.4167 - source_0_acc: 0.7792 - source_0_source_0F1Macro: 0.1752 - target_0_acc: 0.7987 - target_0_target_0F1Macro: 0.2437 - val_loss: 2.7756 - val_relation_0_loss: 0.1285 - val_source_0_loss: 0.5020 - val_target_0_loss: 0.4814 - val_relation_0_acc: 0.9381 - val_relation_0_relation_0F1Macro: 0.3624 - val_source_0_acc: 0.7846 - val_source_0_source_0F1Macro: 0.1759 - val_target_0_acc: 0.7957 - val_target_0_target_0F1Macro: 0.2298 - lr: 0.0030\n",
      "\tNEW LR: 0.002982107355864811\n",
      "Epoch 7/70\n",
      "1948/1948 [==============================] - 423s 217ms/step - loss: 2.6488 - relation_0_loss: 0.1209 - source_0_loss: 0.5309 - target_0_loss: 0.4468 - relation_0_acc: 0.9601 - relation_0_relation_0F1Macro: 0.4169 - source_0_acc: 0.7792 - source_0_source_0F1Macro: 0.1752 - target_0_acc: 0.8043 - target_0_target_0F1Macro: 0.2497 - val_loss: 3.0298 - val_relation_0_loss: 0.1509 - val_source_0_loss: 0.5062 - val_target_0_loss: 0.5301 - val_relation_0_acc: 0.9373 - val_relation_0_relation_0F1Macro: 0.3547 - val_source_0_acc: 0.7846 - val_source_0_source_0F1Macro: 0.1759 - val_target_0_acc: 0.7380 - val_target_0_target_0F1Macro: 0.2319 - lr: 0.0030\n",
      "\tNEW LR: 0.00297914597815293\n",
      "Epoch 8/70\n",
      "1948/1948 [==============================] - 421s 216ms/step - loss: 2.6713 - relation_0_loss: 0.1231 - source_0_loss: 0.5303 - target_0_loss: 0.4600 - relation_0_acc: 0.9601 - relation_0_relation_0F1Macro: 0.4173 - source_0_acc: 0.7792 - source_0_source_0F1Macro: 0.1752 - target_0_acc: 0.7993 - target_0_target_0F1Macro: 0.2393 - val_loss: 2.8739 - val_relation_0_loss: 0.1422 - val_source_0_loss: 0.5176 - val_target_0_loss: 0.4925 - val_relation_0_acc: 0.9353 - val_relation_0_relation_0F1Macro: 0.3555 - val_source_0_acc: 0.7846 - val_source_0_source_0F1Macro: 0.1759 - val_target_0_acc: 0.7900 - val_target_0_target_0F1Macro: 0.2157 - lr: 0.0030\n",
      "\tNEW LR: 0.002976190476190476\n",
      "Epoch 9/70\n",
      "1948/1948 [==============================] - 428s 220ms/step - loss: 2.5801 - relation_0_loss: 0.1185 - source_0_loss: 0.5303 - target_0_loss: 0.4489 - relation_0_acc: 0.9616 - relation_0_relation_0F1Macro: 0.4201 - source_0_acc: 0.7792 - source_0_source_0F1Macro: 0.1752 - target_0_acc: 0.8031 - target_0_target_0F1Macro: 0.2474 - val_loss: 2.8669 - val_relation_0_loss: 0.1394 - val_source_0_loss: 0.5088 - val_target_0_loss: 0.5051 - val_relation_0_acc: 0.9370 - val_relation_0_relation_0F1Macro: 0.3580 - val_source_0_acc: 0.7846 - val_source_0_source_0F1Macro: 0.1759 - val_target_0_acc: 0.7841 - val_target_0_target_0F1Macro: 0.2076 - lr: 0.0030\n",
      "\tNEW LR: 0.0029732408325074335\n",
      "Epoch 10/70\n",
      "1948/1948 [==============================] - 421s 216ms/step - loss: 2.6287 - relation_0_loss: 0.1194 - source_0_loss: 0.5300 - target_0_loss: 0.4562 - relation_0_acc: 0.9600 - relation_0_relation_0F1Macro: 0.4167 - source_0_acc: 0.7792 - source_0_source_0F1Macro: 0.1752 - target_0_acc: 0.7997 - target_0_target_0F1Macro: 0.2384 - val_loss: 2.7776 - val_relation_0_loss: 0.1341 - val_source_0_loss: 0.5104 - val_target_0_loss: 0.4916 - val_relation_0_acc: 0.9384 - val_relation_0_relation_0F1Macro: 0.3629 - val_source_0_acc: 0.7846 - val_source_0_source_0F1Macro: 0.1759 - val_target_0_acc: 0.7604 - val_target_0_target_0F1Macro: 0.2276 - lr: 0.0030\n",
      "\tNEW LR: 0.0029702970297029703\n",
      "Epoch 11/70\n",
      "1948/1948 [==============================] - 428s 220ms/step - loss: 2.6324 - relation_0_loss: 0.1193 - source_0_loss: 0.5297 - target_0_loss: 0.4515 - relation_0_acc: 0.9600 - relation_0_relation_0F1Macro: 0.4169 - source_0_acc: 0.7792 - source_0_source_0F1Macro: 0.1752 - target_0_acc: 0.7991 - target_0_target_0F1Macro: 0.2443 - val_loss: 3.0278 - val_relation_0_loss: 0.1489 - val_source_0_loss: 0.5052 - val_target_0_loss: 0.5069 - val_relation_0_acc: 0.9375 - val_relation_0_relation_0F1Macro: 0.3493 - val_source_0_acc: 0.7846 - val_source_0_source_0F1Macro: 0.1759 - val_target_0_acc: 0.7646 - val_target_0_target_0F1Macro: 0.2435 - lr: 0.0030\n",
      "Epoch 11: early stopping\n",
      "INFO:tensorflow:Assets written to: /tf/notebooks/data/link_prediction/persuasive_essays_paragraph/model/model_attention_0/assets\n",
      "\tNEW LR: 0.003\n",
      "\tNEW LR: 0.003\n",
      "Epoch 1/70\n",
      "1948/1948 [==============================] - 444s 217ms/step - loss: 5.6783 - relation_1_loss: 0.2501 - source_1_loss: 0.6122 - target_1_loss: 0.5798 - relation_1_acc: 0.9197 - relation_1_relation_1F1Macro: 0.3660 - source_1_acc: 0.7563 - source_1_source_1F1Macro: 0.1809 - target_1_acc: 0.7666 - target_1_target_1F1Macro: 0.2193 - val_loss: 4.0226 - val_relation_1_loss: 0.1513 - val_source_1_loss: 0.5181 - val_target_1_loss: 0.5614 - val_relation_1_acc: 0.9370 - val_relation_1_relation_1F1Macro: 0.3582 - val_source_1_acc: 0.7867 - val_source_1_source_1F1Macro: 0.1801 - val_target_1_acc: 0.7889 - val_target_1_target_1F1Macro: 0.2156 - lr: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNEW LR: 0.0029970029970029974\n",
      "Epoch 2/70\n",
      "1948/1948 [==============================] - 426s 219ms/step - loss: 3.4683 - relation_1_loss: 0.1397 - source_1_loss: 0.5344 - target_1_loss: 0.4741 - relation_1_acc: 0.9551 - relation_1_relation_1F1Macro: 0.4063 - source_1_acc: 0.7785 - source_1_source_1F1Macro: 0.1754 - target_1_acc: 0.7978 - target_1_target_1F1Macro: 0.2351 - val_loss: 4.1283 - val_relation_1_loss: 0.2261 - val_source_1_loss: 0.5086 - val_target_1_loss: 0.6116 - val_relation_1_acc: 0.9320 - val_relation_1_relation_1F1Macro: 0.3162 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.6505 - val_target_1_target_1F1Macro: 0.2315 - lr: 0.0030\n",
      "\tNEW LR: 0.0029940119760479044\n",
      "Epoch 3/70\n",
      "1948/1948 [==============================] - 421s 216ms/step - loss: 2.8734 - relation_1_loss: 0.1294 - source_1_loss: 0.5326 - target_1_loss: 0.4597 - relation_1_acc: 0.9585 - relation_1_relation_1F1Macro: 0.4128 - source_1_acc: 0.7790 - source_1_source_1F1Macro: 0.1753 - target_1_acc: 0.7979 - target_1_target_1F1Macro: 0.2385 - val_loss: 3.0779 - val_relation_1_loss: 0.1452 - val_source_1_loss: 0.5079 - val_target_1_loss: 0.5579 - val_relation_1_acc: 0.9331 - val_relation_1_relation_1F1Macro: 0.3493 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7793 - val_target_1_target_1F1Macro: 0.1968 - lr: 0.0030\n",
      "\tNEW LR: 0.0029910269192422734\n",
      "Epoch 4/70\n",
      "1948/1948 [==============================] - 422s 217ms/step - loss: 2.7580 - relation_1_loss: 0.1259 - source_1_loss: 0.5320 - target_1_loss: 0.4567 - relation_1_acc: 0.9586 - relation_1_relation_1F1Macro: 0.4133 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.7977 - target_1_target_1F1Macro: 0.2429 - val_loss: 3.0351 - val_relation_1_loss: 0.1505 - val_source_1_loss: 0.5178 - val_target_1_loss: 0.4928 - val_relation_1_acc: 0.9351 - val_relation_1_relation_1F1Macro: 0.3550 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7887 - val_target_1_target_1F1Macro: 0.2085 - lr: 0.0030\n",
      "\tNEW LR: 0.00298804780876494\n",
      "Epoch 5/70\n",
      "1948/1948 [==============================] - 423s 217ms/step - loss: 2.6957 - relation_1_loss: 0.1254 - source_1_loss: 0.5320 - target_1_loss: 0.4612 - relation_1_acc: 0.9582 - relation_1_relation_1F1Macro: 0.4144 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.7979 - target_1_target_1F1Macro: 0.2390 - val_loss: 2.9443 - val_relation_1_loss: 0.1532 - val_source_1_loss: 0.5132 - val_target_1_loss: 0.4939 - val_relation_1_acc: 0.9353 - val_relation_1_relation_1F1Macro: 0.3514 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7898 - val_target_1_target_1F1Macro: 0.2256 - lr: 0.0030\n",
      "\tNEW LR: 0.002985074626865672\n",
      "Epoch 6/70\n",
      "1948/1948 [==============================] - 424s 218ms/step - loss: 2.6319 - relation_1_loss: 0.1228 - source_1_loss: 0.5317 - target_1_loss: 0.4607 - relation_1_acc: 0.9589 - relation_1_relation_1F1Macro: 0.4140 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.7974 - target_1_target_1F1Macro: 0.2384 - val_loss: 3.0773 - val_relation_1_loss: 0.1451 - val_source_1_loss: 0.5224 - val_target_1_loss: 0.6945 - val_relation_1_acc: 0.9370 - val_relation_1_relation_1F1Macro: 0.3513 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.5603 - val_target_1_target_1F1Macro: 0.2160 - lr: 0.0030\n",
      "\tNEW LR: 0.002982107355864811\n",
      "Epoch 7/70\n",
      "1948/1948 [==============================] - 422s 217ms/step - loss: 2.6502 - relation_1_loss: 0.1236 - source_1_loss: 0.5313 - target_1_loss: 0.4575 - relation_1_acc: 0.9584 - relation_1_relation_1F1Macro: 0.4133 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.7970 - target_1_target_1F1Macro: 0.2388 - val_loss: 3.2022 - val_relation_1_loss: 0.1583 - val_source_1_loss: 0.5132 - val_target_1_loss: 0.6244 - val_relation_1_acc: 0.9353 - val_relation_1_relation_1F1Macro: 0.3406 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.5748 - val_target_1_target_1F1Macro: 0.2191 - lr: 0.0030\n",
      "\tNEW LR: 0.00297914597815293\n",
      "Epoch 8/70\n",
      "1948/1948 [==============================] - 423s 217ms/step - loss: 2.6227 - relation_1_loss: 0.1205 - source_1_loss: 0.5313 - target_1_loss: 0.4498 - relation_1_acc: 0.9608 - relation_1_relation_1F1Macro: 0.4181 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8022 - target_1_target_1F1Macro: 0.2488 - val_loss: 2.9711 - val_relation_1_loss: 0.1551 - val_source_1_loss: 0.5173 - val_target_1_loss: 0.5174 - val_relation_1_acc: 0.9353 - val_relation_1_relation_1F1Macro: 0.3530 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7380 - val_target_1_target_1F1Macro: 0.2323 - lr: 0.0030\n",
      "\tNEW LR: 0.002976190476190476\n",
      "Epoch 9/70\n",
      "1948/1948 [==============================] - 421s 216ms/step - loss: 2.6002 - relation_1_loss: 0.1236 - source_1_loss: 0.5313 - target_1_loss: 0.4562 - relation_1_acc: 0.9592 - relation_1_relation_1F1Macro: 0.4155 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.7997 - target_1_target_1F1Macro: 0.2432 - val_loss: 2.9140 - val_relation_1_loss: 0.1475 - val_source_1_loss: 0.5191 - val_target_1_loss: 0.5648 - val_relation_1_acc: 0.9377 - val_relation_1_relation_1F1Macro: 0.3607 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7920 - val_target_1_target_1F1Macro: 0.2067 - lr: 0.0030\n",
      "\tNEW LR: 0.0029732408325074335\n",
      "Epoch 10/70\n",
      "1948/1948 [==============================] - 424s 218ms/step - loss: 2.6564 - relation_1_loss: 0.1209 - source_1_loss: 0.5304 - target_1_loss: 0.4631 - relation_1_acc: 0.9595 - relation_1_relation_1F1Macro: 0.4159 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.7990 - target_1_target_1F1Macro: 0.2407 - val_loss: 3.0878 - val_relation_1_loss: 0.1556 - val_source_1_loss: 0.5214 - val_target_1_loss: 0.5391 - val_relation_1_acc: 0.9318 - val_relation_1_relation_1F1Macro: 0.3274 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7367 - val_target_1_target_1F1Macro: 0.2454 - lr: 0.0030\n",
      "\tNEW LR: 0.0029702970297029703\n",
      "Epoch 11/70\n",
      "1948/1948 [==============================] - 424s 218ms/step - loss: 2.5637 - relation_1_loss: 0.1213 - source_1_loss: 0.5301 - target_1_loss: 0.4501 - relation_1_acc: 0.9589 - relation_1_relation_1F1Macro: 0.4148 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8032 - target_1_target_1F1Macro: 0.2487 - val_loss: 3.1079 - val_relation_1_loss: 0.1711 - val_source_1_loss: 0.5126 - val_target_1_loss: 0.5073 - val_relation_1_acc: 0.9357 - val_relation_1_relation_1F1Macro: 0.3525 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7832 - val_target_1_target_1F1Macro: 0.2321 - lr: 0.0030\n",
      "\tNEW LR: 0.0029673590504451044\n",
      "Epoch 12/70\n",
      "1948/1948 [==============================] - 425s 218ms/step - loss: 2.5502 - relation_1_loss: 0.1175 - source_1_loss: 0.5299 - target_1_loss: 0.4515 - relation_1_acc: 0.9603 - relation_1_relation_1F1Macro: 0.4171 - source_1_acc: 0.7793 - source_1_source_1F1Macro: 0.1753 - target_1_acc: 0.8048 - target_1_target_1F1Macro: 0.2526 - val_loss: 2.9119 - val_relation_1_loss: 0.1499 - val_source_1_loss: 0.5227 - val_target_1_loss: 0.4816 - val_relation_1_acc: 0.9388 - val_relation_1_relation_1F1Macro: 0.3602 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7905 - val_target_1_target_1F1Macro: 0.2270 - lr: 0.0030\n",
      "\tNEW LR: 0.002964426877470356\n",
      "Epoch 13/70\n",
      "1948/1948 [==============================] - 388s 199ms/step - loss: 2.5412 - relation_1_loss: 0.1170 - source_1_loss: 0.5296 - target_1_loss: 0.4494 - relation_1_acc: 0.9609 - relation_1_relation_1F1Macro: 0.4189 - source_1_acc: 0.7793 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8010 - target_1_target_1F1Macro: 0.2466 - val_loss: 3.0502 - val_relation_1_loss: 0.1476 - val_source_1_loss: 0.5165 - val_target_1_loss: 0.5228 - val_relation_1_acc: 0.9373 - val_relation_1_relation_1F1Macro: 0.3529 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7867 - val_target_1_target_1F1Macro: 0.2352 - lr: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNEW LR: 0.002961500493583416\n",
      "Epoch 14/70\n",
      "1948/1948 [==============================] - 388s 199ms/step - loss: 2.5376 - relation_1_loss: 0.1154 - source_1_loss: 0.5298 - target_1_loss: 0.4509 - relation_1_acc: 0.9606 - relation_1_relation_1F1Macro: 0.4184 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8015 - target_1_target_1F1Macro: 0.2461 - val_loss: 2.9639 - val_relation_1_loss: 0.1486 - val_source_1_loss: 0.5209 - val_target_1_loss: 0.5032 - val_relation_1_acc: 0.9377 - val_relation_1_relation_1F1Macro: 0.3566 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7541 - val_target_1_target_1F1Macro: 0.2427 - lr: 0.0030\n",
      "\tNEW LR: 0.0029585798816568047\n",
      "Epoch 15/70\n",
      "1948/1948 [==============================] - 388s 199ms/step - loss: 2.5569 - relation_1_loss: 0.1151 - source_1_loss: 0.5293 - target_1_loss: 0.4473 - relation_1_acc: 0.9605 - relation_1_relation_1F1Macro: 0.4179 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8023 - target_1_target_1F1Macro: 0.2491 - val_loss: 2.9143 - val_relation_1_loss: 0.1448 - val_source_1_loss: 0.5144 - val_target_1_loss: 0.4952 - val_relation_1_acc: 0.9351 - val_relation_1_relation_1F1Macro: 0.3548 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7652 - val_target_1_target_1F1Macro: 0.2245 - lr: 0.0030\n",
      "\tNEW LR: 0.002955665024630542\n",
      "Epoch 16/70\n",
      "1948/1948 [==============================] - 409s 210ms/step - loss: 2.5451 - relation_1_loss: 0.1124 - source_1_loss: 0.5292 - target_1_loss: 0.4519 - relation_1_acc: 0.9617 - relation_1_relation_1F1Macro: 0.4206 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8017 - target_1_target_1F1Macro: 0.2463 - val_loss: 3.0420 - val_relation_1_loss: 0.1539 - val_source_1_loss: 0.5455 - val_target_1_loss: 0.5674 - val_relation_1_acc: 0.9370 - val_relation_1_relation_1F1Macro: 0.3537 - val_source_1_acc: 0.7859 - val_source_1_source_1F1Macro: 0.1784 - val_target_1_acc: 0.7804 - val_target_1_target_1F1Macro: 0.2135 - lr: 0.0030\n",
      "\tNEW LR: 0.002952755905511811\n",
      "Epoch 17/70\n",
      "1948/1948 [==============================] - 426s 219ms/step - loss: 2.5117 - relation_1_loss: 0.1157 - source_1_loss: 0.5282 - target_1_loss: 0.4501 - relation_1_acc: 0.9605 - relation_1_relation_1F1Macro: 0.4189 - source_1_acc: 0.7793 - source_1_source_1F1Macro: 0.1753 - target_1_acc: 0.7993 - target_1_target_1F1Macro: 0.2459 - val_loss: 2.8146 - val_relation_1_loss: 0.1397 - val_source_1_loss: 0.5130 - val_target_1_loss: 0.5072 - val_relation_1_acc: 0.9359 - val_relation_1_relation_1F1Macro: 0.3570 - val_source_1_acc: 0.7892 - val_source_1_source_1F1Macro: 0.1887 - val_target_1_acc: 0.7874 - val_target_1_target_1F1Macro: 0.2064 - lr: 0.0030\n",
      "\tNEW LR: 0.0029498525073746317\n",
      "Epoch 18/70\n",
      "1948/1948 [==============================] - 398s 204ms/step - loss: 2.4679 - relation_1_loss: 0.1121 - source_1_loss: 0.5288 - target_1_loss: 0.4494 - relation_1_acc: 0.9608 - relation_1_relation_1F1Macro: 0.4183 - source_1_acc: 0.7793 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8001 - target_1_target_1F1Macro: 0.2456 - val_loss: 2.8177 - val_relation_1_loss: 0.1444 - val_source_1_loss: 0.5089 - val_target_1_loss: 0.5150 - val_relation_1_acc: 0.9346 - val_relation_1_relation_1F1Macro: 0.3539 - val_source_1_acc: 0.7863 - val_source_1_source_1F1Macro: 0.1827 - val_target_1_acc: 0.7547 - val_target_1_target_1F1Macro: 0.2253 - lr: 0.0029\n",
      "\tNEW LR: 0.0029469548133595285\n",
      "Epoch 19/70\n",
      "1948/1948 [==============================] - 393s 202ms/step - loss: 2.4645 - relation_1_loss: 0.1116 - source_1_loss: 0.5288 - target_1_loss: 0.4435 - relation_1_acc: 0.9608 - relation_1_relation_1F1Macro: 0.4186 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8022 - target_1_target_1F1Macro: 0.2503 - val_loss: 2.8642 - val_relation_1_loss: 0.1469 - val_source_1_loss: 0.5062 - val_target_1_loss: 0.4945 - val_relation_1_acc: 0.9359 - val_relation_1_relation_1F1Macro: 0.3556 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7878 - val_target_1_target_1F1Macro: 0.2145 - lr: 0.0029\n",
      "\tNEW LR: 0.0029440628066732095\n",
      "Epoch 20/70\n",
      "1948/1948 [==============================] - 393s 202ms/step - loss: 2.4822 - relation_1_loss: 0.1139 - source_1_loss: 0.5284 - target_1_loss: 0.4460 - relation_1_acc: 0.9608 - relation_1_relation_1F1Macro: 0.4193 - source_1_acc: 0.7793 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.7998 - target_1_target_1F1Macro: 0.2451 - val_loss: 2.7845 - val_relation_1_loss: 0.1374 - val_source_1_loss: 0.5115 - val_target_1_loss: 0.5095 - val_relation_1_acc: 0.9421 - val_relation_1_relation_1F1Macro: 0.3706 - val_source_1_acc: 0.7857 - val_source_1_source_1F1Macro: 0.1780 - val_target_1_acc: 0.7589 - val_target_1_target_1F1Macro: 0.2316 - lr: 0.0029\n",
      "\tNEW LR: 0.0029411764705882353\n",
      "Epoch 21/70\n",
      "1948/1948 [==============================] - 394s 202ms/step - loss: 2.4885 - relation_1_loss: 0.1126 - source_1_loss: 0.5287 - target_1_loss: 0.4509 - relation_1_acc: 0.9610 - relation_1_relation_1F1Macro: 0.4191 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8003 - target_1_target_1F1Macro: 0.2441 - val_loss: 2.8749 - val_relation_1_loss: 0.1459 - val_source_1_loss: 0.5151 - val_target_1_loss: 0.5124 - val_relation_1_acc: 0.9333 - val_relation_1_relation_1F1Macro: 0.3482 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7900 - val_target_1_target_1F1Macro: 0.2297 - lr: 0.0029\n",
      "\tNEW LR: 0.0029382957884427035\n",
      "Epoch 22/70\n",
      "1948/1948 [==============================] - 447s 229ms/step - loss: 2.4614 - relation_1_loss: 0.1125 - source_1_loss: 0.5286 - target_1_loss: 0.4425 - relation_1_acc: 0.9608 - relation_1_relation_1F1Macro: 0.4190 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8034 - target_1_target_1F1Macro: 0.2512 - val_loss: 2.8850 - val_relation_1_loss: 0.1438 - val_source_1_loss: 0.5149 - val_target_1_loss: 0.5055 - val_relation_1_acc: 0.9419 - val_relation_1_relation_1F1Macro: 0.3706 - val_source_1_acc: 0.7846 - val_source_1_source_1F1Macro: 0.1759 - val_target_1_acc: 0.7413 - val_target_1_target_1F1Macro: 0.2486 - lr: 0.0029\n",
      "\tNEW LR: 0.0029354207436399216\n",
      "Epoch 23/70\n",
      "1948/1948 [==============================] - 421s 216ms/step - loss: 2.4965 - relation_1_loss: 0.1130 - source_1_loss: 0.5285 - target_1_loss: 0.4435 - relation_1_acc: 0.9609 - relation_1_relation_1F1Macro: 0.4196 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8011 - target_1_target_1F1Macro: 0.2480 - val_loss: 2.8977 - val_relation_1_loss: 0.1461 - val_source_1_loss: 0.5123 - val_target_1_loss: 0.5227 - val_relation_1_acc: 0.9346 - val_relation_1_relation_1F1Macro: 0.3538 - val_source_1_acc: 0.7843 - val_source_1_source_1F1Macro: 0.1758 - val_target_1_acc: 0.7604 - val_target_1_target_1F1Macro: 0.2443 - lr: 0.0029\n",
      "\tNEW LR: 0.0029325513196480943\n",
      "Epoch 24/70\n",
      "1948/1948 [==============================] - 387s 199ms/step - loss: 2.4518 - relation_1_loss: 0.1123 - source_1_loss: 0.5280 - target_1_loss: 0.4404 - relation_1_acc: 0.9609 - relation_1_relation_1F1Macro: 0.4190 - source_1_acc: 0.7793 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8031 - target_1_target_1F1Macro: 0.2489 - val_loss: 3.0920 - val_relation_1_loss: 0.1599 - val_source_1_loss: 0.5217 - val_target_1_loss: 0.5984 - val_relation_1_acc: 0.9335 - val_relation_1_relation_1F1Macro: 0.3462 - val_source_1_acc: 0.7900 - val_source_1_source_1F1Macro: 0.1975 - val_target_1_acc: 0.7602 - val_target_1_target_1F1Macro: 0.2022 - lr: 0.0029\n",
      "\tNEW LR: 0.0029296875\n",
      "Epoch 25/70\n",
      "1948/1948 [==============================] - 386s 198ms/step - loss: 2.3910 - relation_1_loss: 0.1125 - source_1_loss: 0.5285 - target_1_loss: 0.4410 - relation_1_acc: 0.9609 - relation_1_relation_1F1Macro: 0.4195 - source_1_acc: 0.7792 - source_1_source_1F1Macro: 0.1752 - target_1_acc: 0.8012 - target_1_target_1F1Macro: 0.2482 - val_loss: 2.9765 - val_relation_1_loss: 0.1543 - val_source_1_loss: 0.5183 - val_target_1_loss: 0.6110 - val_relation_1_acc: 0.9351 - val_relation_1_relation_1F1Macro: 0.3522 - val_source_1_acc: 0.7885 - val_source_1_source_1F1Macro: 0.1925 - val_target_1_acc: 0.7878 - val_target_1_target_1F1Macro: 0.2077 - lr: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: early stopping\n",
      "INFO:tensorflow:Assets written to: /tf/notebooks/data/link_prediction/persuasive_essays_paragraph/model/model_attention_1/assets\n",
      "\tNEW LR: 0.003\n",
      "\tNEW LR: 0.003\n",
      "Epoch 1/70\n",
      "1948/1948 [==============================] - 406s 199ms/step - loss: 5.5853 - relation_2_loss: 0.2386 - source_2_loss: 0.6189 - target_2_loss: 0.5698 - relation_2_acc: 0.9242 - relation_2_relation_2F1Macro: 0.3729 - source_2_acc: 0.7572 - source_2_source_2F1Macro: 0.1773 - target_2_acc: 0.7683 - target_2_target_2F1Macro: 0.2208 - val_loss: 3.9185 - val_relation_2_loss: 0.1458 - val_source_2_loss: 0.5124 - val_target_2_loss: 0.5117 - val_relation_2_acc: 0.9331 - val_relation_2_relation_2F1Macro: 0.3477 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7885 - val_target_2_target_2F1Macro: 0.1981 - lr: 0.0030\n",
      "\tNEW LR: 0.0029970029970029974\n",
      "Epoch 2/70\n",
      "1948/1948 [==============================] - 385s 198ms/step - loss: 3.3863 - relation_2_loss: 0.1345 - source_2_loss: 0.5357 - target_2_loss: 0.4732 - relation_2_acc: 0.9564 - relation_2_relation_2F1Macro: 0.4082 - source_2_acc: 0.7791 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.7962 - target_2_target_2F1Macro: 0.2346 - val_loss: 3.3888 - val_relation_2_loss: 0.1563 - val_source_2_loss: 0.5201 - val_target_2_loss: 0.5223 - val_relation_2_acc: 0.9397 - val_relation_2_relation_2F1Macro: 0.3598 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7286 - val_target_2_target_2F1Macro: 0.2363 - lr: 0.0030\n",
      "\tNEW LR: 0.0029940119760479044\n",
      "Epoch 3/70\n",
      "1948/1948 [==============================] - 386s 198ms/step - loss: 2.8996 - relation_2_loss: 0.1297 - source_2_loss: 0.5341 - target_2_loss: 0.4648 - relation_2_acc: 0.9587 - relation_2_relation_2F1Macro: 0.4134 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.7975 - target_2_target_2F1Macro: 0.2387 - val_loss: 3.0074 - val_relation_2_loss: 0.1432 - val_source_2_loss: 0.5267 - val_target_2_loss: 0.5031 - val_relation_2_acc: 0.9300 - val_relation_2_relation_2F1Macro: 0.3388 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7843 - val_target_2_target_2F1Macro: 0.1906 - lr: 0.0030\n",
      "\tNEW LR: 0.0029910269192422734\n",
      "Epoch 4/70\n",
      "1948/1948 [==============================] - 386s 198ms/step - loss: 2.7856 - relation_2_loss: 0.1276 - source_2_loss: 0.5328 - target_2_loss: 0.4637 - relation_2_acc: 0.9584 - relation_2_relation_2F1Macro: 0.4128 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.7975 - target_2_target_2F1Macro: 0.2377 - val_loss: 3.0253 - val_relation_2_loss: 0.1470 - val_source_2_loss: 0.5104 - val_target_2_loss: 0.4945 - val_relation_2_acc: 0.9348 - val_relation_2_relation_2F1Macro: 0.3498 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7815 - val_target_2_target_2F1Macro: 0.2293 - lr: 0.0030\n",
      "\tNEW LR: 0.00298804780876494\n",
      "Epoch 5/70\n",
      "1948/1948 [==============================] - 385s 198ms/step - loss: 2.7915 - relation_2_loss: 0.1259 - source_2_loss: 0.5328 - target_2_loss: 0.4586 - relation_2_acc: 0.9585 - relation_2_relation_2F1Macro: 0.4132 - source_2_acc: 0.7791 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8004 - target_2_target_2F1Macro: 0.2450 - val_loss: 3.1248 - val_relation_2_loss: 0.1507 - val_source_2_loss: 0.5127 - val_target_2_loss: 0.5228 - val_relation_2_acc: 0.9397 - val_relation_2_relation_2F1Macro: 0.3596 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7495 - val_target_2_target_2F1Macro: 0.2471 - lr: 0.0030\n",
      "\tNEW LR: 0.002985074626865672\n",
      "Epoch 6/70\n",
      "1948/1948 [==============================] - 385s 198ms/step - loss: 2.6965 - relation_2_loss: 0.1224 - source_2_loss: 0.5310 - target_2_loss: 0.4584 - relation_2_acc: 0.9594 - relation_2_relation_2F1Macro: 0.4150 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8010 - target_2_target_2F1Macro: 0.2447 - val_loss: 3.0846 - val_relation_2_loss: 0.1573 - val_source_2_loss: 0.5148 - val_target_2_loss: 0.5343 - val_relation_2_acc: 0.9381 - val_relation_2_relation_2F1Macro: 0.3597 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7222 - val_target_2_target_2F1Macro: 0.2421 - lr: 0.0030\n",
      "\tNEW LR: 0.002982107355864811\n",
      "Epoch 7/70\n",
      "1948/1948 [==============================] - 385s 197ms/step - loss: 2.6067 - relation_2_loss: 0.1170 - source_2_loss: 0.5304 - target_2_loss: 0.4520 - relation_2_acc: 0.9605 - relation_2_relation_2F1Macro: 0.4173 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8009 - target_2_target_2F1Macro: 0.2465 - val_loss: 2.9277 - val_relation_2_loss: 0.1432 - val_source_2_loss: 0.5191 - val_target_2_loss: 0.4880 - val_relation_2_acc: 0.9386 - val_relation_2_relation_2F1Macro: 0.3635 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7905 - val_target_2_target_2F1Macro: 0.2256 - lr: 0.0030\n",
      "\tNEW LR: 0.00297914597815293\n",
      "Epoch 8/70\n",
      "1948/1948 [==============================] - 385s 198ms/step - loss: 2.6076 - relation_2_loss: 0.1189 - source_2_loss: 0.5303 - target_2_loss: 0.4548 - relation_2_acc: 0.9606 - relation_2_relation_2F1Macro: 0.4187 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8005 - target_2_target_2F1Macro: 0.2469 - val_loss: 3.1100 - val_relation_2_loss: 0.1568 - val_source_2_loss: 0.5214 - val_target_2_loss: 0.5467 - val_relation_2_acc: 0.9392 - val_relation_2_relation_2F1Macro: 0.3619 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7337 - val_target_2_target_2F1Macro: 0.2377 - lr: 0.0030\n",
      "\tNEW LR: 0.002976190476190476\n",
      "Epoch 9/70\n",
      "1948/1948 [==============================] - 386s 198ms/step - loss: 2.6104 - relation_2_loss: 0.1162 - source_2_loss: 0.5304 - target_2_loss: 0.4481 - relation_2_acc: 0.9602 - relation_2_relation_2F1Macro: 0.4171 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8029 - target_2_target_2F1Macro: 0.2498 - val_loss: 3.0040 - val_relation_2_loss: 0.1528 - val_source_2_loss: 0.5134 - val_target_2_loss: 0.4956 - val_relation_2_acc: 0.9364 - val_relation_2_relation_2F1Macro: 0.3559 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7729 - val_target_2_target_2F1Macro: 0.2260 - lr: 0.0030\n",
      "\tNEW LR: 0.0029732408325074335\n",
      "Epoch 10/70\n",
      "1948/1948 [==============================] - 385s 197ms/step - loss: 2.5631 - relation_2_loss: 0.1154 - source_2_loss: 0.5304 - target_2_loss: 0.4525 - relation_2_acc: 0.9608 - relation_2_relation_2F1Macro: 0.4185 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8002 - target_2_target_2F1Macro: 0.2460 - val_loss: 2.8939 - val_relation_2_loss: 0.1450 - val_source_2_loss: 0.5209 - val_target_2_loss: 0.4884 - val_relation_2_acc: 0.9375 - val_relation_2_relation_2F1Macro: 0.3545 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7876 - val_target_2_target_2F1Macro: 0.2347 - lr: 0.0030\n",
      "\tNEW LR: 0.0029702970297029703\n",
      "Epoch 11/70\n",
      "1948/1948 [==============================] - 385s 198ms/step - loss: 2.5671 - relation_2_loss: 0.1175 - source_2_loss: 0.5307 - target_2_loss: 0.4488 - relation_2_acc: 0.9597 - relation_2_relation_2F1Macro: 0.4167 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8041 - target_2_target_2F1Macro: 0.2506 - val_loss: 3.2007 - val_relation_2_loss: 0.1652 - val_source_2_loss: 0.5170 - val_target_2_loss: 0.6097 - val_relation_2_acc: 0.9309 - val_relation_2_relation_2F1Macro: 0.3136 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.6766 - val_target_2_target_2F1Macro: 0.2406 - lr: 0.0030\n",
      "\tNEW LR: 0.0029673590504451044\n",
      "Epoch 12/70\n",
      "1948/1948 [==============================] - 385s 197ms/step - loss: 2.5012 - relation_2_loss: 0.1148 - source_2_loss: 0.5302 - target_2_loss: 0.4475 - relation_2_acc: 0.9608 - relation_2_relation_2F1Macro: 0.4189 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8029 - target_2_target_2F1Macro: 0.2484 - val_loss: 2.8586 - val_relation_2_loss: 0.1481 - val_source_2_loss: 0.5137 - val_target_2_loss: 0.4622 - val_relation_2_acc: 0.9397 - val_relation_2_relation_2F1Macro: 0.3632 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7909 - val_target_2_target_2F1Macro: 0.2352 - lr: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tNEW LR: 0.002964426877470356\n",
      "Epoch 13/70\n",
      "1948/1948 [==============================] - 385s 198ms/step - loss: 2.5678 - relation_2_loss: 0.1140 - source_2_loss: 0.5298 - target_2_loss: 0.4469 - relation_2_acc: 0.9607 - relation_2_relation_2F1Macro: 0.4188 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8020 - target_2_target_2F1Macro: 0.2477 - val_loss: 2.9508 - val_relation_2_loss: 0.1449 - val_source_2_loss: 0.5147 - val_target_2_loss: 0.5196 - val_relation_2_acc: 0.9368 - val_relation_2_relation_2F1Macro: 0.3571 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7387 - val_target_2_target_2F1Macro: 0.2435 - lr: 0.0030\n",
      "\tNEW LR: 0.002961500493583416\n",
      "Epoch 14/70\n",
      "1948/1948 [==============================] - 386s 198ms/step - loss: 2.5629 - relation_2_loss: 0.1141 - source_2_loss: 0.5296 - target_2_loss: 0.4531 - relation_2_acc: 0.9604 - relation_2_relation_2F1Macro: 0.4184 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8016 - target_2_target_2F1Macro: 0.2429 - val_loss: 2.7844 - val_relation_2_loss: 0.1404 - val_source_2_loss: 0.5166 - val_target_2_loss: 0.4700 - val_relation_2_acc: 0.9410 - val_relation_2_relation_2F1Macro: 0.3687 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7946 - val_target_2_target_2F1Macro: 0.2307 - lr: 0.0030\n",
      "\tNEW LR: 0.0029585798816568047\n",
      "Epoch 15/70\n",
      "1948/1948 [==============================] - 385s 198ms/step - loss: 2.4579 - relation_2_loss: 0.1120 - source_2_loss: 0.5293 - target_2_loss: 0.4435 - relation_2_acc: 0.9599 - relation_2_relation_2F1Macro: 0.4168 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8056 - target_2_target_2F1Macro: 0.2504 - val_loss: 2.7502 - val_relation_2_loss: 0.1404 - val_source_2_loss: 0.5111 - val_target_2_loss: 0.5002 - val_relation_2_acc: 0.9368 - val_relation_2_relation_2F1Macro: 0.3592 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7955 - val_target_2_target_2F1Macro: 0.2191 - lr: 0.0030\n",
      "\tNEW LR: 0.002955665024630542\n",
      "Epoch 16/70\n",
      "1948/1948 [==============================] - 391s 201ms/step - loss: 2.4654 - relation_2_loss: 0.1129 - source_2_loss: 0.5293 - target_2_loss: 0.4446 - relation_2_acc: 0.9616 - relation_2_relation_2F1Macro: 0.4211 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8034 - target_2_target_2F1Macro: 0.2490 - val_loss: 2.9476 - val_relation_2_loss: 0.1481 - val_source_2_loss: 0.5160 - val_target_2_loss: 0.4868 - val_relation_2_acc: 0.9370 - val_relation_2_relation_2F1Macro: 0.3571 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7894 - val_target_2_target_2F1Macro: 0.2198 - lr: 0.0030\n",
      "\tNEW LR: 0.002952755905511811\n",
      "Epoch 17/70\n",
      "1948/1948 [==============================] - 424s 217ms/step - loss: 2.5310 - relation_2_loss: 0.1143 - source_2_loss: 0.5291 - target_2_loss: 0.4437 - relation_2_acc: 0.9599 - relation_2_relation_2F1Macro: 0.4170 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8035 - target_2_target_2F1Macro: 0.2481 - val_loss: 2.8401 - val_relation_2_loss: 0.1435 - val_source_2_loss: 0.5222 - val_target_2_loss: 0.4816 - val_relation_2_acc: 0.9357 - val_relation_2_relation_2F1Macro: 0.3528 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7953 - val_target_2_target_2F1Macro: 0.2273 - lr: 0.0030\n",
      "\tNEW LR: 0.0029498525073746317\n",
      "Epoch 18/70\n",
      "1948/1948 [==============================] - 418s 215ms/step - loss: 2.5007 - relation_2_loss: 0.1106 - source_2_loss: 0.5293 - target_2_loss: 0.4439 - relation_2_acc: 0.9609 - relation_2_relation_2F1Macro: 0.4192 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8021 - target_2_target_2F1Macro: 0.2486 - val_loss: 2.7877 - val_relation_2_loss: 0.1397 - val_source_2_loss: 0.5111 - val_target_2_loss: 0.4774 - val_relation_2_acc: 0.9414 - val_relation_2_relation_2F1Macro: 0.3673 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7911 - val_target_2_target_2F1Macro: 0.2315 - lr: 0.0029\n",
      "\tNEW LR: 0.0029469548133595285\n",
      "Epoch 19/70\n",
      "1948/1948 [==============================] - 421s 216ms/step - loss: 2.4592 - relation_2_loss: 0.1120 - source_2_loss: 0.5295 - target_2_loss: 0.4411 - relation_2_acc: 0.9608 - relation_2_relation_2F1Macro: 0.4191 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8027 - target_2_target_2F1Macro: 0.2509 - val_loss: 3.0003 - val_relation_2_loss: 0.1548 - val_source_2_loss: 0.5123 - val_target_2_loss: 0.5581 - val_relation_2_acc: 0.9399 - val_relation_2_relation_2F1Macro: 0.3570 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.6994 - val_target_2_target_2F1Macro: 0.2456 - lr: 0.0029\n",
      "\tNEW LR: 0.0029440628066732095\n",
      "Epoch 20/70\n",
      "1948/1948 [==============================] - 419s 215ms/step - loss: 2.4422 - relation_2_loss: 0.1116 - source_2_loss: 0.5287 - target_2_loss: 0.4444 - relation_2_acc: 0.9611 - relation_2_relation_2F1Macro: 0.4197 - source_2_acc: 0.7792 - source_2_source_2F1Macro: 0.1752 - target_2_acc: 0.8040 - target_2_target_2F1Macro: 0.2524 - val_loss: 2.8160 - val_relation_2_loss: 0.1458 - val_source_2_loss: 0.5191 - val_target_2_loss: 0.5057 - val_relation_2_acc: 0.9346 - val_relation_2_relation_2F1Macro: 0.3539 - val_source_2_acc: 0.7846 - val_source_2_source_2F1Macro: 0.1759 - val_target_2_acc: 0.7885 - val_target_2_target_2F1Macro: 0.2052 - lr: 0.0029\n",
      "Epoch 20: early stopping\n",
      "INFO:tensorflow:Assets written to: /tf/notebooks/data/link_prediction/persuasive_essays_paragraph/model/model_attention_2/assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def train_and_save_model(params: dict):\n",
    "    model_name = params['model_name']\n",
    "    batch_size = params['batch_size']\n",
    "    if params['in_production']:\n",
    "        epochs = params['epochs']\n",
    "        train_ds = params['train_ds'].batch(batch_size)\n",
    "        val_ds = params['dev_ds'].batch(batch_size)\n",
    "        models = params[model_name]\n",
    "    else:\n",
    "        epochs = 2 \n",
    "        train_ds = params['train_ds'].batch(batch_size).take(30)\n",
    "        val_ds = params['dev_ds'].batch(batch_size).take(10)\n",
    "        models = params[model_name][:2]\n",
    "    loss_weights = params['loss_weights']\n",
    "    lr_alpha = params['lr_alpha']\n",
    "    lr_kappa = params['lr_kappa']\n",
    "    relation_amount = len(params['relation_tag_vectorizer'].get_vocabulary())\n",
    "    proposition_amount = len(params['proposition_tag_vectorizer'].get_vocabulary())\n",
    "    global_metrics = params['metrics']\n",
    "    beta_1 = params['beta_1']\n",
    "    beta_2 = params['beta_2']\n",
    "    min_delta = params['min_delta']\n",
    "    patience = params['patience']\n",
    "  \n",
    "    def single_train(index, model):\n",
    "        # Optimizer\n",
    "        lr_function = create_lr_annealing_function(initial_lr=lr_alpha, k=lr_kappa)\n",
    "        lr_scheduler = keras.callbacks.LearningRateScheduler(lr_function)\n",
    "        optimizer = tf.optimizers.Adam(\n",
    "            learning_rate=lr_function(0),\n",
    "            beta_1=beta_1,\n",
    "            beta_2=beta_2,\n",
    "        )\n",
    "\n",
    "        # EarlyStopping\n",
    "        early_stopping = keras.callbacks.EarlyStopping(\n",
    "            min_delta=min_delta,\n",
    "            patience=patience,\n",
    "            verbose=1,\n",
    "        )\n",
    "\n",
    "        # Metrics\n",
    "        metrics = {\n",
    "            f'relation_{index}': global_metrics.copy(),\n",
    "            f'source_{index}': global_metrics.copy(),\n",
    "            f'target_{index}': global_metrics.copy(),\n",
    "        }\n",
    "        for name, num_classes in [\n",
    "                (f'relation_{index}', relation_amount), \n",
    "                (f'source_{index}', proposition_amount), \n",
    "                (f'target_{index}', proposition_amount)\n",
    "            ]:\n",
    "\n",
    "    #         f1 = tfa.metrics.F1Score( # Same as macro\n",
    "    #             num_classes=num_classes,\n",
    "    #             average=None,\n",
    "    #             name=f'{name}F1',\n",
    "    #         )\n",
    "            f1_macro = tfa.metrics.F1Score(\n",
    "                num_classes=num_classes,\n",
    "                average='macro',\n",
    "                name=f'{name}F1Macro',\n",
    "            )\n",
    "    #         f1_micro = tfa.metrics.F1Score( # Accuracy\n",
    "    #             num_classes=num_classes,\n",
    "    #             average='micro',\n",
    "    #             name=f'{name}F1Micro',\n",
    "    #         )\n",
    "            metrics[name].extend([\n",
    "    #             f1,\n",
    "                f1_macro,\n",
    "    #             f1_micro,\n",
    "            ])\n",
    "        \n",
    "        current_loss_weights = {f'{name}_{index}': value for name, value in loss_weights.items()}\n",
    "        \n",
    "        model.compile(\n",
    "            loss='categorical_crossentropy', # Apply this loss function to all outputs\n",
    "            loss_weights=current_loss_weights, # Weights for the sum of the loss functions\n",
    "            optimizer=optimizer,\n",
    "            metrics=metrics\n",
    "        )\n",
    "\n",
    "        # Train\n",
    "        history = model.fit(train_ds,\n",
    "                      batch_size=batch_size, \n",
    "                      epochs=epochs, \n",
    "                      validation_data=val_ds,\n",
    "                      callbacks=[\n",
    "                          lr_scheduler,\n",
    "                          early_stopping,\n",
    "                      ])\n",
    "\n",
    "        model.save(str(Path(params[\"model_path\"], f\"{model_name}_{index}\")), save_format='tf')\n",
    "\n",
    "        history = history.history\n",
    "        for key in history:\n",
    "            values = np.array(history[key]).tolist()\n",
    "            history[key] = values\n",
    "        params[f'history_{index}'] = history\n",
    "        with Path(params['export_path'], f\"{model_name}_{index}_history.json\").open('w') as f:\n",
    "            json.dump(history, f)\n",
    "    \n",
    "    for i, model in enumerate(models):\n",
    "        single_train(i, model)\n",
    "\n",
    "train_and_save_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Model\n",
    "def load_saved_model(params: dict):\n",
    "    ensemble_amount = params['ensemble_amount']\n",
    "    \n",
    "    model_name = params[\"model_name\"]\n",
    "    models = []\n",
    "    for i in range(ensemble_amount):        \n",
    "        model_path = Path(params[\"model_path\"], f\"{model_name}_{i}\")\n",
    "        if model_path.exists():\n",
    "            history_path = Path(params['export_path'], f\"{model_name}_{i}_history.json\")\n",
    "            history = json.load(history_path.open())\n",
    "            params[f'history_{i}'] = history\n",
    "            model = keras.models.load_model(str(model_path))\n",
    "            models.append(model)\n",
    "        else:\n",
    "            print(f\"Model in {model_path} doesn't exist\")\n",
    "    params[model_name] = models\n",
    "\n",
    "    \n",
    "load_saved_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0\n",
      "162/162 [==============================] - 18s 51ms/step - loss: 6.1294 - relation_0_loss: 0.4489 - source_0_loss: 0.5649 - target_0_loss: 0.5489 - relation_0_acc: 0.7982 - relation_0_relation_0F1Macro: 0.3611 - source_0_acc: 0.7086 - source_0_source_0F1Macro: 0.1659 - target_0_acc: 0.7349 - target_0_target_0F1Macro: 0.2768\n",
      "Model 1\n",
      "162/162 [==============================] - 13s 50ms/step - loss: 5.8009 - relation_1_loss: 0.4302 - source_1_loss: 0.5529 - target_1_loss: 0.6417 - relation_1_acc: 0.8180 - relation_1_relation_1F1Macro: 0.3827 - source_1_acc: 0.7451 - source_1_source_1F1Macro: 0.2263 - target_1_acc: 0.7417 - target_1_target_1F1Macro: 0.2326\n",
      "Model 2\n",
      "162/162 [==============================] - 14s 67ms/step - loss: 5.6603 - relation_2_loss: 0.4210 - source_2_loss: 0.5703 - target_2_loss: 0.5467 - relation_2_acc: 0.8226 - relation_2_relation_2F1Macro: 0.3874 - source_2_acc: 0.7086 - source_2_source_2F1Macro: 0.1659 - target_2_acc: 0.7509 - target_2_target_2F1Macro: 0.2504\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model\n",
    "def evaluate_model(params: dict):\n",
    "    models = params[params['model_name']]\n",
    "    batch_size = params['batch_size']\n",
    "    test_ds = params['test_ds'].batch(batch_size)\n",
    "    for i, model in enumerate(models):\n",
    "        print(\"Model\", i)\n",
    "        results = model.evaluate(test_ds, batch_size=batch_size)\n",
    "\n",
    "\n",
    "evaluate_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def plot_history(params: dict):\n",
    "    history = params['history_0']\n",
    "    relation_labels = [x if x else \"None\" for x in params['relation_tag_vectorizer'].get_vocabulary()]\n",
    "    proposition_labels = [x if x else \"None\" for x in params['proposition_tag_vectorizer'].get_vocabulary()]\n",
    "        \n",
    "    def plot_list(values, label):\n",
    "        X = [i for i in range(len(values))]\n",
    "        plt.plot(X, values, label=label)\n",
    "    \n",
    "    def show_plot(title, x_label=\"Epoch\", y_label=\"\"):\n",
    "        plt.title(title)\n",
    "        plt.xlabel(x_label)\n",
    "        plt.ylabel(y_label)\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "        \n",
    "    def plot_categorical_list(values, labels, bar_plot=False):\n",
    "        values = np.array(values).T\n",
    "        plt.xticks(rotation = 45)\n",
    "        if bar_plot:\n",
    "            plt.bar(labels, [x[-1] for x in values])\n",
    "        else:\n",
    "            for label, label_values in zip(labels, values):\n",
    "                X = [i for i in range(len(label_values))]\n",
    "                plt.plot(X, label_values, label=label)\n",
    "    \n",
    "    for key, value in history.items():\n",
    "        value = np.array(value)\n",
    "        if len(value.shape) == 1: # List values\n",
    "            plot_list(value, key)\n",
    "            show_plot(key, y_label=\"values\")\n",
    "        else: # Categorical values\n",
    "            labels = relation_labels if 'relation' in key else proposition_labels\n",
    "            plot_categorical_list(value, labels, bar_plot=True)\n",
    "            show_plot(key + \" bar\", x_label='categories', y_label=\"values\")\n",
    "            plot_categorical_list(value, labels, bar_plot=False)\n",
    "            show_plot(key, y_label=\"values\")\n",
    "        \n",
    "plot_history(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('supports', 'Premise', 'Premise'), ('', 'Premise', 'Premise'), ('supports_Inverse', 'Premise', 'Premise')]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "class LinkPredictionModel(keras.Model):\n",
    "    \n",
    "    def __init__(self,\n",
    "                 models,\n",
    "                 sequence_vectorizer, \n",
    "                 proposition_tag_vectorizer, \n",
    "                 relation_tag_vectorizer, \n",
    "                 distance_encoding_bits,\n",
    "                 batch_size=32\n",
    "                ):\n",
    "        super().__init__()\n",
    "        self.models = models\n",
    "        self.sequence_vectorizer = sequence_vectorizer\n",
    "        self.proposition_tag_vectorizer = proposition_tag_vectorizer\n",
    "        self.relation_tag_vectorizer = relation_tag_vectorizer\n",
    "        self.distance_encoding_bits = distance_encoding_bits\n",
    "        self.batch_size = batch_size\n",
    "    \n",
    "    def __decode_outputs(self, outputs):\n",
    "        propositions = self.proposition_tag_vectorizer.get_vocabulary()\n",
    "        relations = self.relation_tag_vectorizer.get_vocabulary()\n",
    "        \n",
    "#         # Flatting results\n",
    "#         results = []\n",
    "#         for models_output in outputs:\n",
    "#             relation = []\n",
    "#             source = []\n",
    "#             target = []\n",
    "#             for i,input_models_output in enumerate(zip(*models_output)):\n",
    "#                 print(input_models_output)\n",
    "#                 if i == 0:\n",
    "#                     current = relation\n",
    "#                 elif i == 1:\n",
    "#                     current = source\n",
    "#                 elif i == 2:\n",
    "#                     current = target\n",
    "#                 current.append(list(input_models_output))\n",
    "                \n",
    "# #                 for relation_output, source_output, target_output in zip(relation_outputs, source_outputs, target_outputs):\n",
    "# #                     result.append((relation_output, source_output, target_output))\n",
    "#             results.append(list(zip(relation, source, target)))\n",
    "        \n",
    "        final_result = []\n",
    "        relation_eye = tf.eye(len(relations))\n",
    "        proposition_eye = tf.eye(len(propositions))\n",
    "        for output in zip(*outputs):\n",
    "\n",
    "            # Reset voting vectors\n",
    "            relation_tag_tensor = tf.zeros(shape=(len(relations)))\n",
    "            target_tag_tensor = tf.zeros(shape=(len(propositions)))\n",
    "            source_tag_tensor = tf.zeros(shape=(len(propositions)))\n",
    "            \n",
    "            for relation_output, source_output, target_output in zip(*output):\n",
    "                # Add the vote for each class\n",
    "                relation_tag_tensor = tf.add(relation_tag_tensor, relation_eye[tf.argmax(relation_output)])\n",
    "                target_tag_tensor = tf.add(target_tag_tensor, proposition_eye[tf.argmax(target_output)])\n",
    "                source_tag_tensor = tf.add(source_tag_tensor, proposition_eye[tf.argmax(source_output)])\n",
    "            \n",
    "            # Get the most voted class\n",
    "            relation_tag = relations[tf.argmax(relation_tag_tensor)]\n",
    "            target_tag_tensor = propositions[tf.argmax(target_tag_tensor)]\n",
    "            source_tag_tensor = propositions[tf.argmax(source_tag_tensor)]\n",
    "            \n",
    "            final_result.append((relation_tag, source_tag_tensor, target_tag_tensor))\n",
    "            \n",
    "        return final_result\n",
    "    \n",
    "    def call(self, source_inputs, target_inputs, distance_inputs):\n",
    "        \n",
    "        outputs = [[], [], []]\n",
    "        if source_inputs == [] or target_inputs == [] or distance_inputs == []:\n",
    "            return outputs\n",
    "\n",
    "        if len(set([len(source_inputs), len(target_inputs), len(distance_inputs)])) > 1:\n",
    "            print(\"WARNING: source_inputs, target_inputs, distance_inputs with different lengths\")\n",
    "\n",
    "        source_ds = tf.data.Dataset.from_tensor_slices(tf.constant(source_inputs)).map(lambda x: self.sequence_vectorizer(x))\n",
    "        target_ds = tf.data.Dataset.from_tensor_slices(tf.constant(target_inputs)).map(lambda x: self.sequence_vectorizer(x))\n",
    "        distance_ds = tf.data.Dataset.from_tensor_slices(tf.constant(distance_inputs)).map(lambda x: encode_distance(x, self.distance_encoding_bits))\n",
    "    \n",
    "        inputs_ds = tf.data.Dataset.zip((source_ds, target_ds, distance_ds)).batch(self.batch_size)\n",
    "        \n",
    "        for inputs in inputs_ds:\n",
    "            relations = []\n",
    "            sources = []\n",
    "            targets = []\n",
    "            for model in self.models:\n",
    "                output = model(list(inputs))\n",
    "                for i, (relation, source, target) in enumerate(zip(*output)):\n",
    "                    if i == len(relations):\n",
    "                        relations.append([])\n",
    "                    relations[i].append(relation)\n",
    "                    if i == len(sources):\n",
    "                        sources.append([])\n",
    "                    sources[i].append(source)\n",
    "                    if i == len(targets):\n",
    "                        targets.append([])\n",
    "                    targets[i].append(target)\n",
    "            outputs[0].extend(relations)\n",
    "            outputs[1].extend(sources)\n",
    "            outputs[2].extend(targets)\n",
    "        return self.__decode_outputs(outputs)\n",
    "\n",
    "def build_link_prediction_model(params: dict):\n",
    "    models = params[params['model_name']]\n",
    "    sequence_vectorizer = params['sequence_vectorizer']\n",
    "    proposition_tag_vectorizer = params['proposition_tag_vectorizer']\n",
    "    relation_tag_vectorizer = params['relation_tag_vectorizer']\n",
    "    distance_encoding_bits = params['max_distance_encoded'] * 2\n",
    "    \n",
    "    \n",
    "    model = LinkPredictionModel(\n",
    "        models=models,\n",
    "        sequence_vectorizer=sequence_vectorizer,\n",
    "        proposition_tag_vectorizer=proposition_tag_vectorizer,\n",
    "        relation_tag_vectorizer=relation_tag_vectorizer,\n",
    "        distance_encoding_bits=distance_encoding_bits\n",
    "    )\n",
    "    \n",
    "    source = \"muchos aos , la gente tena que pagar una gran cantidad de dinero prar enviar sus cartas , y sus pagos estaban relacionados con el peso de sus cartas o cajas , y muchos accidentes pueden causar el problema de que el correo no se pueda entregar\"\n",
    "    target = \"electrnico puede contarse como uno de los resultados ms beneficiosos de la tecnologa moderna\"\n",
    "    source = \"muchos pagar\"\n",
    "    target = \"algo\"\n",
    "    \n",
    "    result = model([source, source, source], [target, target, target], [-1, 0 , 1])\n",
    "    \n",
    "    print(result)\n",
    "    print(len(result))\n",
    "\n",
    "    params[params['model_name'] + \"_final\"] = model\n",
    "    \n",
    "build_link_prediction_model(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch: 1\n",
      "batch: 2\n",
      "batch: 3\n",
      "batch: 4\n",
      "batch: 5\n",
      "batch: 6\n",
      "batch: 7\n",
      "batch: 8\n",
      "batch: 9\n",
      "batch: 10\n",
      "batch: 11\n",
      "batch: 12\n",
      "batch: 13\n",
      "batch: 14\n",
      "batch: 15\n",
      "batch: 16\n",
      "batch: 17\n",
      "batch: 18\n",
      "batch: 19\n",
      "batch: 20\n",
      "batch: 21\n",
      "batch: 22\n",
      "batch: 23\n",
      "batch: 24\n",
      "batch: 25\n",
      "batch: 26\n",
      "batch: 27\n",
      "batch: 28\n",
      "batch: 29\n",
      "batch: 30\n",
      "batch: 31\n",
      "batch: 32\n",
      "batch: 33\n",
      "batch: 34\n",
      "batch: 35\n",
      "batch: 36\n",
      "batch: 37\n",
      "batch: 38\n",
      "batch: 39\n",
      "batch: 40\n",
      "batch: 41\n",
      "batch: 42\n",
      "batch: 43\n",
      "batch: 44\n",
      "batch: 45\n",
      "batch: 46\n",
      "batch: 47\n",
      "batch: 48\n",
      "batch: 49\n",
      "batch: 50\n",
      "batch: 51\n",
      "batch: 52\n",
      "batch: 53\n",
      "batch: 54\n",
      "batch: 55\n",
      "batch: 56\n",
      "batch: 57\n",
      "batch: 58\n",
      "batch: 59\n",
      "batch: 60\n",
      "batch: 61\n",
      "batch: 62\n",
      "batch: 63\n",
      "batch: 64\n",
      "batch: 65\n",
      "batch: 66\n",
      "batch: 67\n",
      "batch: 68\n",
      "batch: 69\n",
      "batch: 70\n",
      "batch: 71\n",
      "batch: 72\n",
      "batch: 73\n",
      "batch: 74\n",
      "batch: 75\n",
      "batch: 76\n",
      "batch: 77\n",
      "batch: 78\n",
      "batch: 79\n",
      "batch: 80\n",
      "batch: 81\n",
      "batch: 82\n",
      "batch: 83\n",
      "batch: 84\n",
      "batch: 85\n",
      "batch: 86\n",
      "batch: 87\n",
      "batch: 88\n",
      "batch: 89\n",
      "batch: 90\n",
      "batch: 91\n",
      "batch: 92\n",
      "batch: 93\n",
      "batch: 94\n",
      "batch: 95\n",
      "batch: 96\n",
      "batch: 97\n",
      "batch: 98\n",
      "batch: 99\n",
      "batch: 100\n",
      "batch: 101\n",
      "batch: 102\n",
      "batch: 103\n",
      "batch: 104\n",
      "batch: 105\n",
      "batch: 106\n",
      "batch: 107\n",
      "batch: 108\n",
      "batch: 109\n",
      "batch: 110\n",
      "batch: 111\n",
      "batch: 112\n",
      "batch: 113\n",
      "batch: 114\n",
      "batch: 115\n",
      "batch: 116\n",
      "batch: 117\n",
      "batch: 118\n",
      "batch: 119\n",
      "batch: 120\n",
      "batch: 121\n",
      "batch: 122\n",
      "batch: 123\n",
      "batch: 124\n",
      "batch: 125\n",
      "batch: 126\n",
      "batch: 127\n",
      "batch: 128\n",
      "batch: 129\n",
      "batch: 130\n",
      "batch: 131\n",
      "batch: 132\n",
      "batch: 133\n",
      "batch: 134\n",
      "batch: 135\n",
      "batch: 136\n",
      "batch: 137\n",
      "batch: 138\n",
      "batch: 139\n",
      "batch: 140\n",
      "batch: 141\n",
      "batch: 142\n",
      "batch: 143\n",
      "batch: 144\n",
      "batch: 145\n",
      "batch: 146\n",
      "batch: 147\n",
      "batch: 148\n",
      "batch: 149\n",
      "batch: 150\n",
      "batch: 151\n",
      "batch: 152\n",
      "batch: 153\n",
      "batch: 154\n",
      "batch: 155\n",
      "batch: 156\n",
      "batch: 157\n",
      "batch: 158\n",
      "batch: 159\n",
      "batch: 160\n",
      "batch: 161\n",
      "batch: 162\n",
      "batch: 163\n",
      "batch: 164\n",
      "batch: 165\n",
      "batch: 166\n",
      "batch: 167\n",
      "batch: 168\n",
      "batch: 169\n",
      "batch: 170\n",
      "batch: 171\n",
      "batch: 172\n",
      "batch: 173\n",
      "batch: 174\n",
      "batch: 175\n",
      "batch: 176\n",
      "batch: 177\n",
      "batch: 178\n",
      "batch: 179\n",
      "batch: 180\n",
      "batch: 181\n",
      "batch: 182\n",
      "batch: 183\n",
      "batch: 184\n",
      "batch: 185\n",
      "batch: 186\n",
      "batch: 187\n",
      "batch: 188\n",
      "batch: 189\n",
      "batch: 190\n",
      "batch: 191\n",
      "batch: 192\n",
      "batch: 193\n",
      "batch: 194\n",
      "batch: 195\n",
      "batch: 196\n",
      "batch: 197\n",
      "batch: 198\n",
      "batch: 199\n",
      "batch: 200\n",
      "batch: 201\n",
      "batch: 202\n",
      "batch: 203\n",
      "batch: 204\n",
      "batch: 205\n",
      "batch: 206\n",
      "batch: 207\n",
      "batch: 208\n",
      "batch: 209\n",
      "batch: 210\n",
      "batch: 211\n",
      "batch: 212\n",
      "batch: 213\n",
      "batch: 214\n",
      "batch: 215\n",
      "batch: 216\n",
      "batch: 217\n",
      "batch: 218\n",
      "batch: 219\n",
      "batch: 220\n",
      "batch: 221\n",
      "batch: 222\n",
      "batch: 223\n",
      "batch: 224\n",
      "batch: 225\n",
      "batch: 226\n",
      "batch: 227\n",
      "batch: 228\n",
      "batch: 229\n",
      "batch: 230\n",
      "batch: 231\n",
      "batch: 232\n",
      "batch: 233\n",
      "batch: 234\n",
      "batch: 235\n",
      "batch: 236\n",
      "batch: 237\n",
      "batch: 238\n",
      "batch: 239\n",
      "batch: 240\n",
      "batch: 241\n",
      "batch: 242\n",
      "batch: 243\n",
      "batch: 244\n",
      "batch: 245\n",
      "batch: 246\n",
      "batch: 247\n",
      "batch: 248\n",
      "batch: 249\n",
      "batch: 250\n",
      "batch: 251\n",
      "batch: 252\n",
      "batch: 253\n",
      "batch: 254\n",
      "batch: 255\n",
      "batch: 256\n",
      "batch: 257\n",
      "batch: 258\n",
      "batch: 259\n",
      "batch: 260\n",
      "batch: 261\n",
      "batch: 262\n",
      "batch: 263\n",
      "batch: 264\n",
      "batch: 265\n",
      "batch: 266\n",
      "batch: 267\n",
      "batch: 268\n",
      "batch: 269\n",
      "batch: 270\n",
      "batch: 271\n",
      "batch: 272\n",
      "batch: 273\n",
      "batch: 274\n",
      "batch: 275\n",
      "batch: 276\n",
      "batch: 277\n",
      "batch: 278\n",
      "batch: 279\n",
      "batch: 280\n",
      "batch: 281\n",
      "batch: 282\n",
      "batch: 283\n",
      "batch: 284\n",
      "batch: 285\n",
      "batch: 286\n",
      "batch: 287\n",
      "batch: 288\n",
      "batch: 289\n",
      "batch: 290\n",
      "batch: 291\n",
      "batch: 292\n",
      "batch: 293\n",
      "batch: 294\n",
      "batch: 295\n",
      "batch: 296\n",
      "batch: 297\n",
      "batch: 298\n",
      "batch: 299\n",
      "batch: 300\n",
      "batch: 301\n",
      "batch: 302\n",
      "batch: 303\n",
      "batch: 304\n",
      "batch: 305\n",
      "batch: 306\n",
      "batch: 307\n",
      "batch: 308\n",
      "batch: 309\n",
      "batch: 310\n",
      "batch: 311\n",
      "batch: 312\n",
      "batch: 313\n",
      "batch: 314\n",
      "batch: 315\n",
      "batch: 316\n",
      "batch: 317\n",
      "batch: 318\n",
      "batch: 319\n",
      "batch: 320\n",
      "batch: 321\n",
      "batch: 322\n",
      "batch: 323\n",
      "batch: 324\n",
      "batch: 325\n",
      "batch: 326\n",
      "batch: 327\n",
      "batch: 328\n",
      "batch: 329\n",
      "batch: 330\n",
      "batch: 331\n",
      "batch: 332\n",
      "batch: 333\n",
      "batch: 334\n",
      "batch: 335\n",
      "batch: 336\n",
      "batch: 337\n",
      "batch: 338\n",
      "batch: 339\n",
      "batch: 340\n",
      "batch: 341\n",
      "batch: 342\n",
      "batch: 343\n",
      "batch: 344\n",
      "batch: 345\n",
      "batch: 346\n",
      "batch: 347\n",
      "batch: 348\n",
      "batch: 349\n",
      "batch: 350\n",
      "batch: 351\n",
      "batch: 352\n",
      "batch: 353\n",
      "batch: 354\n",
      "batch: 355\n",
      "batch: 356\n",
      "batch: 357\n",
      "batch: 358\n",
      "batch: 359\n",
      "batch: 360\n",
      "batch: 361\n",
      "batch: 362\n",
      "batch: 363\n",
      "batch: 364\n",
      "batch: 365\n",
      "batch: 366\n",
      "batch: 367\n",
      "batch: 368\n",
      "batch: 369\n",
      "batch: 370\n",
      "batch: 371\n",
      "batch: 372\n",
      "batch: 373\n",
      "batch: 374\n",
      "batch: 375\n",
      "batch: 376\n",
      "                                         source_prop_text  \\\n",
      "count                                               12024   \n",
      "unique                                               1035   \n",
      "top     profesores podran ensear a los estudiantes a...   \n",
      "freq                                                   20   \n",
      "\n",
      "                                         target_prop_text source_prop_type  \\\n",
      "count                                               12024            12024   \n",
      "unique                                               1035                2   \n",
      "top     Algunos estudiantes disfrutan participando en ...          Premise   \n",
      "freq                                                   20             9528   \n",
      "\n",
      "       target_prop_type relation_type infered_source_prop_type  \\\n",
      "count             12024         12024                    12024   \n",
      "unique                2             5                        1   \n",
      "top             Premise                                Premise   \n",
      "freq               9528         10406                    12024   \n",
      "\n",
      "       infered_target_prop_type infered_relation_type  \\\n",
      "count                     12024                 12024   \n",
      "unique                        2                     3   \n",
      "top                     Premise                         \n",
      "freq                      11558                 10406   \n",
      "\n",
      "                                   distance  \n",
      "count                                 12024  \n",
      "unique                                   19  \n",
      "top     tf.Tensor(0, shape=(), dtype=int32)  \n",
      "freq                                  10406  \n"
     ]
    }
   ],
   "source": [
    "def compute_statistic(params: dict):\n",
    "    data_dataframe = params['raw_data_dataframe']\n",
    "    data_dataframe = data_dataframe[data_dataframe['split'] == 'test']\n",
    "    \n",
    "    model = params[params['model_name'] + \"_final\"]\n",
    "    \n",
    "    statistic = {\n",
    "        'source_prop_text': [],\n",
    "        'target_prop_text': [],\n",
    "        'source_prop_type': [],\n",
    "        'target_prop_type': [],\n",
    "        'relation_type': [],\n",
    "        'infered_source_prop_type': [],\n",
    "        'infered_target_prop_type': [],\n",
    "        'infered_relation_type': [], \n",
    "        'distance': [],\n",
    "    }\n",
    "    \n",
    "    source_ds = tf.data.Dataset.from_tensor_slices(data_dataframe['source_prop_text'])\n",
    "    target_ds = tf.data.Dataset.from_tensor_slices(data_dataframe['target_prop_text'])\n",
    "    distance_ds = tf.data.Dataset.from_tensor_slices(list(data_dataframe['distance'].to_numpy(dtype=int)))\n",
    "    source_tag_ds = tf.data.Dataset.from_tensor_slices(data_dataframe['source_prop_type'])\n",
    "    target_tag_ds = tf.data.Dataset.from_tensor_slices(data_dataframe['target_prop_type'])\n",
    "    relation_tag_ds = tf.data.Dataset.from_tensor_slices(data_dataframe['relation_type'])\n",
    "    \n",
    "    batch_num = 1\n",
    "    for sources, targets, distances, source_tags, target_tags, relation_tags in tf.data.Dataset.zip((source_ds, target_ds, distance_ds, source_tag_ds, target_tag_ds, relation_tag_ds)).batch(32):\n",
    "        print(\"batch:\", batch_num)\n",
    "        batch_num += 1\n",
    "        \n",
    "        inference = model(sources, targets, distances)\n",
    "        \n",
    "        statistic['source_prop_text'].extend([x.numpy().decode() for x in sources])\n",
    "        statistic['target_prop_text'].extend([x.numpy().decode() for x in targets])\n",
    "        statistic['source_prop_type'].extend([x.numpy().decode() for x in source_tags])\n",
    "        statistic['target_prop_type'].extend([x.numpy().decode() for x in target_tags])\n",
    "        statistic['relation_type'].extend([x.numpy().decode() for x in relation_tags])\n",
    "        statistic['distance'].extend(distances)\n",
    "        \n",
    "        for relation_tag, source_tag, target_tag in inference:\n",
    "            statistic['infered_source_prop_type'].append(source_tag)\n",
    "            statistic['infered_target_prop_type'].append(target_tag)\n",
    "            statistic['infered_relation_type'].append(relation_tag)\n",
    "        \n",
    "        if not params['in_production']:\n",
    "            if batch_num > 10:\n",
    "                break\n",
    "    \n",
    "    statistic = pandas.DataFrame(statistic)\n",
    "    print(statistic.describe())\n",
    "    params['statistic'] = statistic\n",
    "    \n",
    "compute_statistic(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show statistic\n",
    "\n",
    "- [ ] Calculate consistency (If support or Inverse_support are present its inverse should be present as well)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:\n",
      "Relation Accuracy: 0.9528443113772455\n",
      "Source Accuracy: 0.7924151696606786\n",
      "Target Accuracy: 0.8068862275449101\n",
      "Source Counter: Counter({'Premise': 9528, 'Claim': 2496})\n",
      "Target Counter: Counter({'Premise': 9528, 'Claim': 2496})\n",
      "Relation Counter: Counter({'': 10406, 'supports': 767, 'supports_Inverse': 767, 'attacks_Inverse': 42, 'attacks': 42})\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def show_statistic(params: dict):\n",
    "    statistic = params['statistic']\n",
    "#     statistic = {\n",
    "#         'source_prop_text': [],\n",
    "#         'target_prop_text': [],\n",
    "#         'source_prop_type': [],\n",
    "#         'target_prop_type': [],\n",
    "#         'relation_type': [],\n",
    "#         'infered_source_prop_type': [],\n",
    "#         'infered_target_prop_type': [],\n",
    "#         'infered_relation_type': [], \n",
    "#         'distance': [],\n",
    "#     }\n",
    "    true_positive_relation = statistic[statistic['relation_type'] == statistic['infered_relation_type']]\n",
    "    true_positive_source = statistic[statistic['source_prop_type'] == statistic['infered_source_prop_type']]\n",
    "    true_positive_target = statistic[statistic['target_prop_type'] == statistic['infered_target_prop_type']]\n",
    "    \n",
    "    print(\"Accuracy:\")\n",
    "    relation_accuracy = len(true_positive_relation) / len(statistic)\n",
    "    print(\"Relation Accuracy:\", relation_accuracy)\n",
    "    source_accuracy = len(true_positive_source) / len(statistic)\n",
    "    print(\"Source Accuracy:\", source_accuracy)\n",
    "    target_accuracy = len(true_positive_target) / len(statistic)\n",
    "    print(\"Target Accuracy:\", target_accuracy)\n",
    "    \n",
    "    source_counter = Counter(statistic['source_prop_type'])\n",
    "    target_counter = Counter(statistic['target_prop_type'])\n",
    "    relation_counter = Counter(statistic['relation_type'])\n",
    "    print(\"Source Counter:\", source_counter)\n",
    "    print(\"Target Counter:\", target_counter)\n",
    "    print(\"Relation Counter:\", relation_counter)\n",
    "    \n",
    "    def plot_confusion_matrix(true_y, pred_y, title, xticks_rotation=0):\n",
    "        ConfusionMatrixDisplay.from_predictions(true_y, pred_y, normalize=\"true\")\n",
    "        plt.xticks(rotation = xticks_rotation)\n",
    "        plt.title(title)\n",
    "        plt.show()\n",
    "        \n",
    "    plot_confusion_matrix(statistic['relation_type'], statistic['infered_relation_type'], \"Relation\", xticks_rotation=45)\n",
    "    plot_confusion_matrix(statistic['source_prop_type'], statistic['infered_source_prop_type'], \"Source\")\n",
    "    plot_confusion_matrix(statistic['target_prop_type'], statistic['infered_target_prop_type'], \"Target\")\n",
    "    \n",
    "show_statistic(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_and_build_model_from_params(params: dict):\n",
    "    extract_propositions(params)\n",
    "    load_saved_model(params)\n",
    "    build_link_prediction_model(params)\n",
    "    return params[params['model_name'] + \"_final\"]\n",
    "\n",
    "load_and_build_model_from_params(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_pipeline(params: dict):\n",
    "    extract_propositions(params)\n",
    "    creating_glove_embeddings(params)\n",
    "    encode_datasets(params)\n",
    "    build_model(params)\n",
    "    train_and_save_model(params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_file(params: dict, content: str, target_file: Path = None, source_language: str=\"english\", source_file: str = None, **kwargs):\n",
    "    model = params[params['model_name'] + \"_final\"]\n",
    "    max_argumentative_distance = params['max_proposition_distance']\n",
    "    \n",
    "#     print(\"Processing\", file)\n",
    "    \n",
    "    parser = ConllParser(bioes=True)\n",
    "    argumentative, _, non_argumentative = parser.parse(content)\n",
    "\n",
    "    source_ids = []\n",
    "    target_ids = []\n",
    "    sources = []\n",
    "    targets = []\n",
    "    distances = []\n",
    "    \n",
    "    predictions: Dict[Tuple[int,int], Tuple[str,str,str]] = {\n",
    "            \n",
    "    }\n",
    "\n",
    "    for _, source in argumentative.iterrows():\n",
    "        for _, target in argumentative.iterrows():\n",
    "            distance = target['prop_id'] - source['prop_id']\n",
    "            if source['prop_id'] == target['prop_id'] or abs(distance) > max_argumentative_distance:\n",
    "                continue\n",
    "            source_ids.append(source['prop_id'])\n",
    "            target_ids.append(target['prop_id'])\n",
    "            sources.append(source['prop_text'])\n",
    "            targets.append(target['prop_text'])\n",
    "            distances.append(distance)\n",
    "\n",
    "#     print(\"Inference\", file)\n",
    "#     print(sources)\n",
    "    inference = model(sources, targets, distances)\n",
    "\n",
    "    for source_id, target_id, (predicted_relation_tag, predicted_source_tag, predicted_target_tag) in zip(source_ids, target_ids, inference):\n",
    "        if predicted_relation_tag:\n",
    "            predictions[source_id, target_id] = predicted_relation_tag, predicted_source_tag, predicted_target_tag\n",
    "\n",
    "    # Remove inverse relations. If the forward relation doesn't exist then\n",
    "    # it will be added in either case the inverse relation will be removed.\n",
    "    to_add = {}\n",
    "    to_remove = set()\n",
    "#     print(\"Removing Inverse relations\", file)\n",
    "    for (source_id, target_id), (predicted_relation_tag, predicted_source_tag, predicted_target_tag) in predictions.items():\n",
    "        inverse_relation = predicted_relation_tag.endswith(\"_Inverse\")\n",
    "        if inverse_relation:\n",
    "            try:\n",
    "                _ = predictions[target_id, source_id]\n",
    "            except KeyError:\n",
    "                # Add the forward relation\n",
    "                no_inverse_tag = predicted_relation_tag[:-len(\"_Inverse\")]\n",
    "                to_add[target_id, source_id] = no_inverse_tag, predicted_target_tag, predicted_source_tag\n",
    "            # Remove inverse relation\n",
    "            to_remove.add((source_id, target_id))\n",
    "\n",
    "    # Commit actions to predictions\n",
    "    for key in to_remove:\n",
    "        predictions.pop(key)\n",
    "    predictions.update(to_add)\n",
    "\n",
    "    # Empty relations table and fill with calculated values\n",
    "    relation_dict = {\n",
    "        'relation_id': [],\n",
    "        'relation_type': [],\n",
    "        'prop_id_source': [],\n",
    "        'prop_id_target': [],\n",
    "    }\n",
    "    relation_id = 1\n",
    "    for (source_id, target_id), (predicted_relation_tag, predicted_source_tag, predicted_target_tag) in predictions.items():\n",
    "        relation_dict['relation_id'].append(relation_id)\n",
    "        relation_dict['relation_type'].append(predicted_relation_tag)\n",
    "        relation_dict['prop_id_source'].append(source_id)\n",
    "        relation_dict['prop_id_target'].append(target_id)\n",
    "        relation_id += 1\n",
    "    relations = pandas.DataFrame(relation_dict)\n",
    "\n",
    "    file_key = \"str(file)\" if not source_file else source_file\n",
    "#     print(\"Parsing from dataframe\")\n",
    "#     print(\"Relations:\", len(relations))\n",
    "    result = parser.from_dataframes({file_key: (argumentative, relations, non_argumentative)}, source_language=source_language, **kwargs)\n",
    "    \n",
    "    if target_file:\n",
    "        target_file.write_text(result[file_key][0])\n",
    "\n",
    "    return result[file_key][0]\n",
    "\n",
    "def use_model(params: dict):\n",
    "    to_process_dir = params['to_process_data_path']\n",
    "    processed_data_dir = params['processed_data_path']\n",
    "    \n",
    "    segmentation_models = sorted(list(os.walk(to_process_dir))[0][1])\n",
    "    print(segmentation_models)\n",
    "    \n",
    "    for segmentation_model in segmentation_models:\n",
    "        \n",
    "        base_path = Path(processed_data_dir) / params['model_name']\n",
    "        base_path.mkdir(exist_ok=True, parents=True)\n",
    "        \n",
    "        current_to_process_dir = Path(to_process_dir, segmentation_model)\n",
    "        corpus_labels = sorted(list(os.walk(current_to_process_dir))[0][1])\n",
    "        print(corpus_labels)\n",
    "        \n",
    "        for corpus_label in corpus_labels:\n",
    "            final_current_to_process_dir = current_to_process_dir / corpus_label\n",
    "            dest_folder = base_path / segmentation_model / corpus_label\n",
    "            dest_folder.mkdir(exist_ok=True, parents=True)\n",
    "            \n",
    "            for file in final_current_to_process_dir.iterdir():\n",
    "                if file.exists() and file.is_file():\n",
    "                    dest_file = dest_folder / file.name\n",
    "                    dest_file.touch(exist_ok=True)\n",
    "                    process_file(params, file.read_text(), dest_file)\n",
    "            \n",
    "use_model(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export jupyter as module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    from pathlib import Path\n",
    "    try:\n",
    "        if Path(__file__).suffix == \".ipynb\":\n",
    "            raise NameError()\n",
    "    except NameError:\n",
    "        # In Jupyer Notebook\n",
    "        from utils.notebook_utils import export_notebook_as_module\n",
    "        export_notebook_as_module(Path(\"link_prediction.ipynb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4cd7ab41f5fca4b9b44701077e38c5ffd31fe66a6cab21e0214b68d958d0e462"
  },
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": ""
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}