{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n",
    "\n",
    "Change INFO_TAG according the data you want to project and/or train the models with.\n",
    "\n",
    "Change PROCESS_TAG according the data you want to process with the trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "\n",
    "INFO_TAG = \"cdcp\"\n",
    "# INFO_TAG = \"persuasive_essays_paragraph_all_linked\"\n",
    "# INFO_TAG = \"abstrct\"\n",
    "\n",
    "# PROCESS_TAG = \"responded_granma_letters\"\n",
    "# PROCESS_TAG = \"response_responded_granma_letters\"\n",
    "PROCESS_TAG = \"selected_response_responded_granma_letters\"\n",
    "\n",
    "\n",
    "BASE_DATA = Path(\"data\")\n",
    "\n",
    "SOURCE_LANGUAGE = \"english\"\n",
    "TARGET_LANGUAGE = \"spanish\"\n",
    "\n",
    "# Corpus Projection\n",
    "CORPUS = BASE_DATA / \"corpus\" / INFO_TAG\n",
    "PROCESSED_CORPUS = BASE_DATA / \"parsed_to_conll\" / INFO_TAG\n",
    "SENTENCE_ALIGN = BASE_DATA / 'sentence_alignment' / INFO_TAG\n",
    "BIDIRECTIONAL_ALIGN = BASE_DATA / 'bidirectional_alignment' / INFO_TAG\n",
    "PROJECTION = BASE_DATA / 'projection' / INFO_TAG\n",
    "\n",
    "# Link Prediction\n",
    "TO_PROCESS = BASE_DATA / \"to_process\" / PROCESS_TAG\n",
    "SEGMENTER = BASE_DATA / \"segmenter_processed\" / INFO_TAG / PROCESS_TAG\n",
    "LINK_PREDICTION = BASE_DATA / 'link_prediction_processed' / INFO_TAG / PROCESS_TAG\n",
    "\n",
    "# Export to Brat\n",
    "BRAT = Path(\"brat\", \"data\", PROCESS_TAG, INFO_TAG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus Projection\n",
    "\n",
    "Make corpus projection. From SOURCE_LANGUAGE to TARGET_LANGUAGE.\n",
    "\n",
    "To change the algorithms used in each step, import other versions of it. For example:\n",
    "\n",
    "python\n",
    "```\n",
    "from aligner.aligner import FastAlignAligner as Aligner\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipelines.corpus_pipelines import full_corpus_processing_pipeline, make_alignemnts_pipeline\n",
    "from aligner.aligner import AwesomeAlignAligner as Aligner\n",
    "from corpus_parser.unified_parser import UnifiedParser as Parser\n",
    "from projector.projector import CrossLingualAnnotationProjector as Projector\n",
    "from sentence_aligner.sentence_aligner import SentenceAligner\n",
    "from sentence_aligner.translator import GoogleDeepTranslator as Translator\n",
    "from data_augmentation.translation_augmentation import TranslateDataAugmentator as DataAugmentator\n",
    "\n",
    "for split in ['dev', 'test', 'train']:\n",
    "    \n",
    "    print(split)\n",
    "    print()\n",
    "    \n",
    "    full_corpus_processing_pipeline(\n",
    "        corpus_dir=CORPUS / split,\n",
    "        standard_corpus_dest_dir=PROCESSED_CORPUS / split,\n",
    "        sentence_alignment_dest_dir=SENTENCE_ALIGN / split,\n",
    "        bidirectional_alignment_dest_dir=BIDIRECTIONAL_ALIGN / split,\n",
    "        projection_dest_dir=PROJECTION / split,\n",
    "        corpus_parser=Parser(),\n",
    "        sentence_aligner=SentenceAligner(Translator()),\n",
    "        aligner=Aligner(),\n",
    "        projector=Projector(),\n",
    "        data_augmentator=DataAugmentator(),\n",
    "        source_language=SOURCE_LANGUAGE,\n",
    "        target_language=TARGET_LANGUAGE,\n",
    "        middle_language=TARGET_LANGUAGE,\n",
    "        use_spacy=True,\n",
    "    )\n",
    "    \n",
    "#     make_alignemnts_pipeline(\n",
    "#         standard_corpus_dir=PROCESSED_CORPUS/ split,\n",
    "#         sentence_alignment_dest_dir=SENTENCE_ALIGN/ split,\n",
    "#         bidirectional_alignment_dest_dir=BIDIRECTIONAL_ALIGN/ split,\n",
    "#         projection_dest_dir=PROJECTION/ split,\n",
    "#         sentence_aligner=SentenceAligner(Translator()),\n",
    "#         aligner=Aligner(),\n",
    "#         projector=Projector(),\n",
    "#         data_augmentator=DataAugmentator(),\n",
    "#         source_language=SOURCE_LANGUAGE,\n",
    "#         target_language=TARGET_LANGUAGE,\n",
    "#         use_spacy=True,\n",
    "#     )\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Segmentator\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from segmenter.models.train import train as segmenter_train\n",
    "\n",
    "segmenter_kwargs = {\n",
    "    \"corpus_tag\": INFO_TAG,\n",
    "    \"language\": TARGET_LANGUAGE,\n",
    "    # Define other kwargs. For full list see param dictionary at segmenter/models/segmenter.ipynb\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "segmenter_train(**segmenter_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Link Predictor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from link_prediction.models.train import train as link_prediction_train\n",
    "\n",
    "link_prediction_kwargs = {\n",
    "    \"corpus_tag\": INFO_TAG,\n",
    "    \"language\": TARGET_LANGUAGE,\n",
    "    # Define other kwargs. For full list see param dictionary at link_prediction/models/link_prediction.ipynb\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "link_prediction_train(**link_prediction_kwargs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pipelines.segmenter_pipelines import perform_segmentation_pipeline\n",
    "from segmenter.tf_segmenter import TensorflowArgumentSegmenter as Segmenter\n",
    "\n",
    "segmenter = Segmenter(INFO_TAG, TARGET_LANGUAGE, **segmenter_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only segmentation\n",
    "\n",
    "perform_segmentation_pipeline(\n",
    "    segmenter=segmenter,\n",
    "    source_dir=TO_PROCESS,\n",
    "    destination_dir=SEGMENTER,\n",
    "    language=TARGET_LANGUAGE,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipelines.segmenter_pipelines import perform_link_prediction_pipeline\n",
    "from link_prediction.tf_link_predictor import TensorflowLinkPredictor as LinkPredictor\n",
    "\n",
    "link_predictor = LinkPredictor(INFO_TAG, TARGET_LANGUAGE, **link_prediction_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only link prediction (Segmentation process must be done first)\n",
    "\n",
    "perform_link_prediction_pipeline(\n",
    "    link_predictor=link_predictor,\n",
    "    source_dir=SEGMENTER,\n",
    "    destination_dir=LINK_PREDICTION,\n",
    "    source_language=TARGET_LANGUAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Prediction and Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from pipelines.segmenter_pipelines import perform_full_inference_pipeline\n",
    "\n",
    "# Both processes Segmentation and Link prediction\n",
    "perform_full_inference_pipeline(\n",
    "    segmenter=segmenter,\n",
    "    link_predictor=link_predictor,\n",
    "    source_dir=TO_PROCESS,\n",
    "    segmenter_destination_dir=SEGMENTER,\n",
    "    destination_dir=LINK_PREDICTION,\n",
    "    source_language=TARGET_LANGUAGE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to Brat\n",
    "\n",
    "To run brat server run the script `run_brat.sh`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corpus_parser.brat_parser import BratParser\n",
    "from corpus_parser.conll_parser import ConllParser\n",
    "\n",
    "dataframes_dict = ConllParser(bioes=True).parse_dir(LINK_PREDICTION)\n",
    "BratParser().export_from_dataframes(BRAT, dataframes_dict)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
