{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Main\n",
    "\n",
    "Using the notebook will allow you to load the model once and use it as many times as you\n",
    "want. Also makes the code more resilient to errors, such as a bad path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "INFO_TAG = \"persuasive_essays_paragraph\"\n",
    "BASE_DATA = Path(\"data\")\n",
    "\n",
    "SOURCE_LANGUAGE = \"english\"\n",
    "TARGET_LANGUAGE = \"spanish\"\n",
    "\n",
    "# Corpus Projection\n",
    "CORPUS = BASE_DATA / \"corpus\" / INFO_TAG\n",
    "PROCESSED_CORPUS = BASE_DATA / \"parsed_to_conll\" / INFO_TAG\n",
    "SENTENCE_ALIGN = BASE_DATA / 'sentence_alignment' / INFO_TAG\n",
    "BIDIRECTIONAL_ALIGN = BASE_DATA / 'bidirectional_alignment' / INFO_TAG\n",
    "PROJECTION = BASE_DATA / 'projection' / INFO_TAG\n",
    "\n",
    "# Link Prediction\n",
    "TO_PROCESS = BASE_DATA / \"to_process\" / INFO_TAG\n",
    "SEGMENTER = BASE_DATA / \"segmenter_processed\" / INFO_TAG\n",
    "LINK_PREDICTION = BASE_DATA / 'link_prediction_processed' / INFO_TAG\n",
    "\n",
    "# Export to Brat\n",
    "BRAT = Path(\"brat\", \"data\", INFO_TAG)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Corpus Projection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipelines.corpus_pipelines import full_corpus_processing_pipeline\n",
    "\n",
    "from aligner.aligner import AwesomeAlignAligner as Aligner\n",
    "from corpus_parser.unified_parser import UnifiedParser as Parser\n",
    "from projector.projector import CrossLingualAnnotationProjector as Projector\n",
    "from sentence_aligner.sentence_aligner import SentenceAligner\n",
    "from sentence_aligner.translator import GoogleDeepTranslator as Translator\n",
    "\n",
    "full_corpus_processing_pipeline(\n",
    "    corpus_dir=CORPUS,\n",
    "    standard_corpus_dest_dir=PROCESSED_CORPUS,\n",
    "    sentence_alignment_dest_dir=SENTENCE_ALIGN,\n",
    "    bidirectional_alignment_dest_dir=BIDIRECTIONAL_ALIGN,\n",
    "    projection_dest_dir=PROJECTION,\n",
    "    corpus_parser=Parser(),\n",
    "    sentence_aligner=SentenceAligner(Translator()),\n",
    "    aligner=Aligner(),\n",
    "    projector=Projector(),\n",
    "    source_language=SOURCE_LANGUAGE,\n",
    "    target_language=TARGET_LANGUAGE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Link Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pipelines.segmenter_pipelines import perform_full_inference_pipeline, perform_segmentation_pipeline, perform_link_prediction_pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from segmenter.tf_segmenter import TensorflowArgumentSegmenter as Segmenter\n",
    "\n",
    "segmenter = Segmenter(INFO_TAG, TARGET_LANGUAGE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dev relations 652\n",
      "dev source argumentative units 326\n",
      "dev target argumentative units 144\n",
      "test relations 1618\n",
      "test source argumentative units 809\n",
      "test target argumentative units 365\n",
      "train relations 5392\n",
      "train source argumentative units 2696\n",
      "train target argumentative units 1198\n",
      "Vocab size 8958\n",
      "Relation tags ['supports', 'attacks', 'supports_Inverse', 'attacks_Inverse']\n",
      "Proposition tags ['Claim', 'MajorClaim', 'Premise']\n",
      "max_size_prop 70\n",
      "max_amount_doc 20\n",
      "[('supports', 'Premise', 'Claim'), ('', 'Premise', 'Premise'), ('supports', 'Premise', 'Premise')]\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "from link_prediction.tf_link_predictor import TensorflowLinkPredictor as LinkPredictor\n",
    "\n",
    "link_predictor = LinkPredictor(INFO_TAG, TARGET_LANGUAGE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# perform_segmentation_pipeline(\n",
    "#     segmenter=segmenter,\n",
    "#     source_dir=TO_PROCESS,\n",
    "#     destination_dir=SEGMENTER,\n",
    "# )\n",
    "\n",
    "perform_link_prediction_pipeline(\n",
    "    link_predictor=link_predictor,\n",
    "    source_dir=SEGMENTER,\n",
    "    destination_dir=LINK_PREDICTION,\n",
    "    source_language=TARGET_LANGUAGE\n",
    ")\n",
    "\n",
    "# perform_full_inference_pipeline(\n",
    "#     segmenter=segmenter,\n",
    "#     link_predictor=link_predictor,\n",
    "#     source_dir=TO_PROCESS,\n",
    "#     segmenter_destination_dir=SEGMENTER,\n",
    "#     destination_dir=LINK_PREDICTION,\n",
    "#     source_language=TARGET_LANGUAGE\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export to Brat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from corpus_parser.brat_parser import BratParser\n",
    "from corpus_parser.conll_parser import ConllParser\n",
    "\n",
    "dataframes_dict = ConllParser(bioes=True).parse_dir(LINK_PREDICTION)\n",
    "\n",
    "BratParser().export_from_dataframes(BRAT, dataframes_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
